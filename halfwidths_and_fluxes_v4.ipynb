{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pore size and flow rate distributions in 2D porous media calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.spatial import KDTree\n",
    "from skimage.morphology import medial_axis\n",
    "from shapely import vectorized\n",
    "from shapely.geometry import Point, LineString, box\n",
    "from shapely.ops import polygonize, unary_union\n",
    "from shapely.prepared import prep\n",
    "import networkx as netx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read and load the VTK file that contains the solved OpenFOAM case\n",
    "\n",
    "case_dir = os.path.expanduser(\"~/OpenFOAM/jose-v2406/run/YDRAY-flow_n13_sat\")\n",
    "vtk_file = os.path.join(case_dir, \"VTK\", \"YDRAY-flow_n13_sat_1047.vtm\")\n",
    "\n",
    "mb        = pv.read(vtk_file)\n",
    "vol_mesh  = mb[\"internal\"] #the \"fluid\" mesh (where CFD is solved)\n",
    "cyl_patch = mb[\"boundary\"][\"wallFluidSolid\"] # the walls of the cylindrical obstacles\n",
    "\n",
    "_, _, _, _, zmin, zmax = vol_mesh.bounds\n",
    "z_mid = 0.5 * (zmin + zmax)\n",
    "\n",
    "# As the problem is 2D, we take a 2D slice centered at z=0 of both the internal mesh and the cylinders' walls and get rid of everything else\n",
    "obst_section = (\n",
    "    cyl_patch.extract_surface()\n",
    "             .slice(normal=\"z\", origin=(0, 0, z_mid))\n",
    "             .clean()\n",
    ")\n",
    "dom_section = (\n",
    "    vol_mesh.extract_surface()\n",
    "            .slice(normal=\"z\", origin=(0, 0, z_mid))\n",
    "            .clean()\n",
    ")\n",
    "\n",
    "xmin, xmax, ymin, ymax, _, _ = dom_section.bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Tu código va aquí arriba)\n",
    "# ... (importaciones y carga de datos)\n",
    "# ... (definición de xmin, xmax, ymin, ymax)\n",
    "\n",
    "# Importamos la función para encontrar picos\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "print(\"Iniciando análisis de geometría...\")\n",
    "\n",
    "## 1. Poligonizar los obstáculos\n",
    "# -------------------------------------------------\n",
    "# Extraemos los puntos 2D y las líneas de la sección de obstáculos\n",
    "points_2d = obst_section.points[:, :2]\n",
    "lines_array = obst_section.lines\n",
    "\n",
    "shapely_lines = []\n",
    "i = 0\n",
    "while i < len(lines_array):\n",
    "    n_points = lines_array[i]\n",
    "    point_indices = lines_array[i + 1 : i + 1 + n_points]\n",
    "    line_coords = points_2d[point_indices]\n",
    "    \n",
    "    # Asegurarse de que la línea tenga al menos 2 puntos\n",
    "    if len(line_coords) > 1:\n",
    "        shapely_lines.append(LineString(line_coords))\n",
    "    \n",
    "    i += n_points + 1\n",
    "\n",
    "# Usamos polygonize para encontrar todos los polígonos cerrados\n",
    "all_polygons = list(polygonize(shapely_lines))\n",
    "print(f\"Encontrados {len(all_polygons)} polígonos iniciales.\")\n",
    "\n",
    "## 2. Clasificar polígonos (circulares vs. fusionados)\n",
    "# -------------------------------------------------\n",
    "# Un círculo perfecto tiene una circularidad de 1.\n",
    "# Circularidad = (4 * pi * Area) / (Perimetro^2)\n",
    "CIRCULARITY_THRESHOLD = 0.9 \n",
    "\n",
    "circular_polygons = []\n",
    "merged_polygons = []\n",
    "\n",
    "for poly in all_polygons:\n",
    "    if poly.area == 0:\n",
    "        continue\n",
    "    \n",
    "    circularity = (4 * np.pi * poly.area) / (poly.length ** 2)\n",
    "    \n",
    "    if circularity > CIRCULARITY_THRESHOLD:\n",
    "        circular_polygons.append(poly)\n",
    "    else:\n",
    "        merged_polygons.append(poly)\n",
    "\n",
    "print(f\"Clasificados: {len(circular_polygons)} círculos individuales y {len(merged_polygons)} polígonos fusionados.\")\n",
    "\n",
    "\n",
    "## 3. Descomponer polígonos fusionados\n",
    "# -------------------------------------------------\n",
    "# Esta es la parte más compleja. Usamos una transformada de distancia.\n",
    "\n",
    "# Definimos una cuadrícula para rasterizar los polígonos\n",
    "GRID_RES = 500 # Resolución (más alta = más preciso pero más lento)\n",
    "x_grid = np.linspace(xmin, xmax, GRID_RES)\n",
    "y_grid = np.linspace(ymin, ymax, GRID_RES)\n",
    "xx, yy = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# Puntos de la cuadrícula aplanados para la comprobación\n",
    "grid_points_x = xx.ravel()\n",
    "grid_points_y = yy.ravel()\n",
    "\n",
    "# Calculamos el tamaño del píxel (promedio, asumiendo proporciones similares)\n",
    "pixel_size = (x_grid[1] - x_grid[0] + y_grid[1] - y_grid[0]) / 2.0\n",
    "\n",
    "# Estimamos una distancia mínima entre picos\n",
    "# Si encontramos círculos individuales, usamos su radio como guía\n",
    "if circular_polygons:\n",
    "    radii = [np.sqrt(p.area / np.pi) for p in circular_polygons]\n",
    "    median_radius = np.median(radii)\n",
    "    # Distancia mínima = 80% del radio mediano, convertido a píxeles\n",
    "    min_dist_px = int((median_radius * 0.8) / pixel_size)\n",
    "    min_dist_px = max(1, min_dist_px) # Asegura que sea al menos 1\n",
    "else:\n",
    "    # Si no hay círculos, usamos un valor fijo (ajustar si es necesario)\n",
    "    min_dist_px = 5 \n",
    "    print(\"Advertencia: No se encontraron círculos individuales. Usando min_distance=5px para la detección de picos.\")\n",
    "\n",
    "print(f\"Usando una distancia mínima entre picos de {min_dist_px} píxeles.\")\n",
    "\n",
    "# Lista final para guardar todos los círculos (los originales + los descompuestos)\n",
    "final_circular_polygons = list(circular_polygons)\n",
    "\n",
    "for i, merged_poly in enumerate(merged_polygons):\n",
    "    print(f\"Procesando polígono fusionado {i+1}/{len(merged_polygons)}...\")\n",
    "    \n",
    "    # 1. Rasterizar: crear una máscara 2D del polígono\n",
    "    mask_flat = vectorized.contains(merged_poly, grid_points_x, grid_points_y)\n",
    "    mask = mask_flat.reshape(GRID_RES, GRID_RES)\n",
    "    \n",
    "    if not np.any(mask):\n",
    "        print(f\"  Polígono {i+1} está vacío o fuera de los límites, omitiendo.\")\n",
    "        continue\n",
    "\n",
    "    # 2. Transformada de distancia: distancia desde cada píxel interior al borde\n",
    "    distance = distance_transform_edt(mask)\n",
    "    \n",
    "    # 3. Encontrar picos (centros de los círculos)\n",
    "    # peak_local_max encuentra coordenadas (fila, columna) de los máximos locales\n",
    "    local_max_indices = peak_local_max(distance, min_distance=min_dist_px, labels=mask)\n",
    "    \n",
    "    # 4. Re-crear círculos\n",
    "    for (row, col) in local_max_indices:\n",
    "        # Convertir índice de píxel (fila, col) a coordenadas (x, y)\n",
    "        center_x = x_grid[col]\n",
    "        center_y = y_grid[row]\n",
    "        \n",
    "        # El radio es el valor de la transformada de distancia en el pico\n",
    "        radius_px = distance[row, col]\n",
    "        radius = radius_px * pixel_size\n",
    "        \n",
    "        # Crear el nuevo círculo y añadirlo a la lista final\n",
    "        new_circle = Point(center_x, center_y).buffer(radius)\n",
    "        final_circular_polygons.append(new_circle)\n",
    "\n",
    "print(f\"Descomposición completa. Total de círculos: {len(final_circular_polygons)}\")\n",
    "\n",
    "\n",
    "## 4. Visualización\n",
    "# -------------------------------------------------\n",
    "print(\"Generando visualización...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12), dpi = 300)\n",
    "\n",
    "# Dibujar los polígonos originales fusionados (para comparar)\n",
    "for poly in merged_polygons:\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.plot(x, y, color='red', linestyle='--', linewidth=1.5, label='Original Fusionado' if 'Original Fusionado' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# Dibujar la lista final de círculos\n",
    "for poly in final_circular_polygons:\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.6, fc='blue', ec='none', label='Círculo Descompuesto' if 'Círculo Descompuesto' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_title(f\"Descomposición de Obstáculos ({len(final_circular_polygons)} círculos finales)\")\n",
    "ax.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Definiendo la Región de Interés (ROI)...\")\n",
    "\n",
    "# Calcular la longitud total en X del dominio\n",
    "x_length = xmax - xmin\n",
    "\n",
    "# Definir los nuevos límites del ROI (ignorando el 3% en cada extremo)\n",
    "roi_xmin = xmin + 0.03 * x_length\n",
    "roi_xmax = xmax - 0.03 * x_length\n",
    "\n",
    "# Los límites de Y no cambian\n",
    "roi_ymin = ymin\n",
    "roi_ymax = ymax\n",
    "\n",
    "print(f\"Límites originales en X: ({xmin:.4f}, {xmax:.4f})\")\n",
    "print(f\"Límites del ROI en X:   ({roi_xmin:.4f}, {roi_xmax:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "print(\"Iniciando la construcción de la red de tubos...\")\n",
    "\n",
    "## 1. Extraer Centros y Radios\n",
    "# -------------------------------------------------\n",
    "# (Esta parte no cambia)\n",
    "bead_data = []\n",
    "for poly in final_circular_polygons:\n",
    "    bead_data.append({\n",
    "        'center': np.array([poly.centroid.x, poly.centroid.y]),\n",
    "        'radius': np.sqrt(poly.area / np.pi)\n",
    "    })\n",
    "centers = np.array([d['center'] for d in bead_data])\n",
    "radii = np.array([d['radius'] for d in bead_data])\n",
    "n_real_beads = len(centers)\n",
    "print(f\"Extraídos {n_real_beads} centros y radios de los granos.\")\n",
    "\n",
    "## 2. Crear \"Ghost Beads\" para las paredes Ymin / Ymax\n",
    "# -------------------------------------------------\n",
    "# (Esta parte no cambia)\n",
    "max_r = np.max(radii)\n",
    "reflection_dist = 3.0 * max_r\n",
    "near_bottom_indices = np.where(centers[:, 1] < ymin + reflection_dist)[0]\n",
    "ghost_centers_bottom = np.copy(centers[near_bottom_indices])\n",
    "ghost_centers_bottom[:, 1] = ymin - (ghost_centers_bottom[:, 1] - ymin) # Reflejar\n",
    "ghost_radii_bottom = radii[near_bottom_indices]\n",
    "near_top_indices = np.where(centers[:, 1] > ymax - reflection_dist)[0]\n",
    "ghost_centers_top = np.copy(centers[near_top_indices])\n",
    "ghost_centers_top[:, 1] = ymax + (ymax - ghost_centers_top[:, 1]) # Reflejar\n",
    "ghost_radii_top = radii[near_top_indices]\n",
    "all_centers = np.vstack((centers, ghost_centers_bottom, ghost_centers_top))\n",
    "all_radii = np.hstack((radii, ghost_radii_bottom, ghost_radii_top))\n",
    "print(f\"Creados {len(ghost_centers_bottom)} ghosts inferiores y {len(ghost_centers_top)} ghosts superiores.\")\n",
    "\n",
    "## 3. Triangulación de Delaunay\n",
    "# -------------------------------------------------\n",
    "# (Esta parte no cambia)\n",
    "tri = Delaunay(all_centers)\n",
    "edges = set()\n",
    "for simplex in tri.simplices:\n",
    "    edges.add(tuple(sorted((simplex[0], simplex[1]))))\n",
    "    edges.add(tuple(sorted((simplex[1], simplex[2]))))\n",
    "    edges.add(tuple(sorted((simplex[2], simplex[0]))))\n",
    "print(f\"Triangulación de Delaunay completada. {len(edges)} ejes totales encontrados.\")\n",
    "\n",
    "## 4. Preparar el KDTree para el muestreo rápido\n",
    "# -------------------------------------------------\n",
    "# (Esta parte no cambia)\n",
    "print(\"Preparando el árbol KDTree para un muestreo de velocidad rápido...\")\n",
    "VEL_NAME_CELL = None\n",
    "common_names = ['U', 'velocity', 'Velocity', 'VELOCITY']\n",
    "for name in common_names:\n",
    "    if name in vol_mesh.cell_data:\n",
    "        VEL_NAME_CELL = name\n",
    "        break\n",
    "if VEL_NAME_CELL is None:\n",
    "    print(f\"ADVERTENCIA: No se encontró 'U' o 'velocity' en vol_mesh.cell_data.\")\n",
    "    print(\"Buscando primer campo vectorial disponible en cell_data...\")\n",
    "    for name, array in vol_mesh.cell_data.items():\n",
    "        if array.ndim == 2 and array.shape[1] == 3:\n",
    "            VEL_NAME_CELL = name\n",
    "            break\n",
    "if VEL_NAME_CELL:\n",
    "    print(f\"Usando el campo de velocidad de celda: '{VEL_NAME_CELL}'\")\n",
    "    cell_centers_3d = vol_mesh.cell_centers().points\n",
    "    U_cells = vol_mesh.cell_data[VEL_NAME_CELL][:, :2] # (M,2)\n",
    "    tree = cKDTree(cell_centers_3d[:, :2])\n",
    "    print(\"Árbol KDTree construido.\")\n",
    "else:\n",
    "    print(\"ERROR FATAL: No se encontró ningún campo de velocidad en cell_data. El caudal será 0.\")\n",
    "    tree = None\n",
    "\n",
    "\n",
    "## 5. Calcular Propiedades del Tubo (FILTRADO POR ROI y SIN DUPLICADOS)\n",
    "# -------------------------------------------------\n",
    "\n",
    "H_METERS = 0.001 # 1 mm en metros\n",
    "N_SAMPLES = 50   # Número de puntos para la integración\n",
    "tube_list = []\n",
    "\n",
    "if 'tree' not in locals() or tree is None:\n",
    "     print(\"ERROR: El árbol KDTree no está definido. Ejecuta la celda de preparación del árbol.\")\n",
    "if 'roi_xmin' not in locals():\n",
    "    print(\"ERROR: Los límites del ROI no están definidos. Ejecuta la celda de definición de ROI.\")\n",
    "\n",
    "wall_tubes_created_for_bead = set()\n",
    "print(f\"Iniciando cálculo de tubos (filtrando por ROI en X: [{roi_xmin:.4f}, {roi_xmax:.4f}])...\")\n",
    "\n",
    "# --- ¡NUEVO! Umbral para definir \"flujo real\" ---\n",
    "# Lo usaremos para encontrar la anchura efectiva\n",
    "VEL_THRESHOLD_RATIO = 0.001 # 5% de la velocidad máxima del perfil\n",
    "\n",
    "for idx1, idx2 in edges:\n",
    "    \n",
    "    # 5.1. Omitir ejes \"fantasma-fantasma\"\n",
    "    if idx1 >= n_real_beads and idx2 >= n_real_beads:\n",
    "        continue\n",
    "\n",
    "    # 5.2. Geometría del tubo\n",
    "    is_wall_tube = (idx1 >= n_real_beads) or (idx2 >= n_real_beads)\n",
    "    \n",
    "    if is_wall_tube:\n",
    "        real_idx = idx1 if idx1 < n_real_beads else idx2\n",
    "        if real_idx in wall_tubes_created_for_bead:\n",
    "            continue\n",
    "        c_real = centers[real_idx]\n",
    "        r_real = radii[real_idx]\n",
    "        is_top_wall = c_real[1] > (ymax + ymin) / 2.0\n",
    "        \n",
    "        if is_top_wall:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] + r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymax])\n",
    "            n_vec = np.array([0.0, 1.0])\n",
    "        else:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] - r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymin])\n",
    "            n_vec = np.array([0.0, -1.0])\n",
    "            \n",
    "        width = np.linalg.norm(p_edge_bead - p_edge_wall)\n",
    "        wall_tubes_created_for_bead.add(real_idx)\n",
    "        \n",
    "    else:\n",
    "        c1, c2 = all_centers[idx1], all_centers[idx2]\n",
    "        r1, r2 = all_radii[idx1], all_radii[idx2]\n",
    "        center_vec = c2 - c1\n",
    "        dist = np.linalg.norm(center_vec)\n",
    "        width = dist - (r1 + r2)\n",
    "        n_vec = center_vec / dist\n",
    "        p_edge_wall = c1 + n_vec * r1\n",
    "        p_edge_bead = c2 - n_vec * r2\n",
    "\n",
    "    # 5.3. Filtrar tubos con solapamiento\n",
    "    if width <= 0:\n",
    "        continue\n",
    "\n",
    "    # --- INICIO DE LA SECCIÓN MODIFICADA ---\n",
    "    \n",
    "    # 5.4. Calcular Caudal (Flow Rate) y Anchura Efectiva\n",
    "    n_vec = np.array([-n_vec[1], n_vec[0]]) # Vector normal para la integral\n",
    "    flow_rate = 0.0\n",
    "    effective_width = width # Por defecto, es la anchura geométrica\n",
    "    \n",
    "    if tree is not None and width > 1e-9: \n",
    "        # Puntos de muestreo a lo largo de la anchura GEOMÉTRICA\n",
    "        sample_points_2d = np.linspace(p_edge_wall, p_edge_bead, N_SAMPLES)\n",
    "        # Eje de integración (distancia de 0 a width)\n",
    "        integration_axis = np.linspace(0, width, N_SAMPLES)\n",
    "        \n",
    "        # Muestrear velocidades\n",
    "        dists, idxs = tree.query(sample_points_2d, k=1)\n",
    "        velocities_2d = U_cells[idxs]\n",
    "        velocities_2d = np.nan_to_num(velocities_2d, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Perfil de velocidad normal al tubo\n",
    "        v_normal_components = np.dot(velocities_2d, n_vec)\n",
    "        v_abs = np.abs(v_normal_components)\n",
    "        v_max = np.max(v_abs)\n",
    "        \n",
    "        if v_max > 1e-12: # Si hay algo de flujo\n",
    "            threshold = v_max * VEL_THRESHOLD_RATIO\n",
    "            \n",
    "            # Encontrar los índices (del array de N_SAMPLES) donde el flujo es \"real\"\n",
    "            effective_indices = np.where(v_abs > threshold)[0]\n",
    "            \n",
    "            if len(effective_indices) > 1:\n",
    "                # Encontrar el inicio y el fin del flujo\n",
    "                i_start = np.min(effective_indices)\n",
    "                i_end = np.max(effective_indices)\n",
    "                \n",
    "                # Recalcular el caudal (integral) SOLO en la sección efectiva\n",
    "                v_effective = v_normal_components[i_start:i_end+1]\n",
    "                axis_effective = integration_axis[i_start:i_end+1]\n",
    "                \n",
    "                integral_value = np.trapz(y=v_effective, x=axis_effective)\n",
    "                flow_rate = np.abs(integral_value) * H_METERS\n",
    "                \n",
    "                # ¡LA CLAVE! Corregir la anchura del tubo\n",
    "                effective_width = axis_effective[-1] - axis_effective[0]\n",
    "                \n",
    "            else:\n",
    "                # Todo el flujo está por debajo del umbral, o es un solo punto\n",
    "                flow_rate = 0.0\n",
    "                effective_width = 0.0\n",
    "                \n",
    "        else:\n",
    "            # No hay nada de flujo\n",
    "            flow_rate = 0.0\n",
    "            effective_width = 0.0 # Tubo bloqueado\n",
    "            \n",
    "    # --- FIN DE LA SECCIÓN MODIFICADA ---\n",
    "\n",
    "    # 5.5. Calcular Midpoint\n",
    "    midpoint_2d = (p_edge_wall + p_edge_bead) / 2.0\n",
    "    \n",
    "    # 5.6. Guardar resultados (USANDO LA NUEVA ANCHURA)\n",
    "    tube_list.append({\n",
    "        'midpoint': midpoint_2d, \n",
    "        'width': effective_width, # <-- ¡VALOR CORREGIDO!\n",
    "        'flow_rate': flow_rate,   # <-- VALOR CORREGIDO!\n",
    "        'is_wall_tube': is_wall_tube, \n",
    "        'bead_indices': (idx1, idx2)\n",
    "    })\n",
    "\n",
    "print(f\"\\n--- Proceso completado ---\")\n",
    "print(f\"Se encontraron {len(tube_list)} tubos válidos (width > 0, sin duplicados y dentro del ROI).\")\n",
    "\n",
    "df_tubos = pd.DataFrame(tube_list)\n",
    "print(\"\\nPrimeros 5 tubos encontrados:\")\n",
    "print(df_tubos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generando histogramas de distribución (con rango limitado por percentiles)...\")\n",
    "\n",
    "# 1. Preparar los datos\n",
    "flow_rates = df_tubos['flow_rate']\n",
    "half_widths = df_tubos['width'] * 0.5\n",
    "\n",
    "# 2. Calcular los límites del eje X basados en percentiles\n",
    "#    Por ejemplo, tomamos hasta el percentil 99.5 para excluir los valores más extremos.\n",
    "#    Puedes ajustar el percentil (e.g., 99, 99.9) si aún ves el problema.\n",
    "flow_rate_max_limit = np.percentile(flow_rates, 99.5)\n",
    "half_width_max_limit = np.percentile(half_widths, 99.5)\n",
    "\n",
    "# Asegurarse de que el límite mínimo sea 0 o muy cerca de 0\n",
    "flow_rate_min_limit = np.percentile(flow_rates, 0.5) if np.percentile(flow_rates, 0.5) > 0 else 0\n",
    "half_width_min_limit = np.percentile(half_widths, 0.5) if np.percentile(half_widths, 0.5) > 0 else 0\n",
    "\n",
    "# 3. Crear la figura con dos subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), dpi=100)\n",
    "\n",
    "# --- Histograma de Caudales (Flow Rates) ---\n",
    "# Definimos los bins dentro del rango limitado\n",
    "bins_flow_rates = np.linspace(flow_rate_min_limit, flow_rate_max_limit, 20) # Más bins para más detalle\n",
    "ax1.hist(flow_rates, bins=bins_flow_rates, color='royalblue', alpha=0.75, edgecolor='black')\n",
    "ax1.set_title(f'Distribución de Caudales (P<={flow_rate_max_limit:.2e})')\n",
    "ax1.set_xlabel('Caudal (m³/s)')\n",
    "ax1.set_ylabel('Frecuencia (Conteo)')\n",
    "#ax1.set_yscale('log')\n",
    "ax1.grid(True, linestyle=':', alpha=0.6)\n",
    "# Opcional: Establecer explícitamente los límites del eje X si np.linspace no lo hace perfecto\n",
    "# ax1.set_xlim(flow_rate_min_limit, flow_rate_max_limit)\n",
    "\n",
    "\n",
    "# --- Histograma de Mitad de Anchuras (Half-Widths) ---\n",
    "# Definimos los bins dentro del rango limitado\n",
    "bins_half_widths = np.linspace(half_width_min_limit, half_width_max_limit, 20) # Más bins para más detalle\n",
    "ax2.hist(half_widths, bins=bins_half_widths, color='forestgreen', alpha=0.75, edgecolor='black')\n",
    "ax2.set_title(f'Distribución de Mitad de Anchuras (P<={half_width_max_limit:.2e})')\n",
    "ax2.set_xlabel('Mitad de Anchura (m)')\n",
    "ax2.set_ylabel('Frecuencia (Conteo)')\n",
    "#ax2.set_yscale('log')\n",
    "ax2.grid(True, linestyle=':', alpha=0.6)\n",
    "# Opcional: Establecer explícitamente los límites del eje X\n",
    "# ax2.set_xlim(half_width_min_limit, half_width_max_limit)\n",
    "\n",
    "\n",
    "# 4. Mostrar el gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generando visualización de la Triangulación de Delaunay (Solo Ejes de Imagen)...\")\n",
    "\n",
    "# --- NUEVO: Crear mapa de Fantasma -> Padre Real ---\n",
    "# Necesitamos 'near_bottom_indices' y 'near_top_indices' de la celda anterior\n",
    "if 'near_bottom_indices' not in locals():\n",
    "    print(\"ERROR: Faltan datos de los granos fantasma. Ejecuta la celda de cálculo de tubos primero.\")\n",
    "else:\n",
    "    # Esta lista mapea el índice fantasma (relativo, empezando en 0) a su índice padre real\n",
    "    ghost_parent_index_map = np.hstack((near_bottom_indices, near_top_indices))\n",
    "    \n",
    "    # {indice_global_fantasma: indice_global_real_padre}\n",
    "    ghost_to_parent_dict = {}\n",
    "    for k, parent_real_idx in enumerate(ghost_parent_index_map):\n",
    "        ghost_global_idx = n_real_beads + k\n",
    "        ghost_to_parent_dict[ghost_global_idx] = parent_real_idx\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12), dpi=150)\n",
    "\n",
    "# 1. Dibujar los granos (círculos)\n",
    "for poly in final_circular_polygons:\n",
    "    # Optimizacion: no dibujar polígonos que estén completamente fuera del ROI\n",
    "    if poly.bounds[2] < roi_xmin or poly.bounds[0] > roi_xmax:\n",
    "        continue\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.3, fc='gray', ec='none', label='Granos' if 'Granos' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 2. Dibujar los centros (reales y fantasmas)\n",
    "# Filtramos centros que caen fuera del ROI en X\n",
    "real_centers_in_roi = centers[(centers[:, 0] >= roi_xmin) & (centers[:, 0] <= roi_xmax)]\n",
    "ax.scatter(real_centers_in_roi[:, 0], real_centers_in_roi[:, 1], c='blue', s=5, label='Centros Reales', zorder=5)\n",
    "\n",
    "ghost_centers = all_centers[n_real_beads:]\n",
    "ghost_centers_in_roi = ghost_centers[(ghost_centers[:, 0] >= roi_xmin) & (ghost_centers[:, 0] <= roi_xmax)]\n",
    "ax.scatter(ghost_centers_in_roi[:, 0], ghost_centers_in_roi[:, 1], \n",
    "           c='black', marker='x', s=15, label='Centros Fantasma', zorder=5)\n",
    "\n",
    "# 3. Dibujar los ejes de la triangulación (CON FILTRO)\n",
    "for idx1, idx2 in edges:\n",
    "    p1 = all_centers[idx1]\n",
    "    p2 = all_centers[idx2]\n",
    "    \n",
    "    # Optimización: no dibujar ejes que estén completamente fuera del ROI\n",
    "    if (p1[0] < roi_xmin and p2[0] < roi_xmin) or \\\n",
    "       (p1[0] > roi_xmax and p2[0] > roi_xmax):\n",
    "        continue\n",
    "\n",
    "    is_idx1_real = (idx1 < n_real_beads)\n",
    "    is_idx2_real = (idx2 < n_real_beads)\n",
    "    \n",
    "    if is_idx1_real and is_idx2_real:\n",
    "        # Eje real-real\n",
    "        ax.plot([p1[0], p2[0]], [p1[1], p2[1]], \n",
    "                color='gray', linestyle='--', linewidth=0.7, alpha=0.5,\n",
    "                label='Eje Real-Real' if 'Eje Real-Real' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "                \n",
    "    elif is_idx1_real and not is_idx2_real:\n",
    "        # Eje real-fantasma\n",
    "        real_idx, ghost_idx = idx1, idx2\n",
    "        if ghost_idx in ghost_to_parent_dict and real_idx == ghost_to_parent_dict[ghost_idx]:\n",
    "            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], \n",
    "                    color='red', linestyle='-', linewidth=1.0, alpha=0.8,\n",
    "                    label='Eje de Imagen (Real-Fantasma)' if 'Eje de Imagen (Real-Fantasma)' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "            \n",
    "    elif not is_idx1_real and is_idx2_real:\n",
    "        # Eje fantasma-real\n",
    "        real_idx, ghost_idx = idx2, idx1\n",
    "        if ghost_idx in ghost_to_parent_dict and real_idx == ghost_to_parent_dict[ghost_idx]:\n",
    "            ax.plot([p1[0], p2[0]], [p1[1], p2[1]], \n",
    "                    color='red', linestyle='-', linewidth=1.0, alpha=0.8,\n",
    "                    label='Eje de Imagen (Real-Fantasma)' if 'Eje de Imagen (Real-Fantasma)' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 4. Configuración del gráfico (CON LÍMITES MODIFICADOS)\n",
    "ax.set_aspect('equal')\n",
    "# --- LÍMITE X MODIFICADO ---\n",
    "ax.set_xlim(roi_xmin, roi_xmax) \n",
    "# --- LÍMITE Y SIN CAMBIOS (extendido para fantasmas) ---\n",
    "ax.set_ylim(ymin - reflection_dist * 0.5, ymax + reflection_dist * 0.5) \n",
    "\n",
    "ax.set_title(f\"Triangulación de Delaunay (ROI en X de {roi_xmin:.3f} a {roi_xmax:.3f})\")\n",
    "ax.set_xlabel(\"Coordenada X (m)\")\n",
    "ax.set_ylabel(\"Coordenada Y (m)\")\n",
    "ax.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Construyendo lista de junctions (Método Híbrido: Bulk + Pared)...\")\n",
    "\n",
    "# --- 0. Preparación ---\n",
    "\n",
    "# Asumimos que estas variables existen de celdas anteriores:\n",
    "# df_tubos_full: El DF de tubos SIN FILTRO ROI\n",
    "# tri: La triangulación de Delaunay original (sobre granos+fantasmas)\n",
    "# edges: El set de ejes de Delaunay\n",
    "# centers: Array (N,2) de centros de granos reales\n",
    "# n_real_beads: Número de granos reales\n",
    "# near_bottom_indices, near_top_indices: Arrays de índices de granos de borde\n",
    "# roi_xmin, roi_xmax: Límites del ROI\n",
    "\n",
    "# Función helper para tu lógica de ROI\n",
    "def is_in_roi(point):\n",
    "    return roi_xmin <= point[0] <= roi_xmax\n",
    "\n",
    "# Crear mapas de búsqueda desde la lista de tubos COMPLETA\n",
    "edge_to_tube_map_full = {} # Clave: (idx1, idx2), Valor: tube_id\n",
    "wall_tube_map = {}         # Clave: real_bead_idx, Valor: wall_tube_id\n",
    "\n",
    "print(\"Creando mapas de búsqueda de tubos (completos)...\")\n",
    "for tube_id, tube_data in df_tubos.iterrows():\n",
    "    idx1, idx2 = tube_data['bead_indices']\n",
    "    edge_key = tuple(sorted((idx1, idx2)))\n",
    "    \n",
    "    # Mapa de todos los ejes\n",
    "    edge_to_tube_map_full[edge_key] = tube_id\n",
    "    \n",
    "    # Mapa específico para tubos de pared\n",
    "    if tube_data['is_wall_tube']:\n",
    "        real_idx = idx1 if idx1 < n_real_beads else idx2\n",
    "        wall_tube_map[real_idx] = tube_id\n",
    "\n",
    "# Set de granos que tocan una pared (granos de \"borde\")\n",
    "real_border_bead_indices = set(near_bottom_indices) | set(near_top_indices)\n",
    "\n",
    "# Esta será nuestra nueva lista de junctions\n",
    "# Contendrá diccionarios para más estructura\n",
    "junctions_list_structured = []\n",
    "\n",
    "# --- 1. Calcular Junctions \"BULK\" ---\n",
    "print(\"Procesando junctions 'Bulk' (interiores)...\")\n",
    "\n",
    "for simplex in tri.simplices:\n",
    "    idx1, idx2, idx3 = simplex\n",
    "    \n",
    "    # Condición: Triángulo formado UNICAMENTE por granos reales\n",
    "    if not (idx1 < n_real_beads and idx2 < n_real_beads and idx3 < n_real_beads):\n",
    "        continue\n",
    "        \n",
    "    # Aplicar tu lógica de ROI\n",
    "    c1, c2, c3 = centers[idx1], centers[idx2], centers[idx3]\n",
    "    roi_count = sum(is_in_roi(c) for c in [c1, c2, c3])\n",
    "    \n",
    "    if roi_count == 0:\n",
    "        continue # Descartar (ningún grano en ROI)\n",
    "    \n",
    "    # Si roi_count > 0, guardamos la junction (tu Lógica 1 y 2)\n",
    "    j_coord = (c1 + c2 + c3) / 3.0\n",
    "    \n",
    "    # Encontrar los 3 tubos que la forman\n",
    "    edge1 = tuple(sorted((idx1, idx2)))\n",
    "    edge2 = tuple(sorted((idx2, idx3)))\n",
    "    edge3 = tuple(sorted((idx3, idx1)))\n",
    "    \n",
    "    tube_ids = [\n",
    "        edge_to_tube_map_full.get(edge1),\n",
    "        edge_to_tube_map_full.get(edge2),\n",
    "        edge_to_tube_map_full.get(edge3)\n",
    "    ]\n",
    "    \n",
    "    # Guardamos solo los tubos que existen (width > 0)\n",
    "    valid_tube_ids = [t_id for t_id in tube_ids if t_id is not None]\n",
    "    \n",
    "    if valid_tube_ids: # Solo guardar si tiene al menos un tubo válido\n",
    "        junctions_list_structured.append({\n",
    "            'coord': j_coord,\n",
    "            'tubes': valid_tube_ids,\n",
    "            'type': 'bulk'\n",
    "        })\n",
    "\n",
    "print(f\"Encontradas {len(junctions_list_structured)} junctions 'Bulk'.\")\n",
    "\n",
    "# --- 2. Calcular Junctions \"DE PARED\" ---\n",
    "print(\"Procesando junctions 'de Pared'...\")\n",
    "wall_junction_count = 0\n",
    "\n",
    "for idx1, idx2 in edges: # Iterar sobre *todos* los ejes de Delaunay\n",
    "    \n",
    "    # Condición: Ambos deben ser granos \"de borde\"\n",
    "    is_border1 = idx1 in real_border_bead_indices\n",
    "    is_border2 = idx2 in real_border_bead_indices\n",
    "    \n",
    "    if not (is_border1 and is_border2):\n",
    "        continue\n",
    "        \n",
    "    # Condición: Ambos centros deben estar DENTRO del ROI\n",
    "    c1, c2 = centers[idx1], centers[idx2]\n",
    "    if not (is_in_roi(c1) and is_in_roi(c2)):\n",
    "        continue\n",
    "        \n",
    "    # Si todo se cumple, encontrar los 3 tubos\n",
    "    \n",
    "    # Tubo 1: El que conecta los dos granos reales\n",
    "    tube_bulk_id = edge_to_tube_map_full.get(tuple(sorted((idx1, idx2))))\n",
    "    \n",
    "    # Tubo 2: El tubo de pared del grano 1\n",
    "    tube_wall1_id = wall_tube_map.get(idx1)\n",
    "    \n",
    "    # Tubo 3: El tubo de pared del grano 2\n",
    "    tube_wall2_id = wall_tube_map.get(idx2)\n",
    "    \n",
    "    # Asegurarse de que los 3 tubos existen (width > 0)\n",
    "    if tube_bulk_id is None or tube_wall1_id is None or tube_wall2_id is None:\n",
    "        continue\n",
    "        \n",
    "    # Calcular coordenadas de la junction\n",
    "    midpoint1 = df_tubos.loc[tube_wall1_id]['midpoint']\n",
    "    midpoint2 = df_tubos.loc[tube_wall2_id]['midpoint']\n",
    "    j_coord = (midpoint1 + midpoint2) / 2.0\n",
    "    \n",
    "    # Guardar la junction\n",
    "    junctions_list_structured.append({\n",
    "        'coord': j_coord,\n",
    "        'tubes': [tube_bulk_id, tube_wall1_id, tube_wall2_id],\n",
    "        'type': 'wall'\n",
    "    })\n",
    "    wall_junction_count += 1\n",
    "\n",
    "print(f\"Encontradas {wall_junction_count} junctions 'de Pared'.\")\n",
    "\n",
    "# --- 3. Resumen Final ---\n",
    "\n",
    "# Para mantener compatibilidad con tu código anterior,\n",
    "# creamos la 'junctions_list' solo con las listas de tubos.\n",
    "junctions_list = [j['tubes'] for j in junctions_list_structured]\n",
    "\n",
    "print(f\"\\n--- Proceso completado ---\")\n",
    "print(f\"Se han encontrado {len(junctions_list)} junctions totales (Bulk + Pared).\")\n",
    "\n",
    "# Analizar la \"coordinación\" (cuántos tubos por junction)\n",
    "junction_sizes = [len(j) for j in junctions_list]\n",
    "size_counts = Counter(junction_sizes)\n",
    "type_counts = Counter(j['type'] for j in junctions_list_structured)\n",
    "\n",
    "print(\"\\nDistribución por Tipo:\")\n",
    "for j_type, count in type_counts.items():\n",
    "    print(f\"  - Junctions de tipo '{j_type}': {count}\")\n",
    "\n",
    "print(\"\\nDistribución de tubos por junction:\")\n",
    "for size, count in sorted(size_counts.items()):\n",
    "    print(f\"  - Junctions con {size} tubos: {count}\")\n",
    "\n",
    "# (Opcional) Mostrar las primeras 5 junctions\n",
    "print(\"\\nEjemplo (primeras 5 junctions):\")\n",
    "for i, j_data in enumerate(junctions_list_structured[:5]):\n",
    "    print(f\"  Junction {i} (tipo {j_data['type']}): tubos {j_data['tubes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtrando la lista de tubos y las junctions por el ROI...\")\n",
    "\n",
    "# 1. Filtrar la lista principal de tubos (df_tubos)\n",
    "#    (El df_tubos actual es el 'full')\n",
    "midpoints = np.stack(df_tubos['midpoint'].values)\n",
    "in_roi_mask = (midpoints[:, 0] >= roi_xmin) & (midpoints[:, 0] <= roi_xmax)\n",
    "\n",
    "# Este es el nuevo DataFrame filtrado que querías\n",
    "df_tubos_roi = df_tubos[in_roi_mask].copy()\n",
    "\n",
    "print(f\"Lista de tubos filtrada: {len(df_tubos)} -> {len(df_tubos_roi)} tubos en ROI.\")\n",
    "\n",
    "# 2. Obtener los IDs (índices) de los tubos que SÍ están en el ROI\n",
    "valid_tube_ids = set(df_tubos_roi.index)\n",
    "\n",
    "# 3. Filtrar la lista de junctions (junctions_list_structured)\n",
    "junctions_list_filtered = []\n",
    "junctions_list_structured_filtered = []\n",
    "\n",
    "for junction in junctions_list_structured:\n",
    "    # Filtrar la lista de tubos de esta junction\n",
    "    filtered_tubes = [\n",
    "        tube_id for tube_id in junction['tubes'] \n",
    "        if tube_id in valid_tube_ids\n",
    "    ]\n",
    "    \n",
    "    # Opcional: No guardar junctions que se queden con < 2 tubos\n",
    "    # (una junction real debe conectar al menos 2 tubos)\n",
    "    if len(filtered_tubes) > 1:\n",
    "        new_junction_data = junction.copy()\n",
    "        new_junction_data['tubes'] = filtered_tubes\n",
    "        \n",
    "        junctions_list_structured_filtered.append(new_junction_data)\n",
    "        junctions_list_filtered.append(filtered_tubes)\n",
    "\n",
    "print(f\"Lista de junctions filtrada: {len(junctions_list_structured)} -> {len(junctions_list_structured_filtered)} junctions válidas.\")\n",
    "\n",
    "# 4. Reemplazar las variables viejas por las nuevas filtradas\n",
    "#    A partir de ahora, df_tubos y junctions_list estarán filtrados por el ROI.\n",
    "df_tubos = df_tubos_roi\n",
    "junctions_list = junctions_list_filtered\n",
    "junctions_list_structured = junctions_list_structured_filtered\n",
    "\n",
    "print(\"Variables 'df_tubos' y 'junctions_list' actualizadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Refinando la topología de la red (Manejando 'loose ends')...\")\n",
    "\n",
    "# Asumimos que 'df_tubos' y 'junctions_list_structured' ya están filtrados por el ROI.\n",
    "\n",
    "# --- 1. Contar apariciones de cada tubo en las junctions ---\n",
    "# Contamos cuántas junctions \"tocan\" cada tubo\n",
    "tube_appearance_count = Counter()\n",
    "for junction in junctions_list_structured:\n",
    "    for tube_id in junction['tubes']:\n",
    "        tube_appearance_count[tube_id] += 1\n",
    "\n",
    "# --- 2. Identificar \"loose ends\" y clasificarlos ---\n",
    "# (Tubos que aparecen 0 o 1 vez)\n",
    "\n",
    "new_junctions_to_add = []\n",
    "tubes_to_delete = set()\n",
    "\n",
    "# Definimos una tolerancia para los bordes (2% del ancho del ROI)\n",
    "roi_width = roi_xmax - roi_xmin\n",
    "tolerance = roi_width * 0.02\n",
    "left_boundary = roi_xmin + tolerance\n",
    "right_boundary = roi_xmax - tolerance\n",
    "\n",
    "print(f\"Definida tolerancia de borde en X: {tolerance:.4f} m\")\n",
    "\n",
    "# Iteramos sobre TODOS los tubos en nuestra lista filtrada por ROI\n",
    "for tube_id in df_tubos.index:\n",
    "    count = tube_appearance_count.get(tube_id, 0)\n",
    "    \n",
    "    # Buscamos tubos con 0 o 1 conexión\n",
    "    if count == 0 or count == 1:\n",
    "        \n",
    "        # Es un \"loose end\". Creamos una junction candidata.\n",
    "        midpoint = df_tubos.loc[tube_id]['midpoint']\n",
    "        j_coord = midpoint\n",
    "        \n",
    "        # Comprobar si es un inlet/outlet (cerca del borde)\n",
    "        is_near_left = (j_coord[0] <= left_boundary)\n",
    "        is_near_right = (j_coord[0] >= right_boundary)\n",
    "        \n",
    "        if is_near_left or is_near_right:\n",
    "            # Es un inlet/outlet VÁLIDO.\n",
    "            # Creamos la nueva junction de 1 tubo.\n",
    "            new_junctions_to_add.append({\n",
    "                'coord': j_coord,\n",
    "                'tubes': [tube_id],\n",
    "                'type': 'outlet' # Nueva categoría\n",
    "            })\n",
    "        else:\n",
    "            # Es un \"dangling tube\" INVÁLIDO (en medio del bulk).\n",
    "            # Lo marcamos para borrar.\n",
    "            tubes_to_delete.add(tube_id)\n",
    "\n",
    "print(f\"Identificados {len(new_junctions_to_add)} tubos de inlet/outlet.\")\n",
    "print(f\"Identificados {len(tubes_to_delete)} tubos 'dangling' internos para borrar.\")\n",
    "\n",
    "# --- 3. Filtrar las listas (¡El paso clave!) ---\n",
    "\n",
    "# 3.1. Eliminar los tubos 'dangling' de la lista principal\n",
    "df_tubos_final = df_tubos.drop(index=list(tubes_to_delete))\n",
    "\n",
    "# 3.2. Filtrar la lista de junctions existente\n",
    "final_junctions_structured = []\n",
    "for junction in junctions_list_structured:\n",
    "    \n",
    "    # Re-crear la lista de tubos de la junction,\n",
    "    # omitiendo los que marcamos para borrar\n",
    "    new_tube_list = [\n",
    "        t_id for t_id in junction['tubes'] \n",
    "        if t_id not in tubes_to_delete\n",
    "    ]\n",
    "    \n",
    "    # Solo mantenemos la junction si todavía tiene tubos\n",
    "    if len(new_tube_list) > 0:\n",
    "        junction['tubes'] = new_tube_list\n",
    "        final_junctions_structured.append(junction)\n",
    "\n",
    "# 3.3. Añadir las nuevas junctions de inlet/outlet\n",
    "final_junctions_structured.extend(new_junctions_to_add)\n",
    "\n",
    "# --- 4. Reemplazar las variables globales ---\n",
    "\n",
    "df_tubos = df_tubos_final\n",
    "junctions_list_structured = final_junctions_structured\n",
    "junctions_list = [j['tubes'] for j in junctions_list_structured] # Regenerar la lista simple\n",
    "\n",
    "print(f\"\\n--- Limpieza completada ---\")\n",
    "print(f\"Lista final de tubos: {len(df_tubos)}\")\n",
    "print(f\"Lista final de junctions: {len(junctions_list)}\")\n",
    "\n",
    "# (Opcional) Ver la nueva distribución de tipos\n",
    "final_type_counts = Counter(j['type'] for j in junctions_list_structured)\n",
    "print(\"\\nNueva distribución de tipos de Junction:\")\n",
    "for j_type, count in final_type_counts.items():\n",
    "    print(f\"  - Junctions de tipo '{j_type}': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "print(\"Iniciando filtro final de 'border-to-border'...\")\n",
    "\n",
    "# --- 1. Identificar Junctions de Borde ---\n",
    "\n",
    "# (Asumimos que 'junctions_list_structured', 'df_tubos', 'roi_xmin', 'roi_xmax' existen)\n",
    "\n",
    "# Re-definimos la tolerancia (igual que en la celda anterior)\n",
    "roi_width = roi_xmax - roi_xmin\n",
    "tolerance = roi_width * 0.02\n",
    "left_boundary = roi_xmin + tolerance\n",
    "right_boundary = roi_xmax - tolerance\n",
    "\n",
    "# Guardamos los ÍNDICES de la lista 'junctions_list_structured'\n",
    "border_junction_indices = set()\n",
    "print(f\"Marcando junctions 'de borde' (tolerancia X: {tolerance:.4f} m)...\")\n",
    "\n",
    "for j_index, junction in enumerate(junctions_list_structured):\n",
    "    coord = junction['coord']\n",
    "    if coord[0] <= left_boundary or coord[0] >= right_boundary:\n",
    "        border_junction_indices.add(j_index)\n",
    "\n",
    "print(f\"Se identificaron {len(border_junction_indices)} junctions 'de borde'.\")\n",
    "\n",
    "# --- 2. Crear mapa Inverso (Tubo -> Junctions) ---\n",
    "# Necesitamos saber qué dos junctions conecta cada tubo\n",
    "\n",
    "# (Usamos 'junctions_list_structured' y 'df_tubos' actuales)\n",
    "tube_to_junctions_map = {tube_id: [] for tube_id in df_tubos.index}\n",
    "\n",
    "for j_index, junction in enumerate(junctions_list_structured):\n",
    "    for tube_id in junction['tubes']:\n",
    "        # Asegurarnos de que el tubo existe en el mapa (no debería fallar)\n",
    "        if tube_id in tube_to_junctions_map:\n",
    "            tube_to_junctions_map[tube_id].append(j_index)\n",
    "\n",
    "# --- 3. Identificar Tubos \"Border-to-Border\" ---\n",
    "tubes_to_delete_b2b = set()\n",
    "\n",
    "for tube_id, connected_junction_indices in tube_to_junctions_map.items():\n",
    "    \n",
    "    # Solo nos interesan los tubos que conectan EXACTAMENTE 2 junctions\n",
    "    if len(connected_junction_indices) == 2:\n",
    "        j_idx_1 = connected_junction_indices[0]\n",
    "        j_idx_2 = connected_junction_indices[1]\n",
    "        \n",
    "        # Si AMBAS junctions son \"de borde\", marcamos el tubo para borrar\n",
    "        if j_idx_1 in border_junction_indices and j_idx_2 in border_junction_indices:\n",
    "            tubes_to_delete_b2b.add(tube_id)\n",
    "\n",
    "print(f\"Se identificaron {len(tubes_to_delete_b2b)} tubos 'border-to-border' para eliminar.\")\n",
    "\n",
    "# --- 4. Aplicar Filtros y Limpiar ---\n",
    "\n",
    "# 4.1. Eliminar los tubos del DataFrame principal\n",
    "df_tubos_final_b2b = df_tubos.drop(index=list(tubes_to_delete_b2b))\n",
    "\n",
    "# 4.2. Filtrar la lista de junctions (eliminando tubos y junctions vacías)\n",
    "final_junctions_structured_b2b = []\n",
    "for j_index, junction in enumerate(junctions_list_structured):\n",
    "    \n",
    "    # Recrear la lista de tubos de la junction,\n",
    "    # omitiendo los que acabamos de borrar\n",
    "    new_tube_list = [\n",
    "        t_id for t_id in junction['tubes'] \n",
    "        if t_id not in tubes_to_delete_b2b\n",
    "    ]\n",
    "    \n",
    "    # Si la junction se ha quedado sin tubos, la eliminamos\n",
    "    if len(new_tube_list) > 0:\n",
    "        junction['tubes'] = new_tube_list\n",
    "        final_junctions_structured_b2b.append(junction)\n",
    "\n",
    "# --- 5. Reemplazar las variables globales ---\n",
    "df_tubos = df_tubos_final_b2b\n",
    "junctions_list_structured = final_junctions_structured_b2b\n",
    "junctions_list = [j['tubes'] for j in junctions_list_structured] # Regenerar la lista simple\n",
    "\n",
    "# --- 6. (NUEVO) Re-calcular border_junction_indices ---\n",
    "# (Porque la lista ha cambiado de tamaño y los índices se han desplazado)\n",
    "print(\"Re-calculando el set 'border_junction_indices' final...\")\n",
    "border_junction_indices = set()\n",
    "for j_index, junction in enumerate(junctions_list_structured):\n",
    "    coord = junction['coord']\n",
    "    if coord[0] <= left_boundary or coord[0] >= right_boundary:\n",
    "        border_junction_indices.add(j_index)\n",
    "\n",
    "print(f\"\\n--- Filtro 'border-to-border' completado ---\")\n",
    "print(f\"Lista final de tubos: {len(df_tubos)}\")\n",
    "print(f\"Lista final de junctions: {len(junctions_list)}\")\n",
    "print(f\"Set de junctions de borde actualizado a {len(border_junction_indices)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Generando visualización de la Red de Poros (Junctions y Tubos)...\")\n",
    "\n",
    "# Asumimos que 'final_circular_polygons', 'df_tubos', \n",
    "# 'junctions_list_structured', 'roi_xmin', 'roi_xmax', \n",
    "# 'ymin', 'ymax' están definidos y filtrados.\n",
    "\n",
    "# 1. Crear un mapa de búsqueda para los midpoints de los tubos\n",
    "#    (Usamos el df_tubos ya filtrado por el ROI)\n",
    "tube_midpoints_map = {idx: row['midpoint'] for idx, row in df_tubos.iterrows()}\n",
    "\n",
    "# 2. Crear la figura con alta resolución\n",
    "fig, ax = plt.subplots(figsize=(14, 14), dpi=200) # <-- DPI elevado\n",
    "\n",
    "# 3. Dibujar los granos (círculos) en el fondo\n",
    "for poly in final_circular_polygons:\n",
    "    # Optimización: no dibujar polígonos que estén completamente fuera del ROI\n",
    "    if poly.bounds[2] < roi_xmin or poly.bounds[0] > roi_xmax:\n",
    "        continue\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.3, fc='gray', ec='none', label='Granos' if 'Granos' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 4. Preparar listas para dibujar las junctions y conexiones\n",
    "junction_coords = []\n",
    "connection_lines = [] # Lista de [[x_j, y_j], [x_t, y_t]]\n",
    "\n",
    "# Iteramos sobre la lista estructurada, que tiene las coordenadas\n",
    "for junction in junctions_list_structured:\n",
    "    j_center = junction['coord']\n",
    "    tube_ids = junction['tubes']\n",
    "    \n",
    "    # Guardamos el centro de la junction\n",
    "    junction_coords.append(j_center)\n",
    "    \n",
    "    # Guardamos las líneas de conexión\n",
    "    for tube_id in tube_ids:\n",
    "        # Buscamos el midpoint del tubo (debería existir, ya que todo está filtrado)\n",
    "        midpoint = tube_midpoints_map.get(tube_id)\n",
    "        if midpoint is not None:\n",
    "            connection_lines.append([j_center, midpoint])\n",
    "\n",
    "# 5. Dibujar las conexiones (líneas verdes)\n",
    "for line in connection_lines:\n",
    "    p_junction = line[0]\n",
    "    p_midpoint = line[1]\n",
    "    ax.plot([p_junction[0], p_midpoint[0]], [p_junction[1], p_midpoint[1]], \n",
    "            color='lime', linestyle='-', linewidth=1.0, alpha=0.8, zorder=8,\n",
    "            label='Conexión Junction-Tubo' if 'Conexión Junction-Tubo' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 6. Dibujar los centros de las junctions (puntos morados)\n",
    "if junction_coords:\n",
    "    junction_coords_np = np.array(junction_coords)\n",
    "    ax.scatter(junction_coords_np[:, 0], junction_coords_np[:, 1], \n",
    "               color='purple', \n",
    "               s=10,  # <-- Puntos pequeños\n",
    "               marker='o', \n",
    "               zorder=10, \n",
    "               label='Centro de Junction' if 'Centro de Junction' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 7. Configuración del gráfico\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax) # <-- Usamos los límites físicos (sin fantasmas)\n",
    "ax.set_title(f\"Red de Poros Final (Junctions y Tubos en ROI)\")\n",
    "ax.set_xlabel(\"Coordenada X (m)\")\n",
    "ax.set_ylabel(\"Coordenada Y (m)\")\n",
    "ax.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Visualización completada. {len(junction_coords)} junctions en el ROI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Pre-calculando direcciones de tubos y flujos In/Out...\")\n",
    "\n",
    "# --- 1. Mapas de búsqueda (si no existen) ---\n",
    "if 'tube_flow_map' not in locals():\n",
    "    tube_flow_map = {idx: row['flow_rate'] for idx, row in df_tubos.iterrows()}\n",
    "\n",
    "# Mapa de tubos -> [junction_idx_A, junction_idx_B]\n",
    "tube_to_junctions_map = {tube_id: [] for tube_id in df_tubos.index}\n",
    "for j_index, junction_tubes in enumerate(junctions_list):\n",
    "    for tube_id in junction_tubes:\n",
    "        if tube_id in tube_to_junctions_map:\n",
    "            tube_to_junctions_map[tube_id].append(j_index)\n",
    "\n",
    "# --- 2. Calcular la dirección de CADA tubo ---\n",
    "# (Usando la lógica de la Tangente Orientada)\n",
    "tube_direction_map = {} # {tube_id: (j_initial_id, j_final_id)}\n",
    "print(\"Calculando dirección de flujo para todos los tubos...\")\n",
    "\n",
    "for tube_id, tube_data in df_tubos.iterrows():\n",
    "    \n",
    "    # 2.1. Encontrar las dos junctions del tubo\n",
    "    junction_indices = tube_to_junctions_map.get(tube_id, [])\n",
    "    if len(junction_indices) != 2:\n",
    "        continue # Omitir tubos sin 2 junctions (no debería pasar)\n",
    "        \n",
    "    j_idx_A, j_idx_B = junction_indices\n",
    "    j_coord_A = junctions_list_structured[j_idx_A]['coord']\n",
    "    j_coord_B = junctions_list_structured[j_idx_B]['coord']\n",
    "\n",
    "    # 2.2. Recalcular geometría (para obtener n_vec_path)\n",
    "    idx1, idx2 = tube_data['bead_indices']\n",
    "    is_wall_tube = tube_data['is_wall_tube']\n",
    "    width = tube_data['width']\n",
    "    \n",
    "    if is_wall_tube:\n",
    "        real_idx = idx1 if idx1 < n_real_beads else idx2\n",
    "        c_real = centers[real_idx]; r_real = radii[real_idx]\n",
    "        is_top_wall = c_real[1] > (ymax + ymin) / 2.0\n",
    "        if is_top_wall:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] + r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymax])\n",
    "            n_vec_path = np.array([0.0, 1.0])\n",
    "        else:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] - r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymin])\n",
    "            n_vec_path = np.array([0.0, -1.0])\n",
    "    else:\n",
    "        c1, c2 = all_centers[idx1], all_centers[idx2]\n",
    "        r1, r2 = all_radii[idx1], all_radii[idx2]\n",
    "        center_vec = c2 - c1; dist = np.linalg.norm(center_vec)\n",
    "        n_vec_path = center_vec / dist\n",
    "        p_edge_wall = c1 + n_vec_path * r1\n",
    "        p_edge_bead = c2 - n_vec_path * r2\n",
    "        \n",
    "    # 2.3. Calcular Tangente Orientada\n",
    "    n_vec_flow_initial = np.array([-n_vec_path[1], n_vec_path[0]])\n",
    "    t_oriented = n_vec_flow_initial \n",
    "\n",
    "    if tree is not None and width > 1e-9:\n",
    "        sample_points_2d = np.linspace(p_edge_wall, p_edge_bead, N_SAMPLES)\n",
    "        dists, idxs = tree.query(sample_points_2d, k=1)\n",
    "        velocities_2d = U_cells[idxs]\n",
    "        velocities_2d = np.nan_to_num(velocities_2d, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        proj_mean = np.dot(velocities_2d, n_vec_flow_initial).mean()\n",
    "        sign = np.sign(proj_mean) if np.sign(proj_mean) != 0 else 1.0\n",
    "        t_oriented = n_vec_flow_initial * sign\n",
    "    \n",
    "    # 2.4. Determinar junction Inicial y Final\n",
    "    midpoint = tube_data['midpoint'] \n",
    "    vec_m_to_A = j_coord_A - midpoint\n",
    "    dp_A = t_oriented.dot(vec_m_to_A)\n",
    "    \n",
    "    if dp_A > 0:\n",
    "        j_initial_id, j_final_id = j_idx_B, j_idx_A\n",
    "    else:\n",
    "        j_initial_id, j_final_id = j_idx_A, j_idx_B\n",
    "        \n",
    "    # Guardar el resultado\n",
    "    tube_direction_map[tube_id] = (j_initial_id, j_final_id)\n",
    "\n",
    "print(f\"Dirección calculada para {len(tube_direction_map)} tubos.\")\n",
    "\n",
    "# --- 3. Calcular Flujos In/Out para CADA junction ---\n",
    "print(\"Calculando flujos In/Out por junction...\")\n",
    "\n",
    "# Inicializar mapas con ceros para todas las junctions\n",
    "junction_flow_in = {j: 0.0 for j in range(len(junctions_list_structured))}\n",
    "junction_flow_out = {j: 0.0 for j in range(len(junctions_list_structured))}\n",
    "\n",
    "# Llenar los mapas\n",
    "for tube_id, (j_initial, j_final) in tube_direction_map.items():\n",
    "    flow = tube_flow_map.get(tube_id, 0.0)\n",
    "    \n",
    "    # Sumar al Out de la junction inicial\n",
    "    junction_flow_out[j_initial] += flow\n",
    "    \n",
    "    # Sumar al In de la junction final\n",
    "    junction_flow_in[j_final] += flow\n",
    "\n",
    "print(\"Pre-cálculo completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Generando gráficos 'Flow In' vs 'Flow Out' para cada junction...\")\n",
    "\n",
    "# --- Usamos los mapas pre-calculados 'junction_flow_in' y 'junction_flow_out' ---\n",
    "\n",
    "all_flow_in = []\n",
    "all_flow_out = []\n",
    "\n",
    "# Iteramos sobre todas las junctions\n",
    "for junction_id in range(len(junctions_list_structured)):\n",
    "    \n",
    "    # Ignorar junctions de borde (inlets/outlets)\n",
    "    if junction_id in border_junction_indices:\n",
    "        continue\n",
    "        \n",
    "    all_flow_in.append(junction_flow_in[junction_id])\n",
    "    all_flow_out.append(junction_flow_out[junction_id])\n",
    "\n",
    "# 3. Convertir a arrays de NumPy\n",
    "flow_in_np = np.array(all_flow_in)\n",
    "flow_out_np = np.array(all_flow_out)\n",
    "\n",
    "print(f\"Cálculo completado para {len(flow_in_np)} junctions internas.\")\n",
    "\n",
    "# --- 4. Generar Gráficos ---\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7), dpi=100)\n",
    "\n",
    "# --- Gráfico 1: Scatter Plot (Flow Out vs Flow In) ---\n",
    "\n",
    "# Calcular un límite visual\n",
    "if len(flow_in_np) > 0:\n",
    "    combined_max = np.percentile(np.hstack((flow_in_np, flow_out_np)), 99.5)\n",
    "    if combined_max == 0: \n",
    "        combined_max = np.max(np.hstack((flow_in_np, flow_out_np)))\n",
    "else:\n",
    "    combined_max = 1.0 # Valor por defecto\n",
    "\n",
    "ax1.scatter(flow_out_np, flow_in_np, alpha=0.4, s=10, label='Junctions Internas')\n",
    "ax1.plot([0, combined_max], [0, combined_max], 'r--', linewidth=2, label='Recta y=x')\n",
    "ax1.set_xlabel('Flow Out (m³/s)') # <-- ETIQUETA CAMBIADA\n",
    "ax1.set_ylabel('Flow In (m³/s)')  # <-- ETIQUETA CAMBIADA\n",
    "ax1.set_title('Conservación de Caudal (Junctions Internas)')\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlim(0, combined_max)\n",
    "ax1.set_ylim(0, combined_max)\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle=':', alpha=0.6)\n",
    "\n",
    "# --- Gráfico 2: PDF Normalizadas ---\n",
    "\n",
    "bins = np.linspace(0, combined_max, 50)\n",
    "\n",
    "ax2.hist(flow_out_np, bins=bins, density=True, alpha=0.7, color='blue', label='PDF Flow Out') # <-- ETIQUETA CAMBIADA\n",
    "ax2.hist(flow_in_np, bins=bins, density=True, alpha=0.7, color='red', label='PDF Flow In')   # <-- ETIQUETA CAMBIADA\n",
    "ax2.set_xlabel('Caudal (m³/s)')\n",
    "ax2.set_ylabel('Densidad de Probabilidad (Normalizada)')\n",
    "ax2.set_title('Distribución de Caudales (Junctions Internas)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle=':', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Identificando y visualizando junctions outliers...\")\n",
    "\n",
    "# --- 1. Re-identificar Outliers (mismo código de antes) ---\n",
    "#    (Pero esta vez guardamos los datos de la junction)\n",
    "    \n",
    "RELATIVE_TOLERANCE = 0.96 \n",
    "ABSOLUTE_TOLERANCE = 1e-12 \n",
    "\n",
    "# Asumimos que 'junctions_list_structured' y 'tube_flow_map' existen\n",
    "outlier_junctions_data = [] # <-- Lista para guardar los datos\n",
    "\n",
    "for junction in junctions_list_structured:\n",
    "    \n",
    "    if junction_id in border_junction_indices:\n",
    "        continue\n",
    "\n",
    "    tube_id_list = junction['tubes']\n",
    "    flows = [tube_flow_map[t_id] for t_id in tube_id_list if t_id in tube_flow_map]\n",
    "    \n",
    "    if len(flows) <= 1:\n",
    "        continue\n",
    "    \n",
    "    flow_big = max(flows)\n",
    "    flow_smalls = sum(flows) - flow_big\n",
    "    \n",
    "    # Si es un outlier, guardamos la junction entera (que tiene 'coord' y 'tubes')\n",
    "    if flow_big > ABSOLUTE_TOLERANCE and flow_smalls < (flow_big * RELATIVE_TOLERANCE):\n",
    "        outlier_junctions_data.append(junction)\n",
    "\n",
    "print(f\"Se encontraron {len(outlier_junctions_data)} junctions outliers para visualizar.\")\n",
    "\n",
    "# --- 2. Crear la Visualización ---\n",
    "# (Asumimos que 'final_circular_polygons', 'roi_xmin', 'roi_xmax', 'ymin', 'ymax' existen)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 14), dpi=150)\n",
    "\n",
    "# 2.1. Dibujar los granos (fondo)\n",
    "for poly in final_circular_polygons:\n",
    "    # Optimización de dibujado\n",
    "    if poly.bounds[2] < roi_xmin or poly.bounds[0] > roi_xmax:\n",
    "        continue\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.3, fc='gray', ec='none', label='Granos' if 'Granos' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 2.2. Preparar listas para dibujar las junctions y conexiones OUTLIER\n",
    "outlier_centers_coords = []\n",
    "outlier_connection_lines = [] # Lista de [[x_j, y_j], [x_t, y_t]]\n",
    "\n",
    "for junction in outlier_junctions_data:\n",
    "    j_center = junction['coord']\n",
    "    tube_ids = junction['tubes']\n",
    "    \n",
    "    outlier_centers_coords.append(j_center)\n",
    "    \n",
    "    for tube_id in tube_ids:\n",
    "        midpoint = tube_midpoints_map.get(tube_id) # Usamos el mapa de la celda anterior\n",
    "        if midpoint is not None:\n",
    "            outlier_connection_lines.append([j_center, midpoint])\n",
    "\n",
    "# 2.3. Dibujar las conexiones (líneas rojas)\n",
    "for line in outlier_connection_lines:\n",
    "    p_junction = line[0]\n",
    "    p_midpoint = line[1]\n",
    "    ax.plot([p_junction[0], p_midpoint[0]], [p_junction[1], p_midpoint[1]], \n",
    "            color='red', linestyle='-', linewidth=2.0, alpha=1.0, zorder=10,\n",
    "            label='Conexión Outlier' if 'Conexión Outlier' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 2.4. Dibujar los centros de las junctions (círculos rojos)\n",
    "if outlier_centers_coords:\n",
    "    coords_np = np.array(outlier_centers_coords)\n",
    "    ax.scatter(coords_np[:, 0], coords_np[:, 1], \n",
    "               color='red', \n",
    "               s=30,  # <-- Puntos más grandes para verlos bien\n",
    "               marker='o', \n",
    "               edgecolor='black', # Borde negro para destacar\n",
    "               zorder=12, \n",
    "               label='Junction Outlier' if 'Junction Outlier' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 2.5. Configuración del gráfico\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(roi_xmin, roi_xmax)\n",
    "ax.set_ylim(ymin, ymax) \n",
    "ax.set_title(f\"Visualización de Junctions con Desbalance de Caudal ({len(outlier_junctions_data)} outliers)\")\n",
    "ax.set_xlabel(\"Coordenada X (m)\")\n",
    "ax.set_ylabel(\"Coordenada Y (m)\")\n",
    "ax.axvline(x=left_boundary, color='cyan', linestyle=':', linewidth=2, label='Límite de Borde')\n",
    "ax.axvline(x=right_boundary, color='cyan', linestyle=':', linewidth=2)\n",
    "ax.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Iniciando la exportación de la red a archivos...\")\n",
    "\n",
    "# --- Asumimos que estas variables existen de las celdas anteriores ---\n",
    "# df_tubos, junctions_list_structured, junction_coords, output_array\n",
    "# tube_direction_map (¡NUEVO!)\n",
    "# junction_flow_out (¡NUEVO!)\n",
    "# tube_flow_map (¡NUEVO!)\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "# --- 1. Guardar \"junction_coordinates.txt\" (CON NODE ID) ---\n",
    "# (Esta parte no cambia)\n",
    "print(\"Guardando junction_coordinates.txt...\")\n",
    "if 'output_array' not in locals():\n",
    "    junction_coords = np.array([j['coord'] for j in junctions_list_structured])\n",
    "    node_ids = np.arange(len(junction_coords))\n",
    "    node_ids_col = node_ids.reshape(-1, 1)\n",
    "    output_array = np.hstack((node_ids_col, junction_coords))\n",
    "\n",
    "np.savetxt(\n",
    "    \"junction_coordinates.txt\", \n",
    "    output_array, \n",
    "    fmt=['%d', '%.8f', '%.8f'],\n",
    "    comments=\"\"\n",
    ")\n",
    "\n",
    "# --- 2. Preparaciones para \"junction_links.txt\" ---\n",
    "# (Esta sección se simplifica enormemente)\n",
    "print(\"Preparando mapas para links...\")\n",
    "# Todos los mapas complejos (tube_direction_map, junction_flow_out, etc.)\n",
    "# ya han sido calculados en la celda anterior.\n",
    "\n",
    "# --- ¡NUEVO! PRE-CÁLCULO PARA NODOS ESTANCADOS ---\n",
    "# Identificar nodos con flujo saliente CERO y contar sus salidas topológicas\n",
    "print(\"Pre-calculando salidas para nodos estancados...\")\n",
    "stagnation_node_out_counts = {}\n",
    "\n",
    "# 1. Encontrar todos los nodos estancados (flow_out <= 1e-12)\n",
    "stagnation_node_ids = set()\n",
    "for j_index in range(len(junctions_list_structured)):\n",
    "    # Usamos el umbral para ser consistentes\n",
    "    if junction_flow_out.get(j_index, 0.0) <= 1e-12:\n",
    "        stagnation_node_ids.add(j_index)\n",
    "\n",
    "# 2. Contar las salidas TOPOLÓGICAS (cuántos tubos salen de ellos)\n",
    "#    (Inicializar contador a 0 para todos los nodos)\n",
    "node_out_link_count = {j_id: 0 for j_id in range(len(junctions_list_structured))}\n",
    "for tube_id, (j_init, j_fin) in tube_direction_map.items():\n",
    "    # Usamos .get() para no fallar si j_init no estuviera (aunque debería)\n",
    "    if j_init in node_out_link_count:\n",
    "        node_out_link_count[j_init] += 1\n",
    "\n",
    "# 3. Guardar el recuento final SOLO para los nodos estancados\n",
    "for j_id in stagnation_node_ids:\n",
    "    stagnation_node_out_counts[j_id] = node_out_link_count.get(j_id, 0)\n",
    "\n",
    "print(f\"Encontrados {len(stagnation_node_out_counts)} nodos estancados con salidas topológicas.\")\n",
    "# --- FIN DEL NUEVO BLOQUE ---\n",
    "\n",
    "# --- 3. Recorrer tubos y generar links ---\n",
    "print(\"Generando links...\")\n",
    "links_data = []\n",
    "\n",
    "# Iteramos sobre el mapa de direcciones que ya calculamos\n",
    "for tube_id, (j_initial_id, j_final_id) in tube_direction_map.items():\n",
    "    \n",
    "    flow_this_tube = tube_flow_map.get(tube_id, 0.0)\n",
    "    flow_out_initial = junction_flow_out.get(j_initial_id, 0.0)\n",
    "    \n",
    "    weight = 0.0\n",
    "    \n",
    "    if flow_out_initial > 1e-12:\n",
    "        # --- Caso 1: Flujo Normal ---\n",
    "        # El nodo NO está estancado. Usamos la fracción de flujo real.\n",
    "        weight = flow_this_tube / flow_out_initial\n",
    "        weight = min(weight, 1.0) # Asegurarse de que no sea > 1\n",
    "    \n",
    "    else:\n",
    "        # --- Caso 2: Nodo Estancado (flow_out_initial es 0) ---\n",
    "        # j_initial_id es un nodo estancado. Debemos asignar pesos\n",
    "        # de forma equiprobable.\n",
    "        N_out = stagnation_node_out_counts.get(j_initial_id, 0)\n",
    "        \n",
    "        if N_out > 0:\n",
    "            # Asignar peso equiprobable 1/N\n",
    "            weight = 1.0 / N_out\n",
    "        else:\n",
    "            # Este nodo no tiene salidas topológicas,\n",
    "            # el peso es 0 (y este link no debería existir,\n",
    "            # pero lo manejamos por si acaso)\n",
    "            weight = 0.0\n",
    "\n",
    "    # --- Filtro Final ---\n",
    "    # Guardamos el link si el peso es significativo.\n",
    "    # Esto incluye los links (peso > 0) del Caso 1\n",
    "    # Y los links (peso = 1/N > 0) del Caso 2.\n",
    "    # Solo filtra los links con flow_this_tube = 0 del Caso 1.\n",
    "    if weight > 1e-9:\n",
    "        links_data.append([j_initial_id, j_final_id, weight])\n",
    "\n",
    "# --- 4. Guardar \"junction_links.txt\" ---\n",
    "# (Tu código np.savetxt va aquí...)\n",
    "# --- 4. Guardar \"junction_links.txt\" ---\n",
    "print(\"Guardando junction_links.txt...\")\n",
    "links_array = np.array(links_data)\n",
    "np.savetxt(\n",
    "    \"junction_links.txt\",\n",
    "    links_array,\n",
    "    fmt=['%d', '%d', '%.8f'], # [int, int, float]\n",
    "    comments=\"\"\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Exportación completada ---\")\n",
    "print(f\"Se guardaron {len(output_array)} coordenadas.\")\n",
    "print(f\"Se guardaron {len(links_array)} links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Generando visualización de la red con flechas de flujo...\")\n",
    "\n",
    "# --- 1. Cargar datos (si no están ya en memoria) ---\n",
    "# (Normalmente no es necesario si acabas de ejecutar la celda anterior)\n",
    "\n",
    "if 'links_array' not in locals():\n",
    "    print(\"Cargando 'junction_links.txt'...\")\n",
    "    links_array = np.loadtxt(\"junction_links.txt\", skiprows=1)\n",
    "\n",
    "if 'junction_coords' not in locals():\n",
    "    print(\"Cargando 'junction_coordinates.txt'...\")\n",
    "    # Cargamos el archivo de coordenadas\n",
    "    junction_coords_file_data = np.loadtxt(\"junction_coordinates.txt\", skiprows=1)\n",
    "    # Creamos el mapa de ID -> [x, y]\n",
    "    j_coords_map = {int(row[0]): row[1:] for row in junction_coords_file_data}\n",
    "else:\n",
    "    # Si ya existe el array 'output_array' de la celda anterior\n",
    "    j_coords_map = {int(row[0]): row[1:] for row in output_array}\n",
    "\n",
    "# --- 2. Preparar datos para las flechas (Quiver) ---\n",
    "\n",
    "# Obtenemos los midpoints EN ORDEN\n",
    "# (Asumimos que el orden de df_tubos no ha cambiado desde que se creó links_array)\n",
    "if len(df_tubos) != len(links_array):\n",
    "    print(\"¡ADVERTENCIA! El número de tubos y de links no coincide.\")\n",
    "    print(\"Asegúrate de ejecutar la celda de exportación justo antes que esta.\")\n",
    "\n",
    "midpoints = np.stack(df_tubos['midpoint'].values)\n",
    "U = np.zeros(len(links_array)) # Componente X del vector\n",
    "V = np.zeros(len(links_array)) # Componente Y del vector\n",
    "\n",
    "# Calculamos el vector de dirección para cada tubo\n",
    "for i in range(len(links_array)):\n",
    "    link = links_array[i]\n",
    "    j_initial_id = int(link[0])\n",
    "    j_final_id = int(link[1])\n",
    "    \n",
    "    # Obtenemos las coordenadas de las junctions\n",
    "    coord_initial = j_coords_map[j_initial_id]\n",
    "    coord_final = j_coords_map[j_final_id]\n",
    "    \n",
    "    # Calculamos el vector (final - inicial)\n",
    "    vector = coord_final - coord_initial\n",
    "    U[i] = vector[0]\n",
    "    V[i] = vector[1]\n",
    "\n",
    "# Normalizamos los vectores para que sean unitarios\n",
    "norms = np.linalg.norm(np.vstack((U, V)), axis=0)\n",
    "norms[norms == 0] = 1.0 # Evitar división por cero\n",
    "U_norm = U / norms\n",
    "V_norm = V / norms\n",
    "\n",
    "# --- 3. Generar la visualización ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 14), dpi=400)\n",
    "\n",
    "# 3.1. Dibujar los granos (fondo)\n",
    "for poly in final_circular_polygons:\n",
    "    if poly.bounds[2] < roi_xmin or poly.bounds[0] > roi_xmax:\n",
    "        continue\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.3, fc='gray', ec='none', label='Granos' if 'Granos' not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "# 3.2. Dibujar las flechas de flujo\n",
    "ax.quiver(\n",
    "    midpoints[:, 0], midpoints[:, 1], # Origen de la flecha (midpoint)\n",
    "    U_norm, V_norm,                   # Dirección (vector unitario)\n",
    "    color='black',\n",
    "    scale=1200,                         # Escala (más grande = flechas más pequeñas)\n",
    "    width=0.0003,                      # Ancho de la cabeza\n",
    "    scale_units='xy',                 # Usar unidades de los ejes para escalar\n",
    "    angles='xy',                      # No rotar flechas con el aspect ratio\n",
    "    zorder=10\n",
    ")\n",
    "\n",
    "# 3.3. Configuración del gráfico\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(roi_xmin, roi_xmax)\n",
    "ax.set_ylim(ymin, ymax) \n",
    "ax.set_title(f\"Visualización de la Dirección del Flujo en Tubos\")\n",
    "ax.set_xlabel(\"Coordenada X (m)\")\n",
    "ax.set_ylabel(\"Coordenada Y (m)\")\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Iniciando visualización detallada de la red (Poiseuille)...\")\n",
    "print(\"(Este método es más robusto y puede tardar un poco más...)\")\n",
    "\n",
    "# --- 1. Preparación (Tangentes y Clasificación) ---\n",
    "if 'N_SAMPLES' not in locals():\n",
    "    N_SAMPLES = 10\n",
    "    \n",
    "# --- CAMBIO 1 ---\n",
    "arrow_len = (roi_xmax - roi_xmin) * 0.002 # Longitud de flecha\n",
    "\n",
    "oriented_tangents = {} \n",
    "Xg, Yg, Ug, Vg = [], [], [], [] \n",
    "junc1, junc2 = [], [] \n",
    "Xy, Yy, Uy, Vy = [], [], [], [] \n",
    "\n",
    "if 'tube_flow_map' not in locals():\n",
    "    tube_flow_map = {idx: row['flow_rate'] for idx, row in df_tubos.iterrows()}\n",
    "if 'junction_coords' not in locals():\n",
    "    junction_coords = np.array([j['coord'] for j in junctions_list_structured])\n",
    "\n",
    "print(\"Pre-calculando orientación de tangentes y clasificación...\")\n",
    "for tube_id, tube_data in df_tubos.iterrows():\n",
    "    \n",
    "    # --- 1a. Recalcular geometría ---\n",
    "    idx1, idx2 = tube_data['bead_indices']\n",
    "    is_wall_tube = tube_data['is_wall_tube']\n",
    "    width = tube_data['width']\n",
    "    \n",
    "    if is_wall_tube:\n",
    "        real_idx = idx1 if idx1 < n_real_beads else idx2\n",
    "        c_real = centers[real_idx]; r_real = radii[real_idx]\n",
    "        is_top_wall = c_real[1] > (ymax + ymin) / 2.0\n",
    "        if is_top_wall:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] + r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymax])\n",
    "            n_vec_path = np.array([0.0, 1.0])\n",
    "        else:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] - r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymin])\n",
    "            n_vec_path = np.array([0.0, -1.0])\n",
    "    else:\n",
    "        c1, c2 = all_centers[idx1], all_centers[idx2]\n",
    "        r1, r2 = all_radii[idx1], all_radii[idx2]\n",
    "        center_vec = c2 - c1; dist = np.linalg.norm(center_vec)\n",
    "        n_vec_path = center_vec / dist\n",
    "        p_edge_wall = c1 + n_vec_path * r1\n",
    "        p_edge_bead = c2 - n_vec_path * r2\n",
    "        \n",
    "    # --- 1b. Orientar Tangente ---\n",
    "    n_vec_flow_initial = np.array([-n_vec_path[1], n_vec_path[0]])\n",
    "    sample_pts_k = np.linspace(p_edge_wall, p_edge_bead, N_SAMPLES)\n",
    "    \n",
    "    dists, idxs = tree.query(sample_pts_k, k=1)\n",
    "    v_sec = U_cells[idxs]\n",
    "    v_sec = np.nan_to_num(v_sec, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    proj_mean = np.dot(v_sec, n_vec_flow_initial).mean()\n",
    "    sign = np.sign(proj_mean) if np.sign(proj_mean) != 0 else 1.0\n",
    "    t_oriented = n_vec_flow_initial * sign\n",
    "    oriented_tangents[tube_id] = t_oriented\n",
    "    \n",
    "    midpoint = tube_data['midpoint']\n",
    "    Xg.append(midpoint[0]); Yg.append(midpoint[1])\n",
    "    Ug.append(t_oriented[0] * arrow_len); Vg.append(t_oriented[1] * arrow_len)\n",
    "\n",
    "# --- 1c. Clasificar Junctions ---\n",
    "for j_index, tube_id_list in enumerate(junctions_list):\n",
    "    if j_index in border_junction_indices or not tube_id_list:\n",
    "        continue\n",
    "    flows = [tube_flow_map[t_id] for t_id in tube_id_list if t_id in tube_flow_map]\n",
    "    if not flows:\n",
    "        continue\n",
    "    i_max_id = tube_id_list[np.argmax(flows)]\n",
    "    midpoint_max = df_tubos.loc[i_max_id]['midpoint']\n",
    "    j_coord = junction_coords[j_index]\n",
    "    tangent_max = oriented_tangents[i_max_id]\n",
    "    vec_m_to_j = j_coord - midpoint_max\n",
    "    dp = tangent_max.dot(vec_m_to_j)\n",
    "    if dp > 0: junc2.append(j_index)\n",
    "    else: junc1.append(j_index)\n",
    "    Xy.append(j_coord[0]); Yy.append(j_coord[1])\n",
    "    Uy.append(tangent_max[0] * arrow_len); Vy.append(tangent_max[1] * arrow_len)\n",
    "\n",
    "print(f\"Pre-cálculo completado. Clasificadas {len(junc1)} tipo '1' y {len(junc2)} tipo '2'.\")\n",
    "\n",
    "# --- 2. ¡A PLOTEAR! ---\n",
    "print(\"Generando gráfico...\")\n",
    "# --- CAMBIO 3 ---\n",
    "fig, ax = plt.subplots(figsize=(14, 14), dpi=1200) # (Resolución muy alta)\n",
    "\n",
    "# 2.1. Fondo (Granos)\n",
    "print(\"Dibujando granos (vectorial)...\")\n",
    "for poly in final_circular_polygons:\n",
    "    x, y = poly.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.4, fc='gray', ec='none', zorder=0)\n",
    "\n",
    "# 2.2. Perfiles de Poiseuille (Líneas y Flechas cian)\n",
    "print(\"Dibujando perfiles de tubo (Poiseuille)...\")\n",
    "\n",
    "# Calcular escala de velocidad\n",
    "sample_vel_mags = np.linalg.norm(U_cells, axis=1)\n",
    "max_vel = np.percentile(sample_vel_mags, 99.5) \n",
    "if max_vel == 0: max_vel = 1.0\n",
    "vel_scale = 5 * arrow_len / max_vel \n",
    "\n",
    "for tube_id, tube_data in df_tubos.iterrows():\n",
    "    \n",
    "    # Recalcular geometría\n",
    "    idx1, idx2 = tube_data['bead_indices']\n",
    "    is_wall_tube = tube_data['is_wall_tube']\n",
    "    if is_wall_tube:\n",
    "        real_idx = idx1 if idx1 < n_real_beads else idx2\n",
    "        c_real = centers[real_idx]; r_real = radii[real_idx]\n",
    "        is_top_wall = c_real[1] > (ymax + ymin) / 2.0\n",
    "        if is_top_wall:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] + r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymax])\n",
    "        else:\n",
    "            p_edge_bead = np.array([c_real[0], c_real[1] - r_real])\n",
    "            p_edge_wall = np.array([c_real[0], ymin])\n",
    "    else:\n",
    "        c1, c2 = all_centers[idx1], all_centers[idx2]\n",
    "        r1, r2 = all_radii[idx1], all_radii[idx2]\n",
    "        center_vec = c2 - c1; dist = np.linalg.norm(center_vec)\n",
    "        n_vec_path = center_vec / dist\n",
    "        p_edge_wall = c1 + n_vec_path * r1\n",
    "        p_edge_bead = c2 - n_vec_path * r2\n",
    "        \n",
    "    pts_k = np.linspace(p_edge_wall, p_edge_bead, N_SAMPLES)\n",
    "    xs, ys = pts_k[:,0], pts_k[:,1]\n",
    "    \n",
    "    dists, idxs = tree.query(pts_k, k=1)\n",
    "    U_k = U_cells[idxs]\n",
    "    U_k = np.nan_to_num(U_k, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    uscaled_k = U_k * vel_scale\n",
    "    \n",
    "    # Dibujar ESTE tubo\n",
    "    ax.plot(xs, ys, color='black', linewidth=0.5, alpha=0.6, zorder=3)\n",
    "    ax.quiver(xs, ys,\n",
    "              uscaled_k[:,0], uscaled_k[:,1],\n",
    "              angles='xy', scale_units='xy', scale=1,\n",
    "              width=0.001,\n",
    "              color='cyan', alpha=0.8, zorder=2)\n",
    "\n",
    "# 2.3. Tangentes de tubos (Flechas verdes)\n",
    "# --- CAMBIO 4 (parámetros) ---\n",
    "ax.quiver(Xg, Yg, Ug, Vg, angles='xy', scale_units='xy', scale=1,\n",
    "          width=0.0004, headwidth=1, headlength=1.2, headaxislength=1,\n",
    "          color='green', alpha=0.8, zorder=3, label='Tangente del Tubo (orientada)')\n",
    "\n",
    "# 2.4. Tubo principal en Junction (Flechas amarillas)\n",
    "# --- CAMBIO 4 (parámetros) ---\n",
    "ax.quiver(Xy, Yy, Uy, Vy, angles='xy', scale_units='xy', scale=1,\n",
    "          width=0.0004, headwidth=1, headlength=1.2, headaxislength=1,\n",
    "          color='yellow', alpha=0.9, zorder=4, label='Tangente Tubo Principal')\n",
    "\n",
    "# 2.5. Etiquetas de tipo de Junction (Textos 1 y 2)\n",
    "for j_index in junc1:\n",
    "    xj, yj = junction_coords[j_index]\n",
    "    ax.text(xj, yj, \"1\", color='red', fontsize=3, fontweight='bold', ha='center', va='center', zorder=5)\n",
    "for j_index in junc2:\n",
    "    xj, yj = junction_coords[j_index]\n",
    "    ax.text(xj, yj, \"2\", color='blue', fontsize=3, fontweight='bold', ha='center', va='center', zorder=5)\n",
    "\n",
    "# 2.6. Configuración final\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_title('Visualización Detallada del Flujo')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "print(\"Iniciando el cálculo del gradiente de presión...\")\n",
    "\n",
    "# --- 1. Preparar el muestreo de Presión (similar a Velocidad) ---\n",
    "RHO_FLUID = 1000.0 # Densidad del agua (kg/m^3)\n",
    "P_NAME_CELL = None\n",
    "\n",
    "# Buscar el campo de presión (OpenFOAM usa 'p' o 'p_rgh')\n",
    "common_names = ['p', 'pressure', 'Pressure', 'p_rgh']\n",
    "for name in common_names:\n",
    "    if name in vol_mesh.cell_data:\n",
    "        P_NAME_CELL = name\n",
    "        break\n",
    "\n",
    "if P_NAME_CELL is None:\n",
    "    print(\"ERROR FATAL: No se encontró el campo de presión ('p' o 'p_rgh') en vol_mesh.cell_data.\")\n",
    "    # Si no se encuentra, detenemos esta celda\n",
    "    pressure_gradients_np = np.array([0]) # Array vacío para evitar que el plot falle\n",
    "else:\n",
    "    print(f\"Usando el campo de presión de celda: '{P_NAME_CELL}'\")\n",
    "    \n",
    "    # 1a. Extraer datos y construir el árbol\n",
    "    # (Usamos los mismos centros de celda que para la velocidad)\n",
    "    if 'cell_centers_3d' not in locals():\n",
    "         cell_centers_3d = vol_mesh.cell_centers().points\n",
    "         \n",
    "    p_data_raw = vol_mesh.cell_data[P_NAME_CELL] # (M,)\n",
    "    \n",
    "    # 1b. Construir el árbol en 2D\n",
    "    tree_p = cKDTree(cell_centers_3d[:, :2])\n",
    "    print(\"Árbol KDTree para presión construido.\")\n",
    "\n",
    "    # --- 2. Computar la presión en CADA junction ---\n",
    "    \n",
    "    # 2a. Obtener coordenadas de todas las junctions\n",
    "    junction_coords = np.array([j['coord'] for j in junctions_list_structured])\n",
    "    \n",
    "    # 2b. Consultar el árbol para encontrar la celda más cercana a cada junction\n",
    "    dists, idxs = tree_p.query(junction_coords, k=1)\n",
    "    \n",
    "    # 2c. Obtener los valores de presión (p/rho) y corregirlos\n",
    "    p_junction_raw = p_data_raw[idxs]\n",
    "    p_junction_corrected = p_junction_raw * RHO_FLUID # Presión real en Pascales\n",
    "    \n",
    "    # 2d. Crear un mapa para búsqueda fácil: {junction_id: Presión}\n",
    "    junction_pressure_map = {j_idx: p for j_idx, p in enumerate(p_junction_corrected)}\n",
    "    print(f\"Presión muestreada y corregida para {len(junction_pressure_map)} junctions.\")\n",
    "\n",
    "    # --- 3. Calcular el gradiente para CADA tubo ---\n",
    "    pressure_gradients = []\n",
    "    \n",
    "    # Iteramos sobre el mapa de direcciones (contiene j_initial y j_final)\n",
    "    for tube_id, (j_initial_id, j_final_id) in tube_direction_map.items():\n",
    "        \n",
    "        # 3.1. Obtener presiones de las junctions conectadas\n",
    "        p_initial = junction_pressure_map.get(j_initial_id)\n",
    "        p_final = junction_pressure_map.get(j_final_id)\n",
    "        \n",
    "        if p_initial is None or p_final is None:\n",
    "            continue\n",
    "            \n",
    "        # 3.2. Calcular la longitud (L) del tubo (distancia entre junctions)\n",
    "        coord_initial = junctions_list_structured[j_initial_id]['coord']\n",
    "        coord_final = junctions_list_structured[j_final_id]['coord']\n",
    "        length = np.linalg.norm(coord_final - coord_initial)\n",
    "        \n",
    "        if length < 1e-12: # Evitar división por cero\n",
    "            continue\n",
    "            \n",
    "        # 3.3. Calcular el gradiente de presión\n",
    "        # (Usamos el valor absoluto, ya que el signo depende de la dirección)\n",
    "        delta_p = p_final - p_initial\n",
    "        gradient = np.abs(delta_p) / length # |(P2 - P1) / L|\n",
    "        \n",
    "        pressure_gradients.append(gradient)\n",
    "\n",
    "    # Convertir a array de NumPy para estadísticas\n",
    "    pressure_gradients_np = np.array(pressure_gradients)\n",
    "\n",
    "\n",
    "# --- 4. Calcular Estadísticas ---\n",
    "if pressure_gradients_np.size > 0:\n",
    "    mean_grad = np.mean(pressure_gradients_np)\n",
    "    var_grad = np.var(pressure_gradients_np)\n",
    "    std_dev_grad = np.std(pressure_gradients_np)\n",
    "\n",
    "    print(\"\\n--- Pressure Gradient Statistics ---\")\n",
    "    print(f\"Mean:\\t\\t {mean_grad:.2f} Pa/m\")\n",
    "    print(f\"Variance:\\t {var_grad:.2f} (Pa/m)^2\")\n",
    "    print(f\"Std. Deviation:\\t {std_dev_grad:.2f} Pa/m\")\n",
    "else:\n",
    "    print(\"No se calcularon gradientes de presión.\")\n",
    "    mean_grad = 0\n",
    "\n",
    "# --- 5. Representar el Histograma (NORMALIZADO) ---\n",
    "print(\"Generando histograma (PDF)...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "\n",
    "if pressure_gradients_np.size > 0:\n",
    "    # Limitar el rango del histograma para excluir outliers extremos\n",
    "    p_min = np.percentile(pressure_gradients_np, 0.5)\n",
    "    p_max = np.percentile(pressure_gradients_np, 99.5)\n",
    "    \n",
    "    # Asegurarse de que el rango es válido\n",
    "    if p_max <= p_min:\n",
    "        p_min = np.min(pressure_gradients_np)\n",
    "        p_max = np.max(pressure_gradients_np)\n",
    "    \n",
    "    bins = np.linspace(p_min, p_max, 50)\n",
    "    \n",
    "    # --- CAMBIO AQUÍ ---\n",
    "    ax.hist(pressure_gradients_np, bins=bins, color='darkorange', alpha=0.75, edgecolor='black', density=True)\n",
    "    \n",
    "    # Línea de la media\n",
    "    ax.axvline(mean_grad, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {mean_grad:.2f} Pa/m')\n",
    "    \n",
    "    ax.set_title('Pressure Gradient Distribution (PDF)', fontsize=16) # <-- TÍTULO CAMBIADO\n",
    "    ax.set_xlabel('Pressure Gradient (Pa/m)', fontsize=12)\n",
    "    ax.set_ylabel('Probability Density', fontsize=12) # <-- ETIQUETA CAMBIADA\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=':', alpha=0.6)\n",
    "    # Formato de notación científica si los números son muy grandes\n",
    "    ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "else:\n",
    "    ax.set_title('Pressure Gradient Distribution (No Data)', fontsize=16)\n",
    "    ax.set_xlabel('Pressure Gradient (Pa/m)', fontsize=12)\n",
    "    ax.set_ylabel('Probability Density', fontsize=12) # <-- ETIQUETA CAMBIADA\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Calculando la permeabilidad para cada tubo...\")\n",
    "\n",
    "# --- 1. Definir Constantes ---\n",
    "H_METERS = 0.001 # h = 1 mm\n",
    "R_CONST = H_METERS / np.sqrt(12) # r = h / sqrt(12)\n",
    "\n",
    "permeabilities = []\n",
    "\n",
    "# --- 2. Iterar sobre todos los tubos ---\n",
    "# Usamos df_tubos, que ya contiene la 'width' efectiva\n",
    "for tube_id, tube_data in df_tubos.iterrows():\n",
    "    \n",
    "    # 2.1. Get effective half-width (a)\n",
    "    width = tube_data['width']\n",
    "    a = width / 2.0\n",
    "    \n",
    "    # 2.2. Skip tubos con anchura cero o negativa\n",
    "    if a < 1e-12: # Usar un épsilon pequeño para comparación de flotantes\n",
    "        continue\n",
    "        \n",
    "    # 2.3. Aplicar la fórmula proporcionada\n",
    "    h = H_METERS\n",
    "    r = R_CONST\n",
    "    \n",
    "    ratio_r_a = r / a\n",
    "    tanh_term = np.tanh(a / r) # Esto es tanh(1 / ratio_r_a)\n",
    "    \n",
    "    # k = (h^3 * a * (1 - (r/a) * tanh(a/r))) / 9\n",
    "    k_numerator = (h**3 * a * (1 - ratio_r_a * tanh_term))\n",
    "    k = k_numerator / 9.0\n",
    "    \n",
    "    permeabilities.append(k)\n",
    "\n",
    "# --- 3. Calcular Estadísticas ---\n",
    "permeabilities_np = np.array(permeabilities)\n",
    "\n",
    "if permeabilities_np.size > 0:\n",
    "    mean_k = np.mean(permeabilities_np)\n",
    "    var_k = np.var(permeabilities_np)\n",
    "    std_dev_k = np.std(permeabilities_np)\n",
    "\n",
    "    print(\"\\n--- Permeability Statistics ---\")\n",
    "    # Usamos notación científica (:.2e) porque las unidades (m^4) son inusuales\n",
    "    print(f\"Mean:\\t\\t {mean_k:.2e}\")\n",
    "    print(f\"Variance:\\t {var_k:.2e}\")\n",
    "    print(f\"Std. Deviation:\\t {std_dev_k:.2e}\")\n",
    "else:\n",
    "    print(\"No se calcularon permeabilidades.\")\n",
    "    mean_k = 0\n",
    "\n",
    "# --- 4. Representar el Histograma (NORMALIZADO) ---\n",
    "print(\"Generando histograma (PDF)...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "\n",
    "if permeabilities_np.size > 0:\n",
    "    # Limitar el rango para mejor visualización\n",
    "    p_min = np.percentile(permeabilities_np, 0.5)\n",
    "    p_max = np.percentile(permeabilities_np, 99.5)\n",
    "    \n",
    "    if p_max <= p_min: # Fallback si los percentiles fallan\n",
    "        p_min = np.min(permeabilities_np)\n",
    "        p_max = np.max(permeabilities_np)\n",
    "    \n",
    "    bins = np.linspace(p_min, p_max, 20)\n",
    "    \n",
    "    # density=True crea el histograma normalizado (PDF)\n",
    "    ax.hist(permeabilities_np, bins=bins, color='seagreen', alpha=0.75, edgecolor='black', density=True)\n",
    "    \n",
    "    # Línea de la media\n",
    "    ax.axvline(mean_k, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {mean_k:.2e}')\n",
    "    \n",
    "    ax.set_title('Permeability Distribution (PDF)', fontsize=16)\n",
    "    ax.set_xlabel('Permeability ($k$)', fontsize=12) # No especifico unidades dado lo inusual de la fórmula\n",
    "    ax.set_ylabel('Probability Density', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=':', alpha=0.6)\n",
    "    ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "else:\n",
    "    ax.set_title('Permeability Distribution (No Data)', fontsize=16)\n",
    "    ax.set_xlabel('Permeability ($k$)', fontsize=12)\n",
    "    ax.set_ylabel('Probability Density', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Calculando caudales teóricos (Q = k*G/mu)...\")\n",
    "\n",
    "# --- 1. Definir Constantes ---\n",
    "MU_WATER = 1.0e-3 # Viscosidad dinámica del agua (Pa·s) en SI\n",
    "H_METERS = 0.001  # h = 1 mm\n",
    "R_CONST = H_METERS / np.sqrt(12) # r = h / sqrt(12)\n",
    "\n",
    "# Comprobar que los mapas de las celdas anteriores existen\n",
    "if 'tube_direction_map' not in locals() or 'junction_pressure_map' not in locals() or 'tube_flow_map' not in locals():\n",
    "    print(\"ERROR: Faltan datos de celdas anteriores.\")\n",
    "    print(\"Por favor, ejecuta las celdas de 'Pre-cálculo de Dirección', 'Gradiente de Presión' y 'Cálculo de Tubos' primero.\")\n",
    "    # Crear arrays vacíos para que el script no falle\n",
    "    real_flows_np = np.array([])\n",
    "    theoretical_flows_np = np.array([])\n",
    "else:\n",
    "    real_flows = []\n",
    "    theoretical_flows = []\n",
    "\n",
    "    # --- 2. Iterar sobre todos los tubos válidos (los que tienen dirección) ---\n",
    "    for tube_id, (j_initial_id, j_final_id) in tube_direction_map.items():\n",
    "        \n",
    "        # --- 2a. Obtener Caudal Real (Q_real) ---\n",
    "        flow_real = tube_flow_map.get(tube_id)\n",
    "        if flow_real is None:\n",
    "            continue\n",
    "\n",
    "        # --- 2b. Calcular Permeabilidad (k) ---\n",
    "        tube_data = df_tubos.loc[tube_id]\n",
    "        width = tube_data['width']\n",
    "        a = width / 2.0 # Semianchura (a)\n",
    "        \n",
    "        if a < 1e-12:\n",
    "            continue # Omitir tubos sin anchura\n",
    "            \n",
    "        # Fórmula de permeabilidad\n",
    "        ratio_r_a = R_CONST / a\n",
    "        tanh_term = np.tanh(a / R_CONST)\n",
    "        k_numerator = (H_METERS**3 * a * (1 - ratio_r_a * tanh_term))\n",
    "        k = k_numerator / 6.0\n",
    "        k = 2.0*a*a*a*H_METERS/3.0\n",
    "        \n",
    "        \n",
    "        # --- 2c. Calcular Gradiente de Presión (G) ---\n",
    "        p_initial = junction_pressure_map.get(j_initial_id)\n",
    "        p_final = junction_pressure_map.get(j_final_id)\n",
    "        \n",
    "        if p_initial is None or p_final is None:\n",
    "            continue\n",
    "        \n",
    "        coord_initial = junctions_list_structured[j_initial_id]['coord']\n",
    "        coord_final = junctions_list_structured[j_final_id]['coord']\n",
    "        length = np.linalg.norm(coord_final - coord_initial)\n",
    "        \n",
    "        if length < 1e-12:\n",
    "            continue\n",
    "            \n",
    "        delta_p = p_final - p_initial\n",
    "        G = np.abs(delta_p) / length # Módulo del gradiente\n",
    "        \n",
    "        # --- 2d. Calcular Caudal Teórico (Q_theory) ---\n",
    "        Q_theory = (k * G) / MU_WATER\n",
    "        \n",
    "        # --- 2e. Guardar ambos resultados ---\n",
    "        real_flows.append(flow_real)\n",
    "        theoretical_flows.append(Q_theory)\n",
    "\n",
    "    # Convertir listas a arrays de NumPy\n",
    "    real_flows_np = np.array(real_flows)\n",
    "    theoretical_flows_np = np.array(theoretical_flows)\n",
    "\n",
    "# --- 3. Calcular Estadísticas ---\n",
    "if real_flows_np.size > 0:\n",
    "    print(\"\\n--- Real Flow Statistics ---\")\n",
    "    print(f\"Mean:\\t\\t {np.mean(real_flows_np):.2e} m^3/s\")\n",
    "    print(f\"Variance:\\t {np.var(real_flows_np):.2e} (m^3/s)^2\")\n",
    "    \n",
    "    print(\"\\n--- Theoretical Flow Statistics ---\")\n",
    "    print(f\"Mean:\\t\\t {np.mean(theoretical_flows_np):.2e} m^3/s\")\n",
    "    print(f\"Variance:\\t {np.var(theoretical_flows_np):.2e} (m^3/s)^2\")\n",
    "else:\n",
    "    print(\"No se generaron datos de caudal para comparar.\")\n",
    "\n",
    "# --- 4. Representar los Histogramas (NORMALIZADOS) ---\n",
    "print(\"Generando histogramas (PDF)...\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "\n",
    "if real_flows_np.size > 0:\n",
    "    # Encontrar un rango común para ambos histogramas\n",
    "    combined_data = np.hstack((real_flows_np, theoretical_flows_np))\n",
    "    p_min = np.percentile(combined_data, 0.5)\n",
    "    p_max = np.percentile(combined_data, 99.5)\n",
    "    \n",
    "    if p_max <= p_min: # Fallback\n",
    "        p_min = np.min(combined_data)\n",
    "        p_max = np.max(combined_data)\n",
    "    \n",
    "    # Asegurarse de que el rango no sea cero\n",
    "    if p_max == p_min:\n",
    "         p_max = p_min + 1e-9 # Añadir un delta pequeño\n",
    "\n",
    "    bins = np.linspace(p_min, p_max, 20)\n",
    "    \n",
    "    # Histograma de Caudal Real\n",
    "    ax.hist(real_flows_np*H_METERS*1000, bins=bins, color='royalblue', alpha=0.7, \n",
    "            edgecolor='black', density=True, label='Real Flow Rate (CFD)')\n",
    "    \n",
    "    # Histograma de Caudal Teórico\n",
    "    ax.hist(theoretical_flows_np, bins=bins, color='red', alpha=0.7, \n",
    "            edgecolor='black', density=True, label='Theoretical Flow Rate (k*G/mu)')\n",
    "    \n",
    "    ax.set_title('Real vs. Theoretical Flow Rate Distribution (PDF)', fontsize=16)\n",
    "    ax.set_xlabel('Flow Rate ($Q, m^3/s$)', fontsize=12)\n",
    "    ax.set_ylabel('Probability Density', fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=':', alpha=0.6)\n",
    "    ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "else:\n",
    "    ax.set_title('Flow Rate Distribution (No Data)', fontsize=16)\n",
    "    ax.set_xlabel('Flow Rate ($Q, m^3/s$)', fontsize=12)\n",
    "    ax.set_ylabel('Probability Density', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Iniciando análisis de sensibilidad (k-CanalPlano vs G-Uniones)...\")\n",
    "\n",
    "# --- 1. Definir Constantes y verificar datos ---\n",
    "MU_WATER = 1.0e-3 # Viscosidad dinámica del agua (Pa·s)\n",
    "H_METERS = 0.001  # h = 1 mm\n",
    "\n",
    "# Verificar que tenemos los datos de las uniones\n",
    "if 'junction_pressure_map' not in locals() or 'tube_direction_map' not in locals():\n",
    "    print(\"ERROR: Faltan datos (junction_pressure_map o tube_direction_map).\")\n",
    "    print(\"Ejecuta primero la celda de 'Cálculo del gradiente de presión'.\")\n",
    "else:\n",
    "    q_real_list = []\n",
    "    k_list = []\n",
    "    g_list = []\n",
    "\n",
    "    print(\"Calculando Q_real, k_tubo, y G_uniones para cada tubo...\")\n",
    "    # --- 2. Bucle unificado para recolectar datos alineados ---\n",
    "    for tube_id, (j_initial_id, j_final_id) in tube_direction_map.items():\n",
    "        \n",
    "        # --- 2a. Obtener Q_real ---\n",
    "        flow_real = tube_flow_map.get(tube_id, 0.0)\n",
    "        \n",
    "        # --- 2b. Calcular Permeabilidad (k_tubo) ---\n",
    "        tube_data = df_tubos.loc[tube_id]\n",
    "        width_cross_section = tube_data['width'] # Anchura efectiva\n",
    "        a = width_cross_section / 2.0 # Semianchura (a)\n",
    "        \n",
    "        if a < 1e-12:\n",
    "            k = 0.0\n",
    "        else:\n",
    "            # Fórmula de Canal Plano (k = 2*a^3*h / 3)\n",
    "            k = (2.0 * (a**3) * H_METERS) / 3.0\n",
    "            \n",
    "        # --- 2c. Calcular Gradiente de Unión (G_uniones) ---\n",
    "        p_initial = junction_pressure_map.get(j_initial_id)\n",
    "        p_final = junction_pressure_map.get(j_final_id)\n",
    "        \n",
    "        coord_initial = junctions_list_structured[j_initial_id]['coord']\n",
    "        coord_final = junctions_list_structured[j_final_id]['coord']\n",
    "        length = np.linalg.norm(coord_final - coord_initial) # L_unión-unión\n",
    "        \n",
    "        if length < 1e-12:\n",
    "            G = 0.0\n",
    "        else:\n",
    "            delta_p_uniones = p_final - p_initial\n",
    "            G = np.abs(delta_p_uniones) / length # |(P_unión_B - P_unión_A)| / L_unión-unión\n",
    "        \n",
    "        # --- 2d. Guardar datos ---\n",
    "        q_real_list.append(flow_real)\n",
    "        k_list.append(k)\n",
    "        g_list.append(G)\n",
    "\n",
    "    # --- 3. Convertir a arrays y calcular promedios ---\n",
    "    q_real_np = np.array(q_real_list)\n",
    "    k_np = np.array(k_list)\n",
    "    g_np = np.array(g_list)\n",
    "    \n",
    "    if q_real_np.size > 0:\n",
    "        k_avg = np.mean(k_np)\n",
    "        g_avg = np.mean(g_np)\n",
    "        \n",
    "        print(f\"Valor promedio de Permeabilidad (k_avg_CanalPlano): {k_avg:.2e}\")\n",
    "        print(f\"Valor promedio de Gradiente (G_avg_Uniones): {g_avg:.2e} Pa/m\")\n",
    "\n",
    "        # --- 4. Calcular las dos distribuciones teóricas ---\n",
    "        q_theory_avg_k = (k_avg * g_np) / MU_WATER\n",
    "        q_theory_avg_g = (k_np * g_avg) / MU_WATER\n",
    "\n",
    "        # --- 5. Representar los tres histogramas (con líneas) ---\n",
    "        print(\"Generando gráficos (PDF)...\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "        \n",
    "        # Rango común\n",
    "        combined_data = np.hstack((q_real_np, q_theory_avg_k, q_theory_avg_g))\n",
    "        p_min = np.percentile(combined_data, 0.5)\n",
    "        p_max = np.percentile(combined_data, 99.5)\n",
    "        if p_max <= p_min: p_max = p_min + 1e-9\n",
    "        \n",
    "        bins = np.linspace(p_min, p_max, 50)\n",
    "        \n",
    "        # Calcular los datos del histograma (PDF)\n",
    "        pdf_real, bin_edges = np.histogram(q_real_np, bins=bins, density=True)\n",
    "        pdf_avg_k, _ = np.histogram(q_theory_avg_k, bins=bins, density=True)\n",
    "        pdf_avg_g, _ = np.histogram(q_theory_avg_g, bins=bins, density=True)\n",
    "        \n",
    "        # Calcular los centros de los bins para el eje X\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        \n",
    "        # --- INICIO DE LA MODIFICACIÓN (COLORES) ---\n",
    "        \n",
    "        # Graficar con ax.plot en lugar de ax.hist\n",
    "        # Real Q (azul, 'C0', igual que line_h.get_color())\n",
    "        ax.plot(bin_centers, pdf_real, 'o-', color='C0', label='Real Q (CFD)', markersize=5) \n",
    "        \n",
    "        # Avg. k (rojo, 'C3', igual que pdf_mod)\n",
    "        ax.plot(bin_centers, pdf_avg_k, '--', color='C3', label='Q (avg. k, real press. gradient)')\n",
    "        \n",
    "        # Avg. G (naranja, 'C1', igual que pdf_f)\n",
    "        ax.plot(bin_centers, pdf_avg_g, '--', color='C1', label='Q (real k, avg. press. gradient)')\n",
    "        \n",
    "        # --- FIN DE LA MODIFICACIÓN (COLORES) ---\n",
    "        \n",
    "        #ax.set_title('Flow Rate Distribution Sensitivity (PDF)', fontsize=16)\n",
    "        ax.set_xlabel('Flow Rate ($Q, m^3/s$)', fontsize=12)\n",
    "        ax.set_ylabel('Probability Density', fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle=':', alpha=0.6)\n",
    "        ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"No se generaron datos para el análisis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
