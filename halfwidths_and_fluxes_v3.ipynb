{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pore size and flow rate distributions in 2D porous media calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.spatial import KDTree\n",
    "from skimage.morphology import medial_axis\n",
    "from shapely import vectorized\n",
    "from shapely.geometry import Point, LineString, box\n",
    "from shapely.ops import polygonize, unary_union\n",
    "from shapely.prepared import prep\n",
    "import networkx as netx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read and load the VTK file that contains the solved OpenFOAM case\n",
    "\n",
    "case_dir = os.path.expanduser(\"~/OpenFOAM/jose-v2406/run/YDRAY-flow_n13_sat\")\n",
    "vtk_file = os.path.join(case_dir, \"VTK\", \"YDRAY-flow_n13_sat_1047.vtm\")\n",
    "\n",
    "mb        = pv.read(vtk_file)\n",
    "vol_mesh  = mb[\"internal\"] #the \"fluid\" mesh (where CFD is solved)\n",
    "cyl_patch = mb[\"boundary\"][\"wallFluidSolid\"] # the walls of the cylindrical obstacles\n",
    "\n",
    "_, _, _, _, zmin, zmax = vol_mesh.bounds\n",
    "z_mid = 0.5 * (zmin + zmax)\n",
    "\n",
    "# As the problem is 2D, we take a 2D slice centered at z=0 of both the internal mesh and the cylinders' walls and get rid of everything else\n",
    "obst_section = (\n",
    "    cyl_patch.extract_surface()\n",
    "             .slice(normal=\"z\", origin=(0, 0, z_mid))\n",
    "             .clean()\n",
    ")\n",
    "dom_section = (\n",
    "    vol_mesh.extract_surface()\n",
    "            .slice(normal=\"z\", origin=(0, 0, z_mid))\n",
    "            .clean()\n",
    ")\n",
    "\n",
    "xmin, xmax, ymin, ymax, _, _ = dom_section.bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We polygonize the boundary and the obstacles with Shapely\n",
    "\n",
    "def polydata_to_polygon(polydata):\n",
    "    # Takes a PolyData and returns the resulting polygons\n",
    "    if isinstance(polydata, pv.UnstructuredGrid):\n",
    "        polydata = polydata.extract_geometry()\n",
    "    total_entries = len(polydata.lines)\n",
    "    lines = []\n",
    "    i, count = 0, 0\n",
    "    while i < total_entries:\n",
    "        n_pts = polydata.lines[i]\n",
    "        idx = polydata.lines[i+1:i+1+n_pts]\n",
    "        coords = [tuple(polydata.points[j][:2]) for j in idx]\n",
    "        lines.append(LineString(coords))\n",
    "        i += 1 + n_pts\n",
    "        count += 1\n",
    "    merged = unary_union(lines)\n",
    "    polys = list(polygonize(merged))\n",
    "    return polys\n",
    "\n",
    "\n",
    "# We keep only the contours of the circular obstacles\n",
    "clean_obs = obst_section.clean(tolerance=1e-6)\n",
    "conn = clean_obs.connectivity() \n",
    "n_beads = int(conn['RegionId'].max())+1\n",
    "print(f\"Found {n_beads} obstacle contours\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block goes through each obstacle contour found in the slice, converts it from PyVista geometry into Shapely polygons, \n",
    "# and collects them all into obs_polys. \n",
    "obs_polys = []\n",
    "for rid in range(n_beads):\n",
    "    bead = conn.threshold([rid, rid], scalars='RegionId').clean(tolerance = 1e-8).extract_geometry()\n",
    "    polys = polydata_to_polygon(bead)\n",
    "    if polys:\n",
    "        obs_polys.extend(polys)\n",
    "\n",
    "print(f\"A total of {len(obs_polys)} obstacles were converted to polygons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xmin, xmax, ymin, ymax, zmin, zmax = dom_section.bounds\n",
    "x_cutoff = max(poly.bounds[2] for poly in obs_polys)\n",
    "xmax = x_cutoff\n",
    "print(f\"The bottom-left corner is at ({xmin}, {ymin}), the top-right corner is at ({xmax}, {ymax})\")\n",
    "\n",
    "# We merge the obstacles and define the area where the water flows\n",
    "outer = box(xmin, ymin, xmax, ymax)\n",
    "beads = unary_union(obs_polys)\n",
    "free_region = outer.difference(beads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the created polygons to make sure everything is correct\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "# Visualization of the outer contour:\n",
    "if outer.geom_type == 'Polygon':\n",
    "    x, y = outer.exterior.xy\n",
    "    ax.plot(x, y, color='blue', linewidth=2)\n",
    "else:\n",
    "    for poly in outer.geoms:\n",
    "        x, y = poly.exterior.xy\n",
    "        ax.plot(x, y, color='blue', linewidth=2)\n",
    "\n",
    "# Visualization of the beads:\n",
    "if beads.geom_type == 'Polygon':\n",
    "    xb, yb = beads.exterior.xy\n",
    "    ax.plot(xb, yb, color='blue', linewidth=1)\n",
    "else:\n",
    "    for poly in beads.geoms:\n",
    "        xb, yb = poly.exterior.xy\n",
    "        ax.plot(xb, yb, color='blue', linewidth=1)\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW: CREATE A BOOLEAN MASK TO KNOW WHICH POINTS ARE INSIDE OR OUTSIDE THE FREE SPACE\n",
    "\n",
    "# We want maximum resolution: first estimate the smallest cell size of our mesh (dx)\n",
    "# To do this, we build a KDTree and request the list of distances to the 2nd neighbor (the 1st is the point itself)\n",
    "pts2d = dom_section.points[:, :2]\n",
    "tree = KDTree(pts2d)\n",
    "dists, _ = tree.query(pts2d, k=2)\n",
    "nn_dists = dists[:, 1]\n",
    "# Instead of the minimum value, we take the 1st percentile to avoid outliers:\n",
    "dx = np.percentile(nn_dists, 0.1)\n",
    "dy = dx # we assume an isotropic mesh\n",
    "\n",
    "print(f\"The width of our pixel will be dx = {dx:.5g} m\")\n",
    "\n",
    "\n",
    "# Now we set the resolution based on dx. This resolution is nearly maximum\n",
    "nx = int(np.ceil((xmax-xmin)/dx)) + 1\n",
    "ny = int(np.ceil((ymax-ymin)/dy)) + 1\n",
    "\n",
    "print(f\"Mask resolution: {nx}x{ny} (as close as possible to the original mesh).\")\n",
    "\n",
    "# AND NOW: WE GENERATE THE BOOLEAN MASK\n",
    "xs = np.linspace(xmin, xmax, nx)\n",
    "ys = np.linspace(ymin, ymax, ny)\n",
    "XX, YY = np.meshgrid(xs, ys, indexing=\"xy\")\n",
    "\n",
    "prepped = prep(free_region)\n",
    "\n",
    "from shapely import contains_xy\n",
    "mask = contains_xy(free_region, XX, YY)\n",
    "\n",
    "\n",
    "print(\"Mask created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the created mask to make sure everything is in order\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(120,80))\n",
    "im = ax.imshow(mask, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='gray', interpolation='nearest')\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_title('White = free space')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW: WE COMPUTE THE SKELETON OF THE POROUS MEDIUM\n",
    "\n",
    "# First, we compute the Euclidean distance from the center of each white pixel (free space) \n",
    "# to the center of the nearest black pixel (obstacle). \n",
    "# The function we use calculates these distances in \"pixel widths\" (dx)\n",
    "dist_pixels = distance_transform_edt(mask)\n",
    "\n",
    "# Now, we compute the skeleton and project the \"distance matrix\" onto the skeleton\n",
    "skeleton, skel_dist_pixels = medial_axis(mask, return_distance=True)\n",
    "\n",
    "# We convert everything to meters\n",
    "dist_map = dist_pixels * dx\n",
    "skel_dist = skel_dist_pixels * dx\n",
    "\n",
    "# How many pixels does the skeleton have?\n",
    "n_skel_pts = skeleton.sum()\n",
    "print(f\"Points in the skeleton: {n_skel_pts:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot a quick (rough) histogram of the half-widths\n",
    "half_widths_mm = skel_dist[skeleton]*1e3\n",
    "\n",
    "# We fit a Rayleigh distribution\n",
    "from scipy.stats import rayleigh, norm\n",
    "loc_hat, sigma_hat = rayleigh.fit(half_widths_mm)\n",
    "\n",
    "# We fit a Gaussian distribution\n",
    "mu_g, sigma_g = norm.fit(half_widths_mm)\n",
    "\n",
    "# Gaussian fit using the sample mean and standard deviation\n",
    "mean_hw = half_widths_mm.mean()\n",
    "std_hw = half_widths_mm.std()\n",
    "\n",
    "# Time to plot!\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(half_widths_mm, bins=50, density=True, alpha=0.6, label=\"Simulation\")\n",
    "r = np.linspace(0, half_widths_mm.max(), 200)\n",
    "ax.plot(r, rayleigh.pdf(r, loc=loc_hat, scale=sigma_hat), 'r-', lw=2, label=f\"Rayleigh fit\\nσ={sigma_hat:.2f} mm\")\n",
    "ax.plot(r, norm.pdf(r, loc=mu_g, scale=sigma_g), 'b--', lw=2, label=f\"Normal fit\\nμ={mu_g:.2f} mm\\nσ={sigma_g:.2f} mm\")\n",
    "ax.plot(r, norm.pdf(r, loc=mean_hw, scale=std_hw), 'g:', lw=2, label=f\"Empiric normal\\nμ={mean_hw:.2f} mm\\nσ={std_hw:.2f} mm\")\n",
    "ax.set_xlabel(\"Half-width (mm)\")\n",
    "ax.set_ylabel(\"Probability density\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of halfwidths:\", len(half_widths_mm))\n",
    "# The number is much larger than the total amount of Poiseuille tubes because we are considering the \n",
    "# distance from each skeleton point to the nearest obstacle point as a half-width. \n",
    "# However, it can be argued that this is more realistic than taking only one distance per tube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the skeleton on top of the boolean mask to check that everything is correct\n",
    "plt.figure(figsize=(12,8), dpi=1200)\n",
    "plt.imshow(mask, origin='lower', cmap='gray', extent=(xmin, xmax, ymin, ymax))\n",
    "# the skeleton:\n",
    "ys, xs = np.where(skeleton)\n",
    "plt.scatter(xs*dx + xmin, ys*dx + ymin, s=0.005, c='red', label='Skeleton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# WE REMOVE DEAD-ENDS FROM THE SKELETON\n",
    "\n",
    "def prune_spurs(skel, n_iters):\n",
    "    \n",
    "    # We iteratively remove the endpoints (degree-1 pixels) \n",
    "    # from the binary skeleton n_iters times.  \n",
    "    # We use a 3×3 structuring element of ones (to count neighbors)\n",
    "    se = np.ones((3,3), dtype=int)\n",
    "    sk = skel.copy()\n",
    "    for _ in range(n_iters):\n",
    "        # Convolution: count neighbors (including the pixel)\n",
    "        count = ndi.convolve(sk.astype(int), se, mode='constant', cval=0)\n",
    "        # Endpoints are pixels in sk with exactly 2 in count\n",
    "        # because count = 1 (the pixel itself) + 1 (the neighbor) = 2\n",
    "        endpoints = (sk & (count == 2))\n",
    "        if not endpoints.any():\n",
    "            break\n",
    "        sk[endpoints] = False\n",
    "    return sk\n",
    "\n",
    "skeleton_pruned = prune_spurs(skeleton, 600)\n",
    "skeleton = skeleton_pruned\n",
    "\n",
    "# WE CONVERT THE SKELETON INTO A GRAPH\n",
    "# where the skeleton pixels are the nodes and there is a link between two of them if they are neighbors in the 2D mask\n",
    "\n",
    "import networkx as netx\n",
    "\n",
    "\n",
    "orthogonal = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "diagonals  = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "\n",
    "G = netx.Graph()\n",
    "\n",
    "# We extract the row number (i) and the column number (j) of each skeleton pixel:\n",
    "coords = np.argwhere(skeleton)\n",
    "\n",
    "\n",
    "# We add all the nodes\n",
    "for j, i in coords:\n",
    "    G.add_node((i, j), width=skel_dist[j, i])\n",
    "\n",
    "# We build the edges using the conditional diagonals rule\n",
    "for j, i in coords:\n",
    "    this = (i, j)\n",
    "    neighbors = set()\n",
    "    # Orthogonal neighbors:\n",
    "    for dj, di in orthogonal:\n",
    "        nj, ni = j + dj, i + di\n",
    "        if 0 <= nj < ny and 0 <= ni < nx and skeleton[nj, ni]:\n",
    "            neighbors.add((ni, nj))\n",
    "        # Diagonal neighbors only if none of the adjacent orthogonal ones are already present\n",
    "    for dj, di in diagonals:\n",
    "        nj, ni = j + dj, i + di\n",
    "        if not (0 <= nj < ny and 0 <= ni < nx and skeleton[nj, ni]):\n",
    "            continue\n",
    "        ortho1 = (i, j + dj)\n",
    "        ortho2 = (i + di, j)\n",
    "        if ortho1 not in neighbors and ortho2 not in neighbors:\n",
    "            neighbors.add((ni, nj))\n",
    "    # We add the edges\n",
    "    for nb in neighbors:\n",
    "        G.add_edge(this, nb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the skeleton on top of the boolean mask to check that everything is correct\n",
    "plt.figure(figsize=(12,8), dpi=1200)\n",
    "plt.imshow(mask, origin='lower', cmap='gray', extent=(xmin, xmax, ymin, ymax))\n",
    "# the skeleton:\n",
    "ys, xs = np.where(skeleton)\n",
    "plt.scatter(xs*dx + xmin, ys*dx + ymin, s=0.005, c='red', label='Skeleton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE EXTRACT THE JUNCTIONS AND THE TUBES\n",
    "# A junction is a node with degree > 2\n",
    "# Each simple path between two junctions is a tube\n",
    "\n",
    "\n",
    "joints = [n for n,d in G.degree() if d>2]\n",
    "print(f\"Total number of junctions (degree > 2): {len(joints)}\")\n",
    "\n",
    "tubes = []\n",
    "visited = set()\n",
    "for u in joints:\n",
    "    for v in G.neighbors(u):\n",
    "        if (u,v) in visited or (v,u) in visited: continue\n",
    "        path = [u,v]; visited.add((u,v))\n",
    "        prev, curr = u, v\n",
    "        # We continue until the next junction\n",
    "        while G.degree(curr)==2:\n",
    "            w = [w for w in G.neighbors(curr) if w!=prev][0]\n",
    "            prev, curr = curr, w\n",
    "            path.append(curr)\n",
    "            visited.add((prev,curr))\n",
    "        tubes.append(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the system of tubes and junctions to make sure everything is in order\n",
    "\n",
    "pos = {node:(xmin + i*dx, ymin + j*dy) for (j,i), node in zip(coords, G.nodes()) }\n",
    "\n",
    "# We draw the background mask:\n",
    "fig, ax = plt.subplots(figsize=(12,8), dpi=1000)\n",
    "ax.imshow(mask, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='gray', alpha=0.5)\n",
    "\n",
    "# We draw the tubes:\n",
    "for tube in tubes:\n",
    "    xs = [pos[n][0] for n in tube]\n",
    "    ys = [pos[n][1] for n in tube]\n",
    "    ax.plot(xs, ys, color='blue', linewidth=0.5)\n",
    "\n",
    "# We draw the junctions\n",
    "jx = [pos[j][0] for j in joints]\n",
    "jy = [pos[j][1] for j in joints]\n",
    "ax.scatter(jx, jy, color='red', s=3, label='Junctions')\n",
    "\n",
    "# Final adjustments\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('x(m)')\n",
    "ax.set_ylabel('y(m)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE BUILD THE HISTOGRAM OF VALID HALF-WIDTHS (ONLY MIDPOINTS)\n",
    "\n",
    "from scipy.stats import rayleigh, norm  \n",
    "\n",
    "half_widths_mid = []\n",
    "for tube in tubes:\n",
    "    mid = len(tube)//2    # central index\n",
    "    node_mid = tube[mid]\n",
    "    w_mid = G.nodes[node_mid]['width']\n",
    "    half_widths_mid.append(w_mid)\n",
    "\n",
    "half_widths_mid = np.array(half_widths_mid)\n",
    "# To have everything in mm:\n",
    "half_widths_mid_mm = half_widths_mid*1e3\n",
    "\n",
    "# Rayleigh fit:\n",
    "loc_r, sigma_r = rayleigh.fit(half_widths_mid_mm, floc=0)\n",
    "\n",
    "# Normal fit:\n",
    "mu_n, sigma_n = norm.fit(half_widths_mid_mm)\n",
    "\n",
    "# Domain for the curves:\n",
    "r = np.linspace(0, half_widths_mid_mm.max(), 200)\n",
    "\n",
    "# We plot the histogram together with the fits\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=400)\n",
    "ax.hist(half_widths_mid_mm, bins=30, density=True, alpha=0.6, color='C0', edgecolor='black', label='Simulation')\n",
    "ax.plot(r, rayleigh.pdf(r, loc=loc_r, scale=sigma_r), 'r-', lw=2, label=f'Rayleigh fit\\nσ={sigma_r:.2f} mm')\n",
    "ax.plot(r, norm.pdf(r, loc=mu_n, scale=sigma_n), 'b--', lw=2, label=f'Normal fit\\nμ={mu_n:.2f} mm\\nσ={sigma_n:.2f} mm')\n",
    "\n",
    "ax.set_xlabel(\"Half-width (mm)\")\n",
    "ax.set_ylabel(\"Probability density\")\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We also plot it on a logarithmic scale:\n",
    "bins_log = np.logspace(np.log10(half_widths_mid_mm.min()), np.log10(half_widths_mid_mm.max()), 30)\n",
    "\n",
    "plt.figure(figsize=(6,4), dpi=400)\n",
    "plt.hist(half_widths_mid_mm, bins=bins_log, color='C1', edgecolor='black' )\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Half-width (mm)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FLOW-RATE DISTRIBUTION COMPUTATION\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import LineString, Point\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "\n",
    "# We build a KDTree of the pruned skeleton pixels with their width\n",
    "pixel_nodes = np.array(list(G.nodes()))   # array de (i,j)\n",
    "pixel_xy    = np.array([\n",
    "    (xmin + i*dx, ymin + j*dy)\n",
    "    for i,j in pixel_nodes\n",
    "])\n",
    "pixel_width = np.array([\n",
    "    G.nodes[(i,j)]['width']\n",
    "    for i,j in pixel_nodes\n",
    "])\n",
    "pix_tree = cKDTree(pixel_xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We prepare a KDTree with the centroids of the obstacles\n",
    "obs_centers = np.array([[poly.centroid.x, poly.centroid.y] for poly in obs_polys])\n",
    "obs_tree    = cKDTree(obs_centers)\n",
    "\n",
    "all_pts  = []\n",
    "offsets  = [0]\n",
    "tangents = []\n",
    "half_ws  = []\n",
    "normals = []\n",
    "real_midpoints = []\n",
    "L_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We go through each tube to generate the sampling points\n",
    "for tube in tubes:\n",
    "    # Approximate index of midpoint and half-width\n",
    "    mid = len(tube) // 2\n",
    "    i, j = tube[mid]\n",
    "    x_idx, y_idx = pos[(i, j)]\n",
    "\n",
    "    # Nearest obstacle centers\n",
    "    _, idxs = obs_tree.query([x_idx, y_idx], k=2)\n",
    "    c1, c2 = obs_centers[idxs[0]], obs_centers[idxs[1]]\n",
    "\n",
    "    # Intersection between the tube axis and the line of centers\n",
    "    tube_line = LineString([pos[n] for n in tube])\n",
    "    cut_line  = LineString([c1, c2])\n",
    "    inter = tube_line.intersection(cut_line)\n",
    "    if inter.is_empty:\n",
    "        x0, y0 = x_idx, y_idx\n",
    "    else:\n",
    "        if isinstance(inter, Point):\n",
    "            x0, y0 = inter.x, inter.y\n",
    "        \n",
    "    real_midpoints.append((x0, y0))\n",
    "\n",
    "    # We find the nearest (\"real\") half-width\n",
    "    dist_px, idx_px = pix_tree.query([x0, y0])\n",
    "    w_real = pixel_width[idx_px]\n",
    "    half_ws.append(w_real)\n",
    "\n",
    "    # New “real” normal vector\n",
    "    n_hat = c2 - c1\n",
    "    n_hat /= np.linalg.norm(n_hat)\n",
    "\n",
    "    t_hat = np.array([-n_hat[1],  n_hat[0]])\n",
    "\n",
    "    # Use w_real to define D and generate the cutting line\n",
    "    D = 2 * w_real\n",
    "    line_ext = LineString([\n",
    "        (x0 - n_hat[0]*D, y0 - n_hat[1]*D),\n",
    "        (x0 + n_hat[0]*D, y0 + n_hat[1]*D),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Intersect with free_region and measure L\n",
    "    seg = line_ext.intersection(free_region)\n",
    "    if seg.is_empty:\n",
    "        L = 2*w_real\n",
    "        seg = LineString([\n",
    "            (x0 - n_hat[0]*w_real, y0 - n_hat[1]*w_real),\n",
    "            (x0 + n_hat[0]*w_real, y0 + n_hat[1]*w_real)\n",
    "        ])\n",
    "    elif seg.geom_type == \"MultiLineString\":\n",
    "        seg = max(seg.geoms, key=lambda s: s.length)\n",
    "    L = seg.length\n",
    "    L_list.append(L)\n",
    "\n",
    "    # Equally spaced sampling according to L\n",
    "    Nsamples = max(5, int(np.ceil(L / dx)))\n",
    "    ds = L / (Nsamples - 1)\n",
    "    ss = [i*ds for i in range(Nsamples)]\n",
    "    pts = [(seg.interpolate(s).x,\n",
    "            seg.interpolate(s).y,\n",
    "            z_mid) for s in ss]\n",
    "\n",
    "\n",
    "    \n",
    "    all_pts.extend(pts)\n",
    "    offsets.append(len(all_pts))\n",
    "    normals.append(n_hat)\n",
    "    tangents.append(t_hat)\n",
    "\n",
    "all_pts = np.array(all_pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# NOW, WE SAMPLE VELOCITIES:\n",
    "\n",
    "# KDTree on cell centers\n",
    "centers = vol_mesh.cell_centers().points    # (M,3)\n",
    "U_cells = vol_mesh.cell_data['U'][:, :2]    # (M,2)\n",
    "tree    = cKDTree(centers[:, :2])\n",
    "\n",
    "# Bulk query for all_pts\n",
    "dists, idxs = tree.query(all_pts[:, :2], k=1)\n",
    "Uall        = U_cells[idxs]                # (N,2)\n",
    "\n",
    "# Cleaning and verification\n",
    "Uall = np.nan_to_num(Uall, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "assert Uall.shape[0] == len(all_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of flow rates per tube using the real lengths stored in L_list\n",
    "# Preliminary checks\n",
    "assert len(L_list)   == len(tubes)\n",
    "assert len(offsets)-1 == len(tubes)\n",
    "assert all(offsets[i]<offsets[i+1] for i in range(len(tubes)))\n",
    "assert Uall.shape[0] == offsets[-1]\n",
    "\n",
    "h = 1e-3\n",
    "flow_rates = []\n",
    "for k in range(len(tubes)):\n",
    "    start, end = offsets[k], offsets[k+1]\n",
    "    Upts = Uall[start:end]    \n",
    "    t_hat = tangents[k]\n",
    "    # We use the real length L_list[k] for the step ds\n",
    "    # and ensure that ds*(len(Upts)-1) == L_list[k]\n",
    "\n",
    "    L_real = L_list[k]\n",
    "    ds = L_real / (len(Upts) - 1) if len(Upts) > 1 else 0.0\n",
    "\n",
    "    # Projection of U onto the tangent\n",
    "    u_par = Upts.dot(t_hat)\n",
    "    Qt = np.abs(np.sum(u_par * ds))*h \n",
    "    flow_rates.append(Qt)\n",
    "\n",
    "print(f\"Computed flow_rates for {len(flow_rates)} tubes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI filter\n",
    "x_min_roi = 0.002\n",
    "y_min_roi = 0.002\n",
    "y_max_roi = 0.07\n",
    "\n",
    "mp_array = np.array(real_midpoints)  # (N_tubes, 2) with (x_mid, y_mid)\n",
    "valid_tube_mask = (\n",
    "    (mp_array[:, 0] > x_min_roi) &\n",
    "    (mp_array[:, 1] >= y_min_roi) &\n",
    "    (mp_array[:, 1] <= y_max_roi)\n",
    ")\n",
    "valid_tubes_idx = np.nonzero(valid_tube_mask)[0]\n",
    "print(f\"Valid tubes in ROI: {valid_tubes_idx.size} / {len(tubes)}\")\n",
    "\n",
    "flow_rates_roi = []\n",
    "\n",
    "for k in valid_tubes_idx:\n",
    "    start, end = offsets[k], offsets[k+1]\n",
    "    Upts = Uall[start:end]\n",
    "    t_hat = tangents[k]\n",
    "\n",
    "    L_real = L_list[k]\n",
    "    ds = L_real / (len(Upts) - 1) if len(Upts) > 1 else 0.0\n",
    "\n",
    "    # Proyección de U sobre la tangente del tubo\n",
    "    u_par = Upts.dot(t_hat)\n",
    "    Qt = np.abs(np.sum(u_par * ds)) * h\n",
    "    flow_rates_roi.append(Qt)\n",
    "\n",
    "flow_rates_roi = np.array(flow_rates_roi)\n",
    "print(f\"Flow rates in ROI: {len(flow_rates_roi)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE PLOT THE FLOW-RATE DISTRIBUTION\n",
    "\n",
    "data = np.array(flow_rates_roi)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=200)\n",
    "\n",
    "# We define linear bins for the histogram\n",
    "bins = np.linspace(data.min(), data.max(), 30)\n",
    "\n",
    "# We draw the histogram\n",
    "ax.hist(data, bins=bins, alpha=0.75, edgecolor='black')\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_xscale('log'\n",
    "\n",
    "ax.set_xlabel(\"Flow rate $Q$ (m³/s)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of tubes\", fontsize=12)\n",
    "ax.set_title(\"Histogram of flow rates\", fontsize=14, pad=12)\n",
    "\n",
    "# We add a horizontal grid to make reading easier\n",
    "ax.grid(which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "rho = 1e3\n",
    "\n",
    "# WE COMPUTE THE PRESSURE-DROP DISTRIBUTION\n",
    "\n",
    "# We prepare a KDTree of cell centers for p\n",
    "centers   = vol_mesh.cell_centers().points     # (M,3)\n",
    "cell_xy   = centers[:, :2]                     # only X,Y\n",
    "p_cells   = rho*vol_mesh.cell_data['p']            # (M,)\n",
    "tree_p    = cKDTree(cell_xy)\n",
    "\n",
    "# We build a list of start/end points for each tube\n",
    "end_pts = []\n",
    "for tube in tubes:\n",
    "    # Initial node\n",
    "    i0, j0 = tube[0]\n",
    "    x0 = xmin + i0*dx\n",
    "    y0 = ymin + j0*dy\n",
    "    end_pts.append((x0, y0))\n",
    "    # Final node\n",
    "    i1, j1 = tube[-1]\n",
    "    x1 = xmin + i1*dx\n",
    "    y1 = ymin + j1*dy\n",
    "    end_pts.append((x1, y1))\n",
    "\n",
    "end_pts = np.array(end_pts)  # shape (2*N_tubes, 2)\n",
    "\n",
    "# Bulk query of p\n",
    "_, idxs = tree_p.query(end_pts, k=1)\n",
    "p_vals  = p_cells[idxs]     # (2*N_tubes,)\n",
    "\n",
    "# Real pressure drop per tube\n",
    "N = len(tubes)\n",
    "dp = np.empty(N)\n",
    "for k in range(N):\n",
    "    p_start = p_vals[2*k]\n",
    "    p_end   = p_vals[2*k + 1]\n",
    "    dp[k]   = abs(p_start - p_end)\n",
    "\n",
    "# Lengths of each tube (correcting dy) \n",
    "lengths = []\n",
    "for tube in tubes:\n",
    "    L = 0.0\n",
    "    for a, b in zip(tube[:-1], tube[1:]):\n",
    "        i1, j1 = a\n",
    "        i2, j2 = b\n",
    "        p1 = np.array([xmin + i1*dx, ymin + j1*dy])\n",
    "        p2 = np.array([xmin + i2*dx, ymin + j2*dy])\n",
    "        L += np.linalg.norm(p2 - p1)\n",
    "    lengths.append(L)\n",
    "lengths = np.array(lengths)\n",
    "\n",
    "# Theoretical pressure drop (Poiseuille)\n",
    "h = 1e-3\n",
    "mu       = 1e-3  # Pa·s\n",
    "Q = np.array(flow_rates)           \n",
    "L_sec = np.array(L_list)            # widhts (2a)\n",
    "a_list = 0.5 * L_sec                # halfwidths\n",
    "r = h / np.sqrt(12)                 # r = h/√12\n",
    "\n",
    "dp_pois = (3.0*mu*lengths*Q)/(2.0*h*a_list**3)\n",
    "\n",
    "print(\"Average parameters (in SI):\")\n",
    "print(f\"  h = {h} m\")\n",
    "print(f\"  mu = {mu} Pa·s\")\n",
    "print(f\"  mean(a_list) = {a_list.mean():.3e} m\")\n",
    "print(f\"  mean(lengths) = {lengths.mean():.3e} m\")\n",
    "print(f\"  mean(Q) = {Q.mean():.3e} m³/s\")\n",
    "ratio = dp_pois.mean() / dp.mean()\n",
    "print(f\"Ratio ⟨dp_pois⟩/⟨dp⟩ = {ratio:.3e}\")\n",
    "\n",
    "# Comparative histogram\n",
    "min_nz = min(dp[dp > 0].min(), dp_pois[dp_pois > 0].min())\n",
    "max_v = max(dp.max(), dp_pois.max())\n",
    "bins = np.logspace(np.log10(min_nz), np.log10(max_v), 30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=200)\n",
    "ax.hist(dp,      bins=bins, alpha=0.6, edgecolor='black', label='Real ΔP')\n",
    "ax.hist(dp_pois, bins=bins, histtype='step', linestyle='--',\n",
    "        linewidth=2, color='red', label='Theoretic ΔP')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Pressure drop ΔP (Pa)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of tubes\", fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(which='both', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE COMPUTE POROSITY:\n",
    "phi = mask.mean()  \n",
    "print(f\"Porosidad φ = {phi:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE PLOT THE TUBES COLORED ACCORDING TO THEIR FLOW RATE\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import LogNorm, LinearSegmentedColormap\n",
    "\n",
    "\n",
    "segments   = [np.array([pos[n] for n in tube]) for tube in tubes]\n",
    "flow_array = np.array(flow_rates)\n",
    "\n",
    "# Colormap y escala log\n",
    "cmap = LinearSegmentedColormap.from_list(\"BlueRed\", [\"blue\",\"red\"])\n",
    "norm = LogNorm(vmin=flow_array[flow_array>0].min(), vmax=flow_array.max())\n",
    "\n",
    "lc = LineCollection(segments, cmap=cmap, norm=norm, linewidth=1.5)\n",
    "lc.set_array(flow_array)\n",
    "\n",
    "# A pintar\n",
    "fig, ax = plt.subplots(figsize=(12,8), dpi=400)\n",
    "\n",
    "ax.imshow(mask, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='Greys_r', alpha=0.4)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")\n",
    "\n",
    "cbar = fig.colorbar(lc, ax=ax, shrink=0.5, pad=0.02)\n",
    "cbar.set_label(\"Flow rate $Q$ (m³/s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import LogNorm, LinearSegmentedColormap\n",
    "\n",
    "# A MORE PROFESSIONAL VERSION OF LAST PLOT\n",
    "\n",
    "# Global style parameters \n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 14,               \n",
    "    'axes.titlesize': 18,          \n",
    "    'axes.labelsize': 16,          \n",
    "    'xtick.labelsize': 14,         \n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 14,         \n",
    "    'lines.linewidth': 1,          \n",
    "    'xtick.major.width': 1.2,\n",
    "    'ytick.major.width': 1.2,\n",
    "    'xtick.major.size': 6,\n",
    "    'ytick.major.size': 6,\n",
    "})\n",
    "\n",
    "# We prepare the tube data\n",
    "segments   = [np.array([pos[n] for n in tube]) for tube in tubes]\n",
    "flow_array = np.array(flow_rates)\n",
    "\n",
    "# Colormap and logarithmic scale\n",
    "cmap = LinearSegmentedColormap.from_list(\"BlueRed\", [\"blue\", \"red\"])\n",
    "norm = LogNorm(vmin=flow_array[flow_array > 0].min(), vmax=flow_array.max())\n",
    "\n",
    "lc = LineCollection(segments, cmap=cmap, norm=norm, linewidth=1.5)\n",
    "lc.set_array(flow_array) \n",
    "\n",
    "# Figure size: full-width A4 at 300 dpi\n",
    "width_cm  = 21              # width of A4 in centimeters\n",
    "width_in  = width_cm / 2.54 # conversion to inches\n",
    "aspect    = (ymax - ymin) / (xmax - xmin)\n",
    "height_in = width_in * aspect\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width_in, height_in), dpi=300)\n",
    "\n",
    "# Drawing of the mask and the colored lines\n",
    "ax.imshow(mask,\n",
    "          origin='lower',\n",
    "          extent=(xmin, xmax, ymin, ymax),\n",
    "          cmap='Greys_r',\n",
    "          alpha=0.4)\n",
    "\n",
    "ax.add_collection(lc)\n",
    "\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(lc, ax=ax, shrink=0.8, pad=0.02)\n",
    "cbar.ax.tick_params(labelsize=14, width=1.2, length=6)\n",
    "cbar.set_label(\"Flow rate $Q$ (m³/s)\", fontsize=16, labelpad=10)\n",
    "\n",
    "# Final adjustment and saving\n",
    "plt.tight_layout(pad=2)\n",
    "fig.savefig(\"caudales_A4.png\", dpi=300)  # listo para tu artículo\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE COMPUTE THE BEAD-SIZES DISTRIBUTION:\n",
    "\n",
    "radii_obs = np.array([ np.sqrt(poly.area / np.pi) for poly in obs_polys])\n",
    "\n",
    "# we convert to mm:\n",
    "radii_mm = radii_obs * 1e3\n",
    "print(f\"Number of beads: {len(radii_mm)}\")\n",
    "print(f\"Minimum radius: {radii_mm.min():.3f} mm, maximum: {radii_mm.max():.3f} mm\")\n",
    "print(f\"Mean radius = {radii_mm.mean()} mm\")\n",
    "\n",
    "\n",
    "\n",
    "# histogram of obstacle radii:\n",
    "plt.figure(figsize=(6,4), dpi=150)\n",
    "plt.hist(radii_mm, bins=20, edgecolor='black', alpha=0.8)\n",
    "plt.xlabel(\"Bead radius (mm)\", fontsize=12)\n",
    "plt.ylabel(\"Number of beads\", fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the Pearson correlation in the bead size\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "# We have the radii (in radii_mm), but we need the obstacle centers:\n",
    "centers = np.array([[poly.centroid.x, poly.centroid.y] for poly in obs_polys])\n",
    "\n",
    "r_mean = radii_mm.mean()\n",
    "print(r_mean)\n",
    "r_var = radii_mm.var()\n",
    "delta_r = radii_mm - r_mean\n",
    "\n",
    "# Distances and pairwise products of fluctuations:\n",
    "dists = pdist(centers) # distances in meters\n",
    "outer = np.outer(delta_r, delta_r)\n",
    "i_upper = np.triu_indices(len(radii_mm), k=1)\n",
    "prods = outer[i_upper]\n",
    "\n",
    "# we convert the distances to mm:\n",
    "dists_mm = dists*1e3\n",
    "\n",
    "nbins = 500\n",
    "max_d = 60.0 #mm\n",
    "min_d = dists_mm.min()\n",
    "bins = np.linspace(min_d, max_d, nbins+1)\n",
    "bin_centers = 0.5*(bins[:-1] + bins[1:])\n",
    "\n",
    "\n",
    "# we compute C(d)\n",
    "sum_prod, _ = np.histogram(dists_mm, bins=bins, weights=prods)\n",
    "counts, _ = np.histogram(dists_mm, bins=bins)\n",
    "C_d = np.zeros_like(bin_centers)\n",
    "mascara = counts>0\n",
    "C_d[mascara] = sum_prod[mascara]/(counts[mascara]*r_var)\n",
    "\n",
    "# Time to plot!\n",
    "plt.figure(figsize=(6,4), dpi=400)\n",
    "plt.plot(bin_centers, C_d, '-', linewidth=1, color='C0')\n",
    "plt.xlim(min_d, 20)\n",
    "plt.xlabel(\"Distance $d$ (mm)\", fontsize=12)\n",
    "plt.ylabel(\"Spatial correlation $C(d)$\", fontsize=12)\n",
    "plt.grid(ls='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow rate correlation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dz = 1e-3  # fixed thickness in z\n",
    "\n",
    "\n",
    "assert len(tubes) == len(real_midpoints) == len(tangents) == len(L_list)\n",
    "assert offsets[-1] == len(all_pts) == Uall.shape[0]\n",
    "\n",
    "\n",
    "flows = np.array(flow_rates)\n",
    "junction_type = {}\n",
    "\n",
    "\n",
    "# We list the tubes that converge at each node\n",
    "tube_index = {}\n",
    "for idx, tube in enumerate(tubes):\n",
    "    for node in tube:\n",
    "        tube_index.setdefault(node, []).append(idx)\n",
    "\n",
    "# We detect the degree-3 junctions\n",
    "junc3 = [n for n, d in G.degree() if d == 3]\n",
    "\n",
    "# We reorient the tangents based on the average projection of Uall\n",
    "n_tubes   = len(tubes)\n",
    "proj_mean = np.empty(n_tubes)\n",
    "for i in range(n_tubes):\n",
    "    start, end = offsets[i], offsets[i+1]\n",
    "    v_sec      = Uall[start:end]         # velocidades XY en la sección\n",
    "    proj_mean[i] = v_sec.dot(tangents[i]).mean()\n",
    "oriented_tangents = tangents * np.sign(proj_mean)[:, None]\n",
    "\n",
    "# Initialize counters\n",
    "sum_prods      = 0.0\n",
    "count_prods    = 0\n",
    "type1_count    = 0\n",
    "type2_count    = 0\n",
    "sum_t1_prods = 0.0\n",
    "sum_t2_prods = 0.0\n",
    "qbig = []\n",
    "qsmall = []\n",
    "qbig_out = []\n",
    "qsmall_out = []\n",
    "qbig_in = []\n",
    "qsmall_in = []\n",
    "omega = []\n",
    "clas_tubes = np.zeros((n_tubes, 2), dtype=int)\n",
    "\n",
    "\n",
    "# Classification \"towards/from the junction\" using real_midpoints\n",
    "for j in junc3:\n",
    "    idxs = tube_index.get(j, [])\n",
    "    if len(idxs) != 3:\n",
    "        continue\n",
    "\n",
    "    qs    = flows[idxs]\n",
    "    i_max = idxs[np.argmax(qs)]\n",
    "\n",
    "    x0, y0   = real_midpoints[i_max]       # section of tube i_max\n",
    "    xj, yj   = pos[j]                      # position of the junction\n",
    "    v2j      = np.array((xj - x0, yj - y0)) # section → junction vector\n",
    "\n",
    "    dp = oriented_tangents[i_max].dot(v2j)\n",
    "\n",
    "    others = [i for i in idxs if i != i_max]\n",
    "    if len(others) < 2:\n",
    "        # Rare case: there are not two tubes besides the maximum one, so we skip it\n",
    "        continue\n",
    "\n",
    "    #if not all(valid_tube_mask[idx] for idx in idxs):\n",
    "        #continue\n",
    "\n",
    "\n",
    "    if dp > 0:\n",
    "        # Type 2 junction: tube i_max is a feeder → two receivers\n",
    "        for o in others:\n",
    "            q1, q2 = flows[i_max], flows[o]\n",
    "            sum_t2_prods += q1*q2\n",
    "            #count_prods += 1\n",
    "            omega.append(q2/q1)\n",
    "            omega.append(0)\n",
    "            qsmall.append(q2)\n",
    "            qsmall_in.append(q2)\n",
    "        qbig_out.append(q1)\n",
    "        qbig.append(q1)\n",
    "        sum_prods += flows[others[0]]*flows[others[1]]\n",
    "        count_prods += 1\n",
    "        type2_count += 1\n",
    "        clas_tubes[i_max, 1] = 1 \n",
    "        junction_type[j] = 2 \n",
    "\n",
    "        \n",
    "    else:\n",
    "        # Type 1 junction: tube i_max is a receiver ← two feeders\n",
    "        q1, q2 = flows[others[0]], flows[others[1]]\n",
    "        sum_prods      += q1 * q2\n",
    "        count_prods    += 1\n",
    "        type1_count    += 1\n",
    "        sum_t1_prods += q1 * q2\n",
    "        qbig.append(flows[i_max])\n",
    "        qbig_in.append(flows[i_max])\n",
    "        qsmall.append(q1)\n",
    "        qsmall.append(q2)\n",
    "        qsmall_out.append(q1)\n",
    "        qsmall_out.append(q2)\n",
    "        omega.append(q1/flows[i_max])\n",
    "        omega.append(q2/flows[i_max])\n",
    "        omega.append(1)\n",
    "        omega.append(1)\n",
    "        clas_tubes[i_max, 0] = 1\n",
    "        junction_type[j] = 1  \n",
    "        \n",
    "\n",
    "qbig = np.array(qbig)\n",
    "qsmall = np.array(qsmall)\n",
    "\n",
    "# Global pearson\n",
    "mean_q   = flows.mean()\n",
    "E_qiqj   = sum_prods / count_prods\n",
    "cov_qiqj = E_qiqj - qsmall.mean()**2\n",
    "var_q    = qsmall.var()\n",
    "pearson  = cov_qiqj / var_q if var_q != 0 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Type 1 Junctions  (2→1): {type1_count}\")\n",
    "print(f\"Tyope 2 junctions (1→2): {type2_count}\")\n",
    "print(f\"E[q_i·q_j] global       = {E_qiqj:.3e}\")\n",
    "print(f\"Pearson global          = {pearson:.3e}\")\n",
    "\n",
    "# Pearson only feeders \n",
    "if type1_count > 0:\n",
    "    E_t1_prod  = sum_t1_prods / type1_count\n",
    "    cov_feed     = E_t1_prod - qsmall.mean()**2\n",
    "    pearson_feed = cov_feed / qsmall.var()\n",
    "    print(f\"Number of Type 1 junctions             = {type1_count}\")\n",
    "    print(f\"E[q1*q2] for feeders        = {E_t1_prod:.3e}\")\n",
    "    print(f\"Pearson corr. for feeders (Type 1) = {pearson_feed:.3e}\")\n",
    "    print(E_t1_prod)\n",
    "else:\n",
    "    print(\"There are no Type 1 junctions\")\n",
    "\n",
    "\n",
    "print(\"mean_q = \", mean_q)\n",
    "print(\"var_q =\", flows.var())\n",
    "print(\"cov_small =\",cov_qiqj )\n",
    "print(\"E[q1*q2] en type 1\", E_t1_prod)\n",
    "E_t2_prod = sum_t2_prods/(2.0*type2_count)\n",
    "print(\"E[q1*q2] en type 2\", E_t2_prod)\n",
    "print(\"qbig mean = \", qbig.mean())\n",
    "print(\"qbig var = \", qbig.var())\n",
    "print(\"qsmall mean = \", qsmall.mean())\n",
    "print(\"qsmall var = \", qsmall.var())\n",
    "\n",
    "\n",
    "big_in  = clas_tubes[:, 0] == 1\n",
    "big_out = clas_tubes[:, 1] == 1\n",
    "\n",
    "\n",
    "n_bigin_bigout   = np.sum(big_in  & big_out)\n",
    "n_bigin_smallout = np.sum(big_in  & ~big_out)\n",
    "n_smallin_bigout = np.sum(~big_in & big_out)\n",
    "n_smallin_smallout = np.sum(~big_in & ~big_out)\n",
    "\n",
    "\n",
    "print(f\"Number of big‑in & big‑out      : {n_bigin_bigout}\")\n",
    "print(f\"Number of big‑in & small‑out    : {n_bigin_smallout}\")\n",
    "print(f\"Number of small‑in & big‑out    : {n_smallin_bigout}\")\n",
    "print(f\"Number of small‑in & small‑out  : {n_smallin_smallout}\")\n",
    "\n",
    "# Save flows and the triplets of junc3 into a text file\n",
    "with open(\"flows_and_junctions.txt\", \"w\") as f:\n",
    "    # Number of elements in flows\n",
    "    f.write(f\"{len(flows)}\\n\")\n",
    "    \n",
    "    # All flow values, one per line\n",
    "    for val in flows:\n",
    "        f.write(f\"{val}\\n\")\n",
    "\n",
    "    # Triplets of tube indices corresponding to each degree-3 junction\n",
    "    for j in junc3:\n",
    "        idxs = tube_index.get(j, [])\n",
    "        jtype = junction_type.get(j, -1)\n",
    "        if len(idxs) == 3:\n",
    "            f.write(f\"{jtype} {idxs[0]} {idxs[1]} {idxs[2]}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "\n",
    "# WE PLOT  THE SPLITTING FRACTIONS DISTRIBUTION\n",
    "\n",
    "# Nice style:\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.color\": \"#dddddd\",\n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"xtick.direction\": \"out\",\n",
    "    \"ytick.direction\": \"out\",\n",
    "})\n",
    "\n",
    "omega = np.array(omega)\n",
    "\n",
    "hist, bins = np.histogram(omega, bins=20, density=True)\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "fig, ax = plt.subplots(dpi=400)\n",
    "\n",
    "line_hist, = ax.plot(bin_centers, hist, '-', lw=2, label=\"Sampled histogram\")\n",
    "ax.plot(bin_centers, hist, 'o', ms=4, color=line_hist.get_color())\n",
    "\n",
    "\n",
    "# Beta fit:\n",
    "a = 1/7\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = beta.pdf(x, a, a)  # PDF of Beta(a,a)\n",
    "\n",
    "ax.plot(x, pdf, 'r-', lw=2, label='Beta approximation')\n",
    "\n",
    "ax.set_xlabel(\"Mean field splitting fraction U\", fontsize=16)\n",
    "ax.set_ylabel(\"Probability density\", fontsize=16)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylim(0, 5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"fractions_histogram_MF.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "print(omega.var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.special import gamma, gammaincc, erf\n",
    "\n",
    "\n",
    "# WE PLOT THE TOTAL FLOW DISTRIBUTION AND COMPARE WITH ANALYTICAL EXPRESSIONS\n",
    "\n",
    "data      = np.array(flow_rates_roi)           \n",
    "c_mean    = data.mean()               \n",
    "var_data  = data.var(ddof=1)          \n",
    "\n",
    "# Parameters of our model \n",
    "mean_big = qbig.mean()         \n",
    "var_big = qbig.var(ddof=1)\n",
    "k = 25/3\n",
    "theta = mean_big/k\n",
    "# Parameters for Alim's model\n",
    "a_param = 1/7                       \n",
    "\n",
    "\n",
    "x = np.linspace(data.min(), data.max(), 300)\n",
    "\n",
    "# PDF functions\n",
    "def gQ(q, a, mu):\n",
    "    \"\"\"Gamma approx. of Alim's solution\"\"\"\n",
    "    return ((2*a)**(2*a) / gamma(2*a)) * q**(2*a - 1) * np.exp(-2*a*q/mu) / (mu**(2*a))\n",
    "\n",
    "def f_exact(q, c):\n",
    "    \"\"\"Alim's exact solution (sin delta)\"\"\"\n",
    "    term1 = q / (8*c**2)\n",
    "    term2 = np.exp(-q/(4*c)) / (2*np.sqrt(np.pi*c*q)) * (1 - q/(2*c))\n",
    "    term3 = - q/(8*c**2) * erf(np.sqrt(q)/(2*np.sqrt(c)))\n",
    "    return term1 + term2 + term3\n",
    "\n",
    "def fQ(q, k, theta):\n",
    "    \"\"\"Model prediction f_Q(q;k,θ)\"\"\"\n",
    "    term1 = (2/3) * (gamma(k-1) * gammaincc(k-1, q/theta)) / (gamma(k) * theta)\n",
    "    term2 = (1/3) * (q**(k-1) * np.exp(-q/theta)) / (gamma(k) * theta**k)\n",
    "    return term1 + term2\n",
    "\n",
    "# we evaluate\n",
    "pdf_g   = gQ(x, a_param, c_mean)\n",
    "pdf_f   = f_exact(x, c_mean)\n",
    "pdf_mod = fQ(x, k, theta)   \n",
    "\n",
    "# we plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=200)\n",
    "\n",
    "bins = np.linspace(data.min(), data.max(), 30)\n",
    "hist_vals, _ = np.histogram(data, bins=bins, density=True)\n",
    "centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "line_h, = ax.plot(centers, hist_vals, '-', lw=2, label='Sampled distribution (throats)')\n",
    "ax.plot(centers, hist_vals, 'o', ms=4, color=line_h.get_color())  \n",
    "\n",
    "# Model prediction\n",
    "ax.plot(x, pdf_mod, lw=1.2, linestyle='-.', alpha=0.9, color='C3', label=\"Model prediction\")\n",
    "\n",
    "# Gamma approx. of Alim's solution\n",
    "#ax.plot(x, pdf_g, lw=1.2, linestyle='--', alpha=0.9, color='black', label=\"Gamma approx. of Alim's solution\")\n",
    "\n",
    "\"\"\" # Alim's exact solution\n",
    "ax.plot(x, pdf_f, lw=1.2, linestyle='--', alpha=0.9, color='C1', label=\"Mean-field prediction\") \"\"\"\n",
    "\n",
    "ax.set_xlabel(\"Flow rate $Q$ (m³/s)\", fontsize=14)\n",
    "ax.set_ylabel(\"Probability density\", fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.grid(which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax.set_ylim(0, 1.1e11)\n",
    "\n",
    "plt.rcParams['axes.formatter.use_mathtext'] = True\n",
    "fmt = ScalarFormatter(useMathText=True)\n",
    "fmt.set_scientific(True)\n",
    "fmt.set_powerlimits((0, 0))  # fuerza mostrar × 10^{n}\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "ax.yaxis.set_major_formatter(fmt)\n",
    "ax.xaxis.get_offset_text().set_size(12)\n",
    "ax.yaxis.get_offset_text().set_size(12)\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('histogram_comparison.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.stats import gamma as gamma_dist\n",
    "from scipy.special import gamma as gamma_func, gammaincc\n",
    "\n",
    "#WE PLOT BIG AND SMALL TUBES DISTRIBUTIONS\n",
    "\n",
    "plt.rcParams['axes.formatter.use_mathtext'] = True\n",
    "plt.rcParams['axes.formatter.limits'] = (0, 0)  # siempre científica (10^{n})\n",
    "\n",
    "data_big_in = np.array(qbig_in)\n",
    "data_big_out = np.array(qbig_out)\n",
    "data_small_in = np.array(qsmall_in)\n",
    "data_small_out = np.array(qsmall_out)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), dpi=200)\n",
    "\n",
    "# BIG\n",
    "\n",
    "bins_big = np.linspace(\n",
    "    min(data_big_in.min(), data_big_out.min()),\n",
    "    max(data_big_in.max(), data_big_out.max()),\n",
    "    30\n",
    ")\n",
    "hist_big_in, _ = np.histogram(data_big_in, bins=bins_big, density=True)\n",
    "hist_big_out, _ = np.histogram(data_big_out, bins=bins_big, density=True)\n",
    "centers_big = 0.5 * (bins_big[:-1] + bins_big[1:])\n",
    "\n",
    "line_bi, = ax1.plot(centers_big, hist_big_in, '-', lw=2, label=r'Pore flows')\n",
    "ax1.plot(centers_big, hist_big_in, 'o', ms=4, color=line_bi.get_color())\n",
    "\n",
    "\"\"\" line_bo, = ax1.plot(centers_big, hist_big_out, '-', lw=2, label=r'$\\mathit{big\\text{-}out}$ tubes')\n",
    "ax1.plot(centers_big, hist_big_out, 'o', ms=4, color=line_bo.get_color())\n",
    " \"\"\"\n",
    "mean_big = qbig.mean()          \n",
    "var_big = data_big_in.var(ddof=1)\n",
    "k_big = 25/3\n",
    "theta_big = mean_big/k_big\n",
    "\n",
    "x_big = np.linspace(bins_big.min(), bins_big.max(), 300)\n",
    "pdf_gamma_big = gamma_dist.pdf(x_big, k_big, loc=0, scale=theta_big)\n",
    "ax1.plot(x_big, pdf_gamma_big, lw=1, linestyle='--', alpha=0.8, color='black', label='Gamma fit')\n",
    "\n",
    "ax1.set_xlabel(\"Flow rate $Q$ (m³/s)\", fontsize=14)\n",
    "ax1.set_ylabel(\"Probability density\", fontsize=14)\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "ax1.grid(which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax1.legend(fontsize=12)\n",
    "\n",
    "# SMALL\n",
    "bins_small = np.linspace(\n",
    "    min(data_small_in.min(), data_small_out.min()),\n",
    "    max(data_small_in.max(), data_small_out.max()),\n",
    "    30\n",
    ")\n",
    "hist_small_in, _ = np.histogram(data_small_in, bins=bins_small, density=True)\n",
    "hist_small_out, _ = np.histogram(data_small_out, bins=bins_small, density=True)\n",
    "centers_small = 0.5 * (bins_small[:-1] + bins_small[1:])\n",
    "\n",
    "line_si, = ax2.plot(centers_small, hist_small_in, '-', lw=2, label=r'$\\mathit{small\\text{-}in}$ tubes')\n",
    "ax2.plot(centers_small, hist_small_in, 'o', ms=4, color=line_si.get_color())\n",
    "\n",
    "line_so, = ax2.plot(centers_small, hist_small_out, '-', lw=2, label=r'$\\mathit{small\\text{-}out}$ tubes')\n",
    "ax2.plot(centers_small, hist_small_out, 'o', ms=4, color=line_so.get_color())\n",
    "\n",
    "x_small = np.linspace(bins_small.min(), bins_small.max(), 300)\n",
    "pdf_model = (gamma_func(k_big - 1) * gammaincc(k_big - 1, x_small / theta_big)) / (gamma_func(k_big) * theta_big)\n",
    "ax2.plot(x_small, pdf_model, lw=1, linestyle='--', alpha=0.8, color='black', label='Model prediction')\n",
    "\n",
    "ax2.set_xlabel(\"Flow rate $Q$ (m³/s)\", fontsize=14)\n",
    "ax2.tick_params(axis='both', labelsize=12)\n",
    "ax2.grid(which='major', axis='y', linestyle='--', linewidth=0.5, alpha=1.0)\n",
    "ax2.legend(fontsize=12)\n",
    "\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "pe_halo = [pe.Stroke(linewidth=3, foreground='white'), pe.Normal()]\n",
    "ax1.lines[-1].set_path_effects(pe_halo)  \n",
    "ax2.lines[-1].set_path_effects(pe_halo)  \n",
    "\n",
    "fmt = ScalarFormatter(useMathText=True)\n",
    "fmt.set_scientific(True)\n",
    "fmt.set_powerlimits((0, 0))  \n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.xaxis.set_major_formatter(fmt)\n",
    "    ax.yaxis.set_major_formatter(fmt)\n",
    "    ax.xaxis.get_offset_text().set_size(12)\n",
    "    ax.yaxis.get_offset_text().set_size(12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig('histograms.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== FILTRO DE JUNCTIONS / TUBOS POR ROI EN X Y CONSTRUCCIÓN DE LINKS DEL GRAFO ====\n",
    "# Requisitos previos: tubes, flows, oriented_tangents, real_midpoints, pos, tube_index, junc3, G ya definidos.\n",
    "\n",
    "# Parámetros de la \"ventana\" en x:\n",
    "x_lo = 0.002\n",
    "x_hi = 0.11\n",
    "\n",
    "# --- Helpers sobre tubos y junctions ---\n",
    "def tube_end_junctions(k):\n",
    "    \"\"\"Devuelve las junction-nodes (pix coords) en los extremos del tubo k.\"\"\"\n",
    "    # Los extremos de cada \"tube\" son nodos-junction (degree>2) por construcción:\n",
    "    a_node = tubes[k][0]\n",
    "    b_node = tubes[k][-1]\n",
    "    return a_node, b_node\n",
    "\n",
    "def junction_x(j):\n",
    "    return pos[j][0]\n",
    "\n",
    "def tube_both_sides_out(k):\n",
    "    \"\"\"True si los DOS extremos están fuera de [x_lo, x_hi] y además en el mismo lado (ambos < x_lo o ambos > x_hi).\"\"\"\n",
    "    ja, jb = tube_end_junctions(k)\n",
    "    xa, xb = junction_x(ja), junction_x(jb)\n",
    "    left  = (xa < x_lo) and (xb < x_lo)\n",
    "    right = (xa > x_hi) and (xb > x_hi)\n",
    "    return left or right\n",
    "\n",
    "def tube_crosses_x_window(k):\n",
    "    \"\"\"True si un extremo está fuera y el otro dentro (cruza las rectas x=x_lo o x=x_hi).\"\"\"\n",
    "    ja, jb = tube_end_junctions(k)\n",
    "    xa, xb = junction_x(ja), junction_x(jb)\n",
    "    inside_a = (x_lo <= xa <= x_hi)\n",
    "    inside_b = (x_lo <= xb <= x_hi)\n",
    "    return (inside_a != inside_b)\n",
    "\n",
    "# --- (1) Filtrar junctions junc3 por x ---\n",
    "junc3_filtered = [j for j in junc3 if (x_lo <= junction_x(j) <= x_hi)]\n",
    "\n",
    "# --- (2) Eliminar tubos completamente a un lado y reindexar todo lo que dependa del índice del tubo ---\n",
    "n_tubes = len(tubes)\n",
    "keep_mask = np.ones(n_tubes, dtype=bool)\n",
    "for k in range(n_tubes):\n",
    "    if tube_both_sides_out(k):\n",
    "        keep_mask[k] = False\n",
    "\n",
    "old_to_new = {}\n",
    "new_index = 0\n",
    "for k in range(n_tubes):\n",
    "    if keep_mask[k]:\n",
    "        old_to_new[k] = new_index\n",
    "        new_index += 1\n",
    "# nuevo número de tubos:\n",
    "n_tubes_kept = new_index\n",
    "\n",
    "# Reempaquetamos arrays/listas indexadas por tubo\n",
    "tubes_kept           = [tubes[k] for k in range(n_tubes) if keep_mask[k]]\n",
    "flows_kept           = np.array([flows[k] for k in range(n_tubes) if keep_mask[k]], dtype=float)\n",
    "oriented_tangents_kept = [oriented_tangents[k] for k in range(n_tubes) if keep_mask[k]]\n",
    "real_midpoints_kept  = [real_midpoints[k] for k in range(n_tubes) if keep_mask[k]]\n",
    "L_list_kept          = [L_list[k] for k in range(n_tubes) if keep_mask[k]] if 'L_list' in globals() else None\n",
    "\n",
    "# --- Rehacer el índice \"tube_index\" (lista de tubos incidentes en cada nodo del grafo) con los índices nuevos ---\n",
    "tube_index_kept = {}\n",
    "for j,node_tubes in tube_index.items():\n",
    "    kept = [old_to_new[k] for k in node_tubes if keep_mask[k]]\n",
    "    if kept:\n",
    "        tube_index_kept[j] = kept\n",
    "\n",
    "# --- Actualizar junc3 → ya filtradas y con tubos reindexados (pueden pasar a tener 1,2 o 3 tubos) ---\n",
    "juncs_after = []\n",
    "for j in junc3_filtered:\n",
    "    if j in tube_index_kept:\n",
    "        juncs_after.append(j)\n",
    "# (Si alguna junction filtrada pierde todos los tubos, se descarta.)\n",
    "\n",
    "# --- (3) Añadir junctions de un solo tubo para extremos FUERA cuando el tubo cruza la ventana en x ---\n",
    "#     Creamos IDs sintéticos para \"junctions de corte\" de la forma (\"cut\", old_k, side)\n",
    "#     Nota: no hacen falta coordenadas nuevas para escribir el fichero de links; si las quieres,\n",
    "#     podrías calcular la intersección con x=x_lo/x_hi. Aquí guardamos una coordenada aproximada\n",
    "#     (el nodo exterior ya tiene posición en 'pos').\n",
    "synthetic_juncs = []           # lista de IDs de junctions sintéticas\n",
    "synthetic_pos   = {}           # ID -> (x,y)\n",
    "synthetic_incidence = {}       # ID -> [tube_index (nuevo)]\n",
    "\n",
    "def add_synthetic_for_endpoint(j_ext, new_k):\n",
    "    \"\"\"Añade una junction sintética 'de un tubo' para el extremo exterior j_ext del tubo new_k.\"\"\"\n",
    "    key = (\"cut\", new_k, j_ext)  # único por tubo y nodo exterior\n",
    "    if key not in synthetic_pos:\n",
    "        synthetic_pos[key] = pos[j_ext]  # coordenadas del nodo \"exterior\" original\n",
    "        synthetic_incidence[key] = [new_k]\n",
    "        synthetic_juncs.append(key)\n",
    "\n",
    "# Detectar cruces y añadir junctions de un tubo\n",
    "for old_k in range(n_tubes):\n",
    "    if not keep_mask[old_k]:\n",
    "        continue\n",
    "    new_k = old_to_new[old_k]\n",
    "    ja, jb = tube_end_junctions(old_k)\n",
    "    xa, xb = junction_x(ja), junction_x(jb)\n",
    "    inside_a = (x_lo <= xa <= x_hi)\n",
    "    inside_b = (x_lo <= xb <= x_hi)\n",
    "    if inside_a and inside_b:\n",
    "        continue  # totalmente dentro\n",
    "    if not inside_a and not inside_b:\n",
    "        continue  # ambos fuera: ya descartado más arriba\n",
    "    # exactamente uno fuera → añadimos junction sintética para el \"fuera\"\n",
    "    if not inside_a:\n",
    "        add_synthetic_for_endpoint(ja, new_k)\n",
    "    if not inside_b:\n",
    "        add_synthetic_for_endpoint(jb, new_k)\n",
    "\n",
    "# --- Fusionar las junctions finales: reales (dentro de la ventana y con tubos) + sintéticas ---\n",
    "#     Mantenemos un diccionario de incidencia (junction -> lista de tubos incidentes) con índices NUEVOS.\n",
    "junction_to_tubes = {}\n",
    "\n",
    "# Reales dentro (pueden tener 1,2,3 tubos tras el filtrado)\n",
    "for j in juncs_after:\n",
    "    junction_to_tubes[j] = list(tube_index_kept.get(j, []))\n",
    "\n",
    "# Sintéticas (1 solo tubo)\n",
    "for jid in synthetic_juncs:\n",
    "    junction_to_tubes[jid] = list(synthetic_incidence[jid])\n",
    "\n",
    "# --- (4) Construcción de links dirigidos según sentido del flujo y escritura de fichero ---\n",
    "# Para cada tubo (índice nuevo), determinamos su junc_in (upstream) y junc_out (downstream)\n",
    "# usando la tangente orientada en el midpoint.\n",
    "# Luego calculamos los pesos normalizando por el caudal que SALE de cada junction origen.\n",
    "\n",
    "# 4.1: Mapeo (tubo -> par de junctions finales que toca dentro de nuestro conjunto)\n",
    "#      Para extremos fuera, usamos la junction sintética correspondiente si existiese.\n",
    "from collections import defaultdict\n",
    "\n",
    "def endpoint_junction_id(old_k, which):\n",
    "    \"\"\"Devuelve el ID de junction (real o sintética) en el extremo 'which' (0 para inicio, 1 para final)\n",
    "       del tubo old_k, usando índices NUEVOS y ventana en x.\"\"\"\n",
    "    ja, jb = tube_end_junctions(old_k)\n",
    "    j_ext = ja if which == 0 else jb\n",
    "    xj = junction_x(j_ext)\n",
    "    inside = (x_lo <= xj <= x_hi)\n",
    "    new_k = old_to_new[old_k]\n",
    "    if inside:\n",
    "        # si está dentro y además está en la lista final de junctions:\n",
    "        if j_ext in junction_to_tubes:\n",
    "            return j_ext\n",
    "        else:\n",
    "            # podría no estar si perdió todos sus tubos salvo éste; la añadimos:\n",
    "            junction_to_tubes.setdefault(j_ext, []).append(new_k)\n",
    "            return j_ext\n",
    "    else:\n",
    "        # buscar/crear sintética\n",
    "        key = (\"cut\", new_k, j_ext)\n",
    "        if key not in junction_to_tubes:\n",
    "            # si aún no existe (por si llegamos aquí por primera vez)\n",
    "            synthetic_pos[key] = pos[j_ext]\n",
    "            junction_to_tubes[key] = [new_k]\n",
    "            synthetic_juncs.append(key)\n",
    "        return key\n",
    "\n",
    "# Construimos (para tubos mantenidos) los pares (jA, jB) finales\n",
    "tube_end_junc_ids = [None]*n_tubes_kept  # lista de (j0, j1) por índice nuevo\n",
    "for old_k in range(n_tubes):\n",
    "    if not keep_mask[old_k]:\n",
    "        continue\n",
    "    new_k = old_to_new[old_k]\n",
    "    j0 = endpoint_junction_id(old_k, 0)\n",
    "    j1 = endpoint_junction_id(old_k, 1)\n",
    "    tube_end_junc_ids[new_k] = (j0, j1)\n",
    "\n",
    "# 4.2: Dirección (in/out) según tangente orientada en el midpoint\n",
    "def directed_pair_for_tube(new_k):\n",
    "    \"\"\"Devuelve (j_in, j_out) para el tubo new_k según el sentido del flujo.\"\"\"\n",
    "    t = np.asarray(oriented_tangents_kept[new_k])\n",
    "    mx, my = real_midpoints_kept[new_k]\n",
    "    jA, jB = tube_end_junc_ids[new_k]\n",
    "    # posiciones (x,y): junction real -> pos[j]; sintética -> synthetic_pos\n",
    "    def jxy(jid):\n",
    "        return pos[jid] if isinstance(jid, tuple) and len(jid)==2 else synthetic_pos[jid]\n",
    "    Ax, Ay = jxy(jA)\n",
    "    Bx, By = jxy(jB)\n",
    "    vA = np.array([Ax - mx, Ay - my])\n",
    "    vB = np.array([Bx - mx, By - my])\n",
    "    # El endpoint con proyección POSITIVA sobre la tangente orientada está \"downstream\"\n",
    "    dpA = t.dot(vA)\n",
    "    dpB = t.dot(vB)\n",
    "    if dpA < dpB:\n",
    "        # A más negativo/menos positivo -> upstream, B -> downstream\n",
    "        j_in, j_out = jA, jB\n",
    "    else:\n",
    "        j_in, j_out = jB, jA\n",
    "    return j_in, j_out\n",
    "\n",
    "links = []  # (j_in, j_out, Q)\n",
    "for k_new in range(n_tubes_kept):\n",
    "    j_in, j_out = directed_pair_for_tube(k_new)\n",
    "    links.append((j_in, j_out, float(flows_kept[k_new])))\n",
    "\n",
    "# 4.3: Pesos normalizando por el caudal que SALE de cada junction de entrada\n",
    "sum_out = defaultdict(float)\n",
    "for j_in, j_out, q in links:\n",
    "    sum_out[j_in] += q\n",
    "\n",
    "# Asignamos IDs enteros a todas las junctions finales para escribir el fichero\n",
    "all_junction_ids = list(junction_to_tubes.keys())\n",
    "# Aseguramos un orden estable: primero reales (tuplas (i,j)), luego sintéticas (\"cut\", ...)\n",
    "reals      = [jid for jid in all_junction_ids if isinstance(jid, tuple) and len(jid)==2]\n",
    "synthetics = [jid for jid in all_junction_ids if not (isinstance(jid, tuple) and len(jid)==2)]\n",
    "ordered_junctions = reals + synthetics\n",
    "\n",
    "jid_to_int = {jid: idx for idx, jid in enumerate(ordered_junctions)}\n",
    "\n",
    "# Escribimos fichero: junc_in, junc_out, weight\n",
    "with open(\"junction_links.txt\", \"w\") as f:\n",
    "    for j_in, j_out, q in links:\n",
    "        denom = sum_out[j_in]\n",
    "        w = (q/denom) if denom > 0 else 0.0\n",
    "        f.write(f\"{jid_to_int[j_in]} {jid_to_int[j_out]} {w:.4f}\\n\")\n",
    "\n",
    "\n",
    "print(f\"[OK] Filtrado de junctions/tubos en x∈[{x_lo},{x_hi}]\")\n",
    "print(f\"[OK] Tubos mantenidos: {n_tubes_kept} / {n_tubes}\")\n",
    "print(f\"[OK] Junctions reales finales: {len(reals)}, sintéticas: {len(synthetics)}, total: {len(ordered_junctions)}\")\n",
    "print(\"[OK] Fichero 'junction_links.txt' guardado con líneas: junc_in, junc_out, weight\")\n",
    "# ==== FIN DEL BLOQUE ====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== GUARDAR COORDENADAS DE LAS JUNCTIONS FINALES ====\n",
    "# Requisitos: ordered_junctions, jid_to_int, pos, synthetic_pos ya definidos.\n",
    "\n",
    "# Preparamos una lista para guardar las coordenadas ordenadas por ID entero\n",
    "# El tamaño es el número total de junctions finales\n",
    "num_final_junctions = len(ordered_junctions)\n",
    "coords_list = [None] * num_final_junctions\n",
    "\n",
    "# Llenamos la lista usando el mapeo jid_to_int para el índice correcto\n",
    "for jid, int_id in jid_to_int.items():\n",
    "    if isinstance(jid, tuple) and len(jid) == 2:\n",
    "        # Es una junction real, usamos el diccionario 'pos'\n",
    "        coords_list[int_id] = pos[jid]\n",
    "    else:\n",
    "        # Es una junction sintética, usamos el diccionario 'synthetic_pos'\n",
    "        coords_list[int_id] = synthetic_pos[jid]\n",
    "\n",
    "# Escribimos el fichero: integer_id x_coordinate y_coordinate\n",
    "output_coords_file = \"junction_coordinates.txt\"\n",
    "with open(output_coords_file, \"w\") as f_coords:\n",
    "    for int_id, (x, y) in enumerate(coords_list):\n",
    "        f_coords.write(f\"{int_id} {x:.6f} {y:.6f}\\n\") # Formato con 6 decimales\n",
    "\n",
    "print(f\"[OK] Coordenadas de las {num_final_junctions} junctions finales guardadas en '{output_coords_file}'\")\n",
    "# ==== FIN DEL BLOQUE DE GUARDAR COORDENADAS ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# WE PLOT THE MEDIUM DISPLAYING THE POISEUILLE PROFILES AND INDICATING WHICH TYPE EACH JUNCTION IS AND WICH ONE IS THE BIG TUBE IN EACH JUNCTION\n",
    "\n",
    "# We rescale U vectors for better visibilityl\n",
    "vel_mags = np.linalg.norm(Uall, axis=1)\n",
    "max_vel = vel_mags.max() if vel_mags.max()>0 else 1.0\n",
    "\n",
    "arrow_len = (xmax - xmin) * 0.002\n",
    "vel_scale = 5*arrow_len / max_vel\n",
    "U_scaled = Uall * vel_scale  \n",
    "\n",
    "# we classify junctions\n",
    "junc1, junc2 = [], []\n",
    "for j in junc3:\n",
    "    idxs = tube_index.get(j, [])\n",
    "    if len(idxs) != 3:\n",
    "        continue\n",
    "    qs = np.array([flow_rates[i] for i in idxs])\n",
    "    i_max = idxs[np.argmax(qs)]\n",
    "    x0, y0 = real_midpoints[i_max]\n",
    "    xj, yj = pos[j]\n",
    "    dp = oriented_tangents[i_max].dot((xj-x0, yj-y0))\n",
    "    if dp > 0:\n",
    "        junc2.append(j)\n",
    "    else:\n",
    "        junc1.append(j)\n",
    "\n",
    "# we plot tangent vectors\n",
    "Xg, Yg, Ug, Vg = [], [], [], []\n",
    "for k in range(len(tubes)):\n",
    "    x0, y0 = real_midpoints[k]\n",
    "    tx, ty = oriented_tangents[k]\n",
    "    Xg.append(x0); Yg.append(y0)\n",
    "    Ug.append(tx * arrow_len); Vg.append(ty * arrow_len)\n",
    "\n",
    "# we display the biggest tube at each junction\n",
    "Xy, Yy, Uy, Vy = [], [], [], []\n",
    "for j in junc3:\n",
    "    idxs = tube_index[j]\n",
    "    qs = np.array([flow_rates[i] for i in idxs])\n",
    "    i_max = idxs[np.argmax(qs)]\n",
    "    xj, yj = pos[j]  # junction center\n",
    "    tx, ty = oriented_tangents[i_max]\n",
    "    Xy.append(xj); Yy.append(yj)\n",
    "    Uy.append(tx * arrow_len); Vy.append(ty * arrow_len)\n",
    "\n",
    "# GRAPH\n",
    "fig, ax = plt.subplots(figsize=(12, 8), dpi=1200)\n",
    "ax.imshow(mask, origin='lower',\n",
    "          extent=(xmin, xmax, ymin, ymax),\n",
    "          cmap='gray', alpha=0.4)\n",
    "\n",
    "for k in range(len(tubes)):\n",
    "    start, end = offsets[k], offsets[k+1]\n",
    "    pts_k = all_pts[start:end]\n",
    "    uscaled = U_scaled[start:end]\n",
    "    xs, ys = pts_k[:,0], pts_k[:,1]\n",
    "    \n",
    "    ax.plot(xs, ys, color='black', linewidth=0.5, alpha=0.6, zorder=1)\n",
    "    \n",
    "    ax.quiver(xs, ys,\n",
    "              uscaled[:,0], uscaled[:,1],\n",
    "              angles='xy', scale_units='xy', scale=1,\n",
    "              width=0.0002, color='cyan', alpha=0.8, zorder=2)\n",
    "\n",
    "ax.quiver(\n",
    "    Xg, Yg, Ug, Vg,\n",
    "    angles='xy', scale_units='xy', scale=1,\n",
    "    width=0.0004, headwidth=1, headlength=1.2, headaxislength=1,\n",
    "    color='green', alpha=0.8, zorder=3\n",
    ")\n",
    "\n",
    "ax.quiver(\n",
    "    Xy, Yy, Uy, Vy,\n",
    "    angles='xy', scale_units='xy', scale=1,\n",
    "    width=0.0004, headwidth=1, headlength=1.2, headaxislength=1,\n",
    "    color='yellow', alpha=0.9, zorder=4\n",
    ")\n",
    "\n",
    "for j in junc1:\n",
    "    xj, yj = pos[j]\n",
    "    ax.text(xj, yj, \"1\", color='red', fontsize=2,\n",
    "            fontweight='bold', ha='center', va='center', zorder=5)\n",
    "for j in junc2:\n",
    "    xj, yj = pos[j]\n",
    "    ax.text(xj, yj, \"2\", color='blue', fontsize=2,\n",
    "            fontweight='bold', ha='center', va='center', zorder=5)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
