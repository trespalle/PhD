{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pore size and flow rate distributions in 2D porous media calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.spatial import KDTree\n",
    "from skimage.morphology import medial_axis\n",
    "from shapely import vectorized\n",
    "from shapely.geometry import Point, LineString, box\n",
    "from shapely.ops import polygonize, unary_union\n",
    "from shapely.prepared import prep\n",
    "import networkx as netx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos y cargamos el VTK\n",
    "\n",
    "case_dir = os.path.expanduser(\"~/OpenFOAM/jose-v2406/run/YDRAY-flow_n13_sat\")\n",
    "vtk_file = os.path.join(case_dir, \"VTK\", \"YDRAY-flow_n13_sat_1047.vtm\")\n",
    "\n",
    "mb        = pv.read(vtk_file)\n",
    "vol_mesh  = mb[\"internal\"]\n",
    "cyl_patch = mb[\"boundary\"][\"wallFluidSolid\"]\n",
    "\n",
    "_, _, _, _, zmin, zmax = vol_mesh.bounds\n",
    "z_mid = 0.5 * (zmin + zmax)\n",
    "\n",
    "obst_section = (\n",
    "    cyl_patch.extract_surface()\n",
    "             .slice(normal=\"z\", origin=(0, 0, z_mid))\n",
    "             .clean()\n",
    ")\n",
    "dom_section = (\n",
    "    vol_mesh.extract_surface()\n",
    "            .slice(normal=\"z\", origin=(0, 0, z_mid))\n",
    "            .clean()\n",
    ")\n",
    "\n",
    "print(f\"Obstáculos en corte: {obst_section.n_lines:,d} aristas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZACIÓN\n",
    "\n",
    "WINDOW_SIZE = (3200, 2400)   # resolución ventana\n",
    "AXIS_FONT   = 40              # tamaño de números\n",
    "\n",
    "pl = pv.Plotter(window_size=WINDOW_SIZE)\n",
    "pl.set_background(\"white\")\n",
    "\n",
    "pl.add_mesh(obst_section, color=\"blue\",  line_width=1.5, label=\"Obstacles\")\n",
    "pl.add_mesh(dom_section,  color=\"gray\", line_width=0.8, opacity=0.4,\n",
    "            label=\"Domain boundary\")\n",
    "\n",
    "\n",
    "\n",
    "axes = pl.show_bounds(grid=\"front\", fmt=\"%.2f\", font_size=AXIS_FONT)\n",
    "\n",
    "\n",
    "axes.x_label_offset = 400    # mueve los números del eje X hacia abajo\n",
    "axes.y_label_offset = 400    # mueve los números del eje Y hacia la izquierda\n",
    "\n",
    "pl.view_xy()\n",
    "\n",
    "pl.show(window_size=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poligonizamos con shapely el boundary y los obstaculos\n",
    "\n",
    "def polydata_to_polygon(polydata):\n",
    "    # toma un polydata y devuelve los poligonos resultantes\n",
    "    if isinstance(polydata, pv.UnstructuredGrid):\n",
    "        polydata = polydata.extract_geometry()\n",
    "    total_entries = len(polydata.lines)\n",
    "    print(f\"Entradas en polydata.lines: {total_entries}\")\n",
    "    lines = []\n",
    "    i, count = 0, 0\n",
    "    while i < total_entries:\n",
    "        n_pts = polydata.lines[i]\n",
    "        idx = polydata.lines[i+1:i+1+n_pts]\n",
    "        coords = [tuple(polydata.points[j][:2]) for j in idx]\n",
    "        lines.append(LineString(coords))\n",
    "        i += 1 + n_pts\n",
    "        count += 1\n",
    "        if count % 500 == 0:\n",
    "            print(f\"Procesadas {count} lineas, i = {i}/{total_entries}\")\n",
    "    merged = unary_union(lines)\n",
    "    polys = list(polygonize(merged))\n",
    "    return polys\n",
    "\n",
    "\n",
    "# Nos quedamos solo con los contornos de los obstaculos circulares\n",
    "clean_obs = obst_section.clean(tolerance=1e-6)\n",
    "conn = clean_obs.connectivity() \n",
    "n_beads = int(conn['RegionId'].max())+1\n",
    "print(f\"Obtenidos {n_beads} contornos de obstaculo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poligonalizamos cada bead por separado\n",
    "obs_polys = []\n",
    "for rid in range(n_beads):\n",
    "    bead = conn.threshold([rid, rid], scalars='RegionId').clean(tolerance = 1e-6).extract_geometry()\n",
    "    polys = polydata_to_polygon(bead)\n",
    "    if polys:\n",
    "        obs_polys.extend(polys)\n",
    "\n",
    "print(f\"En total, {len(obs_polys)} obstaculos convertidos a poligono\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xmin, xmax, ymin, ymax, zmin, zmax = dom_section.bounds\n",
    "x_cutoff = max(poly.bounds[2] for poly in obs_polys)\n",
    "xmax = x_cutoff\n",
    "print(f\"La esquina inf. izda. esta en ({xmin}, {ymin}), la esquina sup. dcha. esta en ({xmax}, {ymax})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Unimos los obstaculos y definimos la zona por la que fluye el agua\n",
    "outer = box(xmin, ymin, xmax, ymax)\n",
    "beads = unary_union(obs_polys)\n",
    "free_region = outer.difference(beads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos los poligonos creados para asegurarnos de que esta todo correcto\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "# Visualizacion del contorno exterior:\n",
    "if outer.geom_type == 'Polygon':\n",
    "    x, y = outer.exterior.xy\n",
    "    ax.plot(x, y, color='blue', linewidth=2)\n",
    "else:\n",
    "    for poly in outer.geoms:\n",
    "        x, y = poly.exterior.xy\n",
    "        ax.plot(x, y, color='blue', linewidth=2)\n",
    "\n",
    "#  Visualizacion de los beads:\n",
    "if beads.geom_type == 'Polygon':\n",
    "    xb, yb = beads.exterior.xy\n",
    "    ax.plot(xb, yb, color='blue', linewidth=1)\n",
    "else:\n",
    "    for poly in beads.geoms:\n",
    "        xb, yb = poly.exterior.xy\n",
    "        ax.plot(xb, yb, color='blue', linewidth=1)\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHORA: CREAMOS UNA MASCARA BOOLEANA PARA SABER SI LOS PUNTOS ESTAN DENTRO O FUERA DEL ESPACIO LIBRE\n",
    "\n",
    "# Queremos maxima resolucion: estimamos primero la longitud de celda mas pequena de nuestro mesh (dx)\n",
    "# Para ello, construimos un KDTree y pedimos la lista de distancias al 2o vecino (el 1o es el propio punto)\n",
    "pts2d = dom_section.points[:, :2]\n",
    "tree = KDTree(pts2d)\n",
    "dists, _ = tree.query(pts2d, k=2)\n",
    "nn_dists = dists[:, 1]\n",
    "# En vez de el valor minimo, tomamos el percentil 1 para evitar outliers:\n",
    "dx = np.percentile(nn_dists, 1)\n",
    "dy = dx # asumimos malla isotropica\n",
    "\n",
    "print(f\"La anchura de nuestro pixel sera de dx = {dx:.5g} m\")\n",
    "\n",
    "# Ahora si: definimos la resolucion de acuerdo a dx. Esta resolucion es cuasi maxima\n",
    "nx = int(np.ceil((xmax-xmin)/dx)) + 1\n",
    "ny = int(np.ceil((ymax-ymin)/dy)) + 1\n",
    "\n",
    "print(f\"Resolucion de la mascara: {nx}x{ny} (lo mas cercano al mallado original. Cristo murio por nosotros.)\")\n",
    "\n",
    "# Y AHORA: GENERAMOS LA MASCARA BOOLEANA\n",
    "xs = np.linspace(xmin, xmax, nx)\n",
    "ys = np.linspace(ymin, ymax, ny)\n",
    "XX, YY = np.meshgrid(xs, ys, indexing=\"xy\")\n",
    "\n",
    "prepped = prep(free_region)\n",
    "\n",
    "from shapely import contains_xy\n",
    "mask = contains_xy(free_region, XX, YY)\n",
    "\n",
    "\n",
    "print(\"Mascara creada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la mascara creada para asegurarnos de que esta todo en orden\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(120,80))\n",
    "im = ax.imshow(mask, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='gray', interpolation='nearest')\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_title('White = free space')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AHORA: COMPUTAMOS EL ESQUELETO DEL MEDIO POROSO\n",
    "\n",
    "# Primero, calculamos la distancia euclidea del centro cada pixel blanco (free) al centro del pixel negro \n",
    "# (obstacle) mas cercano. La funcion que usamos calcula estas distancias en \"anchos de pixel\" (dx)\n",
    "dist_pixels = distance_transform_edt(mask)\n",
    "\n",
    "# Ahora, computamos el esqueleto y proyectamos la \"matriz de distancias\" sobre el esqueleto\n",
    "skeleton, skel_dist_pixels = medial_axis(mask, return_distance=True)\n",
    "\n",
    "# Lo convertimos todo a metros\n",
    "dist_map = dist_pixels * dx\n",
    "skel_dist = skel_dist_pixels * dx\n",
    "\n",
    "# Cuantos pixeles tiene el esqueleto?\n",
    "n_skel_pts = skeleton.sum()\n",
    "print(f\"Puntos en el esqueleto: {n_skel_pts:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma rapido (pochillo) de half-widths\n",
    "half_widths_mm = skel_dist[skeleton]*1e3\n",
    "\n",
    "# Ajustamos a una Rayleigh\n",
    "from scipy.stats import rayleigh, norm\n",
    "loc_hat, sigma_hat = rayleigh.fit(half_widths_mm)\n",
    "\n",
    "# Ajustamos a una Gaussiana\n",
    "mu_g, sigma_g = norm.fit(half_widths_mm)\n",
    "\n",
    "# Ajuste gaussiano con media y desviacion muestrales\n",
    "mean_hw = half_widths_mm.mean()\n",
    "std_hw = half_widths_mm.std()\n",
    "\n",
    "# A pintar!\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(half_widths_mm, bins=50, density=True, alpha=0.6, label=\"Simulation\")\n",
    "r = np.linspace(0, half_widths_mm.max(), 200)\n",
    "ax.plot(r, rayleigh.pdf(r, loc=loc_hat, scale=sigma_hat), 'r-', lw=2, label=f\"Rayleigh fit\\nσ={sigma_hat:.2f} mm\")\n",
    "ax.plot(r, norm.pdf(r, loc=mu_g, scale=sigma_g), 'b--', lw=2, label=f\"Normal fit\\nμ={mu_g:.2f} mm\\nσ={sigma_g:.2f} mm\")\n",
    "ax.plot(r, norm.pdf(r, loc=mean_hw, scale=std_hw), 'g:', lw=2, label=f\"Empiric normal\\nμ={mean_hw:.2f} mm\\nσ={std_hw:.2f} mm\")\n",
    "ax.set_xlabel(\"Half-width (mm)\")\n",
    "ax.set_ylabel(\"Probability density\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Número de halfwidths:\", len(half_widths_mm))\n",
    "# El numero es mucho mayor que la cantidad total de Poiseuille tubes porque estamos considerando la \n",
    "# distancia de cada punto del skeleton al punto de obstaculo mas cercano como una half-width. \n",
    "# Sin embargo, se puede argumentar que esto es mas realista que tomar solo una distancia por tubo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el esqueleto sobre la mascara booleana para ver que todo esta correcto\n",
    "plt.figure(figsize=(12,8), dpi=1200)\n",
    "plt.imshow(mask, origin='lower', cmap='gray', extent=(xmin, xmax, ymin, ymax))\n",
    "# el esqueleto:\n",
    "ys, xs = np.where(skeleton)\n",
    "plt.scatter(xs*dx + xmin, ys*dx + ymin, s=0.005, c='red', label='Skeleton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def prune_spurs(skel, n_iters):\n",
    "    \"\"\"\n",
    "    Elimina iterativamente los endpoints (píxeles de grado 1)\n",
    "    del skeleton binario `skel`, `n_iters` veces.\n",
    "    \"\"\"\n",
    "    # Un structuring element 3×3 de unos (contaremos vecinos)\n",
    "    se = np.ones((3,3), dtype=int)\n",
    "    sk = skel.copy()\n",
    "    for _ in range(n_iters):\n",
    "        # Convolution: cuenta vecinos (incluido el píxel)\n",
    "        count = ndi.convolve(sk.astype(int), se, mode='constant', cval=0)\n",
    "        # Los endpoints son píxeles en sk con exactamente 2 en count\n",
    "        # porque count = 1(píxel) + 1(vecino) = 2\n",
    "        endpoints = (sk & (count == 2))\n",
    "        if not endpoints.any():\n",
    "            break\n",
    "        sk[endpoints] = False\n",
    "    return sk\n",
    "\n",
    "# Uso:\n",
    "skeleton_pruned = prune_spurs(skeleton, 200)\n",
    "skeleton = skeleton_pruned\n",
    "\n",
    "# CONVERTIMOS EL SKELETON EN UN GRAFO\n",
    "# en el que los skeleton pixels son los nodos y existe un link entre dos de ellos si son vecinos en la mascara 2D\n",
    "\n",
    "import networkx as netx\n",
    "\n",
    "\n",
    "orthogonal = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "diagonals  = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "\n",
    "G = netx.Graph()\n",
    "\n",
    "# extraemos el numero de fila (i) y el numero de columna (j) de cada pixel del skeleton:\n",
    "coords = np.argwhere(skeleton)\n",
    "\n",
    "\n",
    "# 1) Añade todos los nodos\n",
    "for j, i in coords:\n",
    "    G.add_node((i, j), width=skel_dist[j, i])\n",
    "\n",
    "# 2) Construye las aristas con regla de diagonales condicionadas\n",
    "for j, i in coords:\n",
    "    this = (i, j)\n",
    "    neighbors = set()\n",
    "    # 2a) Vecinos ortogonales\n",
    "    for dj, di in orthogonal:\n",
    "        nj, ni = j + dj, i + di\n",
    "        if 0 <= nj < ny and 0 <= ni < nx and skeleton[nj, ni]:\n",
    "            neighbors.add((ni, nj))\n",
    "    # 2b) Vecinos diagonales solo si ninguno de los ortogonales adyacentes ya está\n",
    "    for dj, di in diagonals:\n",
    "        nj, ni = j + dj, i + di\n",
    "        if not (0 <= nj < ny and 0 <= ni < nx and skeleton[nj, ni]):\n",
    "            continue\n",
    "        ortho1 = (i, j + dj)\n",
    "        ortho2 = (i + di, j)\n",
    "        if ortho1 not in neighbors and ortho2 not in neighbors:\n",
    "            neighbors.add((ni, nj))\n",
    "    # 2c) Añade las aristas\n",
    "    for nb in neighbors:\n",
    "        G.add_edge(this, nb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRAEMOS LAS JUNCTIONS Y LOS TUBOS\n",
    "# Una junction es un nodo con grado > 2\n",
    "# Cada camino simple entre dos junctions es un tubo\n",
    "\n",
    "\n",
    "# 1) Reúne todos los leaves (grado==1)\n",
    "#leaves = [n for n,d in G.degree() if d == 1]\n",
    "\n",
    "# 2) Mientras sigas teniendo leaves, quítalos todos\n",
    "#while leaves:\n",
    "    #G.remove_nodes_from(leaves)\n",
    "    #leaves = [n for n,d in G.degree() if d == 1]\n",
    "\n",
    "# Ahora G_pruned es tu skeleton sin dead-ends\n",
    "# A partir de él:\n",
    "\n",
    "\n",
    "joints = [n for n,d in G.degree() if d>2]\n",
    "print(f\"Número total de junctions (grado>2): {len(joints)}\")\n",
    "\n",
    "tubes = []\n",
    "visited = set()\n",
    "for u in joints:\n",
    "    for v in G.neighbors(u):\n",
    "        if (u,v) in visited or (v,u) in visited: continue\n",
    "        path = [u,v]; visited.add((u,v))\n",
    "        prev, curr = u, v\n",
    "        # seguimos hasta la siguiente junction\n",
    "        while G.degree(curr)==2:\n",
    "            w = [w for w in G.neighbors(curr) if w!=prev][0]\n",
    "            prev, curr = curr, w\n",
    "            path.append(curr)\n",
    "            visited.add((prev,curr))\n",
    "        tubes.append(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el sistema de tubos y joints para asegurarnos de que esta todo en orden \n",
    "\n",
    "pos = {node:(xmin + i*dx, ymin + j*dy) for (j,i), node in zip(coords, G.nodes()) }\n",
    "\n",
    "# Dibujamos la mascara de fondo:\n",
    "fig, ax = plt.subplots(figsize=(12,8), dpi=1000)\n",
    "ax.imshow(mask, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='gray', alpha=0.5)\n",
    "\n",
    "# Dibujamos los tubos:\n",
    "for tube in tubes:\n",
    "    xs = [pos[n][0] for n in tube]\n",
    "    ys = [pos[n][1] for n in tube]\n",
    "    ax.plot(xs, ys, color='blue', linewidth=0.5)\n",
    "\n",
    "# Dibujamos las junctions\n",
    "jx = [pos[j][0] for j in joints]\n",
    "jy = [pos[j][1] for j in joints]\n",
    "ax.scatter(jx, jy, color='red', s=3, label='Junctions')\n",
    "\n",
    "# Ajustes finales\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('x(m)')\n",
    "ax.set_ylabel('y(m)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRUIMOS EL HISTOGRAMA DE SEMIAPERTURAS BUENO (SOLO MIDPOINTS)\n",
    "\n",
    "from scipy.stats import rayleigh, norm  \n",
    "\n",
    "half_widths_mid = []\n",
    "for tube in tubes:\n",
    "    mid = len(tube)//2    # indice central\n",
    "    node_mid = tube[mid]\n",
    "    w_mid = G.nodes[node_mid]['width']\n",
    "    half_widths_mid.append(w_mid)\n",
    "\n",
    "half_widths_mid = np.array(half_widths_mid)\n",
    "# para tenerlo todo en mm:\n",
    "half_widths_mid_mm = half_widths_mid*1e3\n",
    "\n",
    "# Ajuste Rayleigh: \n",
    "loc_r, sigma_r = rayleigh.fit(half_widths_mid_mm, floc=0)\n",
    "\n",
    "# Ajuste normal:\n",
    "mu_n, sigma_n = norm.fit(half_widths_mid_mm)\n",
    "\n",
    "# Dominio para las curvas:\n",
    "r = np.linspace(0, half_widths_mid_mm.max(), 200)\n",
    "\n",
    "# Ploteamos el histograma junto a los fits\n",
    "fig, ax = plt.subplots(figsize=(6,4), dpi=400)\n",
    "ax.hist(half_widths_mid_mm, bins=30, density=True, alpha=0.6, color='C0', edgecolor='black', label='Simulation')\n",
    "ax.plot(r, rayleigh.pdf(r, loc=loc_r, scale=sigma_r), 'r-', lw=2, label=f'Rayleigh fit\\nσ={sigma_r:.2f} mm')\n",
    "ax.plot(r, norm.pdf(r, loc=mu_n, scale=sigma_n), 'b--', lw=2, label=f'Normal fit\\nμ={mu_n:.2f} mm\\nσ={sigma_n:.2f} mm')\n",
    "\n",
    "ax.set_xlabel(\"Half-width (mm)\")\n",
    "ax.set_ylabel(\"Probability density\")\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Lo ploteamos tambien en escala logaritmica:\n",
    "bins_log = np.logspace(np.log10(half_widths_mid_mm.min()), np.log10(half_widths_mid_mm.max()), 30)\n",
    "\n",
    "plt.figure(figsize=(6,4), dpi=400)\n",
    "plt.hist(half_widths_mid_mm, bins=bins_log, color='C1', edgecolor='black' )\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Half-width (mm)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### Celda: Cálculo de flujo con midpoint “real” mediante intersección\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import LineString, Point\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "\n",
    "# 0) Construye KD-Tree de los pixels del skeleton podado con su width\n",
    "pixel_nodes = np.array(list(G.nodes()))   # array de (i,j)\n",
    "pixel_xy    = np.array([\n",
    "    (xmin + i*dx, ymin + j*dy)\n",
    "    for i,j in pixel_nodes\n",
    "])\n",
    "pixel_width = np.array([\n",
    "    G.nodes[(i,j)]['width']\n",
    "    for i,j in pixel_nodes\n",
    "])\n",
    "pix_tree = cKDTree(pixel_xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Preparamos KDTree con los centroides de obstáculos\n",
    "obs_centers = np.array([[poly.centroid.x, poly.centroid.y] for poly in obs_polys])\n",
    "obs_tree    = cKDTree(obs_centers)\n",
    "\n",
    "all_pts  = []\n",
    "offsets  = [0]\n",
    "tangents = []\n",
    "half_ws  = []\n",
    "normals = []\n",
    "real_midpoints = []\n",
    "L_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Recorremos cada tubo para generar los puntos de muestreo\n",
    "for tube in tubes:\n",
    "    # 2a) Índice aproximado y semiancho\n",
    "    mid = len(tube) // 2\n",
    "    i, j = tube[mid]\n",
    "    x_idx, y_idx = pos[(i, j)]\n",
    "\n",
    "    # 2c) Centros de obstáculos más cercanos\n",
    "    _, idxs = obs_tree.query([x_idx, y_idx], k=2)\n",
    "    c1, c2 = obs_centers[idxs[0]], obs_centers[idxs[1]]\n",
    "\n",
    "    # 2d) Intersección entre el eje del tubo y la recta centros\n",
    "    tube_line = LineString([pos[n] for n in tube])\n",
    "    cut_line  = LineString([c1, c2])\n",
    "    inter = tube_line.intersection(cut_line)\n",
    "    if inter.is_empty:\n",
    "        x0, y0 = x_idx, y_idx\n",
    "    else:\n",
    "        if isinstance(inter, Point):\n",
    "            x0, y0 = inter.x, inter.y\n",
    "        #else:\n",
    "            # inter es un MultiPoint: extraemos sus sub-puntos con .geoms\n",
    "            #pts = list(inter.geoms)\n",
    "            # calculamos distancias al midpoint índice\n",
    "            #dists = [Point(x_idx, y_idx).distance(pt) for pt in pts]\n",
    "            # elegimos el más cercano\n",
    "            #closest = pts[np.argmin(dists)]\n",
    "            #x0, y0 = closest.x, closest.y\n",
    "\n",
    "    real_midpoints.append((x0, y0))\n",
    "\n",
    "    # 2) Encuentra la semianchura real más cercana\n",
    "    dist_px, idx_px = pix_tree.query([x0, y0])\n",
    "    w_real = pixel_width[idx_px]\n",
    "    half_ws.append(w_real)\n",
    "\n",
    "    # 2e) Nuevo vector normal “real”\n",
    "    n_hat = c2 - c1\n",
    "    n_hat /= np.linalg.norm(n_hat)\n",
    "\n",
    "    t_hat = np.array([-n_hat[1],  n_hat[0]])\n",
    "\n",
    "    # 3) Usa w_real para definir D y generar la línea de corte\n",
    "    D = 2 * w_real\n",
    "    line_ext = LineString([\n",
    "        (x0 - n_hat[0]*D, y0 - n_hat[1]*D),\n",
    "        (x0 + n_hat[0]*D, y0 + n_hat[1]*D),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # 4) Intersecta con free_region y mide L\n",
    "    seg = line_ext.intersection(free_region)\n",
    "    if seg.is_empty:\n",
    "        L = 2*w_real\n",
    "        seg = LineString([\n",
    "            (x0 - n_hat[0]*w_real, y0 - n_hat[1]*w_real),\n",
    "            (x0 + n_hat[0]*w_real, y0 + n_hat[1]*w_real)\n",
    "        ])\n",
    "    elif seg.geom_type == \"MultiLineString\":\n",
    "        seg = max(seg.geoms, key=lambda s: s.length)\n",
    "    L = seg.length\n",
    "    L_list.append(L)\n",
    "\n",
    "    # 5) Muestreo equiespaciado según L\n",
    "    Nsamples = max(5, int(np.ceil(L / dx)))\n",
    "    ds = L / (Nsamples - 1)\n",
    "    ss = [i*ds for i in range(Nsamples)]\n",
    "    pts = [(seg.interpolate(s).x,\n",
    "            seg.interpolate(s).y,\n",
    "            z_mid) for s in ss]\n",
    "\n",
    "\n",
    "    \n",
    "    all_pts.extend(pts)\n",
    "    offsets.append(len(all_pts))\n",
    "    normals.append(n_hat)\n",
    "    tangents.append(t_hat)\n",
    "\n",
    "all_pts = np.array(all_pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Sampleo VTK de velocidades\n",
    "cloud_all = pv.PolyData(all_pts)\n",
    "sampled   = vol_mesh.sample(cloud_all)\n",
    "Uall      = sampled['U'][:, :2]\n",
    "\n",
    "Uall = np.nan_to_num(Uall, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Cálculo de caudales por tubo usando las longitudes reales almacenadas en L_list\n",
    "h = 1e-3\n",
    "flow_rates = []\n",
    "for k in range(len(tubes)):\n",
    "    start, end = offsets[k], offsets[k+1]\n",
    "    Upts = Uall[start:end]    \n",
    "    t_hat = tangents[k]\n",
    "    # Usamos la longitud real L_list[k] para el paso ds\n",
    "    # y garantizamos que ds*(len(Upts)-1) == L_list[k]\n",
    "    L_real = L_list[k]\n",
    "    ds = L_real / (len(Upts) - 1) if len(Upts) > 1 else 0.0\n",
    "\n",
    "    # Proyección de U sobre la tangente\n",
    "    u_par = Upts.dot(t_hat)\n",
    "    Qt = np.abs(np.sum(u_par * ds)) * h\n",
    "    flow_rates.append(Qt)\n",
    "\n",
    "print(f\"Computed flow_rates for {len(flow_rates)} tubes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(flow_rates)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=200)\n",
    "\n",
    "# Definimos bins lineales para el histograma\n",
    "bins = np.linspace(data.min(), data.max(), 50)\n",
    "\n",
    "# Dibujamos el histograma\n",
    "ax.hist(data, bins=bins, alpha=0.75, edgecolor='black')\n",
    "\n",
    "# Escala logarítmica solo en el eje Y\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Etiquetas y título\n",
    "ax.set_xlabel(\"Flow rate $Q$ (m³/s)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of tubes\", fontsize=12)\n",
    "ax.set_title(\"Histogram of flow rates\", fontsize=14, pad=12)\n",
    "\n",
    "# Añadimos rejilla horizontal para facilitar la lectura\n",
    "ax.grid(which='major', axis='y', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULAMOS LA DISTRIBUCION DE CAIDAS DE PRESION\n",
    "\n",
    "# Preparamos la lista de puntos: inicio y fin de cada tubo\n",
    "end_pts = []\n",
    "for tube in tubes:\n",
    "    # Nodo inicial\n",
    "    i0, j0 = tube[0]\n",
    "    x0, y0 = xmin + i0*dx, ymin + j0*dy\n",
    "    end_pts.append((x0, y0, z_mid))\n",
    "    # Nodo final\n",
    "    i1, j1 = tube[-1]\n",
    "    x1, y1 = xmin + i1*dx, ymin + j1*dy\n",
    "    end_pts.append((x1, y1, z_mid))\n",
    "\n",
    "end_pts = np.array(end_pts)\n",
    "\n",
    "# Muestreamos de golpe\n",
    "cloud_end = pv.PolyData(end_pts)\n",
    "sampled_p = vol_mesh.sample(cloud_end)\n",
    "p_vals    = sampled_p['p']  # array de longitud 2*N_tubes\n",
    "\n",
    "# Calculamos la caída de presión por tubo\n",
    "N = len(tubes)\n",
    "dp = np.empty(N)\n",
    "for k in range(N):\n",
    "    p_start = p_vals[2*k]\n",
    "    p_end   = p_vals[2*k + 1]\n",
    "    dp[k]   = abs(p_start - p_end)\n",
    "\n",
    "# Ahora, calculamos la caida de presion teorica (asumiendo Poisueuille)\n",
    "# Para ello, en primer lugar, calculamos la longitud de cada tubo:\n",
    "lengths = []\n",
    "for tube in tubes:\n",
    "    L = 0.0\n",
    "    for k in range(len(tube)-1):\n",
    "        i1, j1 = tube[k]\n",
    "        i2, j2 = tube[k+1]\n",
    "        p1 = np.array([xmin + i1*dx, ymin + j1*dx])\n",
    "        p2 = np.array([xmin + i2*dx, ymin + j2*dx])\n",
    "        L += np.linalg.norm(p2 - p1)\n",
    "    lengths.append(L)\n",
    "lengths = np.array(lengths)\n",
    "\n",
    "# Definimos la viscosidad (agua a 20°C)\n",
    "mu = 1e-3  # Pa·s\n",
    "\n",
    "# Caída de presión teórica (MC Poiseuille en cabina)\n",
    "Q = np.array(flow_rates)\n",
    "w = np.array(half_ws)\n",
    "dp_pois = 3 * mu * lengths * Q / (2 * w**3)\n",
    "\n",
    "# Histograma (comparativo) de caídas de presión\n",
    "min_nonzero = min(dp[dp>0].min(), dp_pois[dp_pois>0].min())\n",
    "max_value   = max(dp.max(), dp_pois.max())\n",
    "bins = np.logspace(np.log10(min_nonzero), np.log10(max_value), 30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6), dpi=200)\n",
    "ax.hist(dp, bins=bins, alpha=0.6, edgecolor='black', label='Real ΔP (OpenFOAM)')\n",
    "ax.hist(dp_pois, bins=bins, histtype='step', linestyle='--', linewidth=2, color='red', label='Estimated ΔP (Poiseuille)')\n",
    "\n",
    "# 3) Log–log\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# 4) Etiquetas y estética\n",
    "ax.set_xlabel(\"Pressure drop ΔP (Pa)\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of tubes\", fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(which='both', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULAMOS LA POROSIDAD:\n",
    "phi = mask.mean()  \n",
    "print(f\"Porosidad φ = {phi:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPRESENTAMOS LOS COLOREADOS SEGUN SU CAUDAL\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import LogNorm, LinearSegmentedColormap\n",
    "\n",
    "\n",
    "segments   = [np.array([pos[n] for n in tube]) for tube in tubes]\n",
    "flow_array = np.array(flow_rates)\n",
    "\n",
    "# Colormap y escala log\n",
    "cmap = LinearSegmentedColormap.from_list(\"BlueRed\", [\"blue\",\"red\"])\n",
    "norm = LogNorm(vmin=flow_array[flow_array>0].min(), vmax=flow_array.max())\n",
    "\n",
    "lc = LineCollection(segments, cmap=cmap, norm=norm, linewidth=1.5)\n",
    "lc.set_array(flow_array)\n",
    "\n",
    "# A pintar\n",
    "fig, ax = plt.subplots(figsize=(12,8), dpi=400)\n",
    "\n",
    "ax.imshow(mask, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='Greys_r', alpha=0.4)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(\"x (m)\")\n",
    "ax.set_ylabel(\"y (m)\")\n",
    "\n",
    "cbar = fig.colorbar(lc, ax=ax, shrink=0.5, pad=0.02)\n",
    "cbar.set_label(\"Flow rate $Q$ (m³/s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULAMOS LA DISTRIBUCION DE BEAD SIZES:\n",
    "\n",
    "radii_obs = np.array([ np.sqrt(poly.area / np.pi) for poly in obs_polys])\n",
    "\n",
    "# los pasamos a mm:\n",
    "radii_mm = radii_obs * 1e3\n",
    "print(f\"Nº de obstáculos: {len(radii_mm)}\")\n",
    "print(f\"Radio mínimo: {radii_mm.min():.3f} mm, máximo: {radii_mm.max():.3f} mm\")\n",
    "\n",
    "\n",
    "\n",
    "# 4) Histograma de radios de obstáculos\n",
    "plt.figure(figsize=(6,4), dpi=150)\n",
    "plt.hist(radii_mm, bins=40, edgecolor='black', alpha=0.8)\n",
    "plt.xlabel(\"Bead radius (mm)\", fontsize=12)\n",
    "plt.ylabel(\"Number of beads\", fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la correlacion de Pearson en el tamano de los beads\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "# Los radios ya los tenemos (en radii_mm), pero necesitamos los centros de cada obstaculo:\n",
    "centers = np.array([[poly.centroid.x, poly.centroid.y] for poly in obs_polys])\n",
    "\n",
    "r_mean = radii_mm.mean()\n",
    "print(r_mean)\n",
    "r_var = radii_mm.var()\n",
    "delta_r = radii_mm - r_mean\n",
    "\n",
    "# Distancias y productos de fluctuaciones dos a dos:\n",
    "dists = pdist(centers) # distancias en metros\n",
    "outer = np.outer(delta_r, delta_r)\n",
    "i_upper = np.triu_indices(len(radii_mm), k=1)\n",
    "prods = outer[i_upper]\n",
    "\n",
    "# pasamos las distancias a mm:\n",
    "dists_mm = dists*1e3\n",
    "\n",
    "nbins = 500\n",
    "max_d = 60.0 #mm\n",
    "min_d = dists_mm.min()\n",
    "bins = np.linspace(min_d, max_d, nbins+1)\n",
    "bin_centers = 0.5*(bins[:-1] + bins[1:])\n",
    "\n",
    "\n",
    "# computamos C(d)\n",
    "sum_prod, _ = np.histogram(dists_mm, bins=bins, weights=prods)\n",
    "counts, _ = np.histogram(dists_mm, bins=bins)\n",
    "C_d = np.zeros_like(bin_centers)\n",
    "mascara = counts>0\n",
    "C_d[mascara] = sum_prod[mascara]/(counts[mascara]*r_var)\n",
    "\n",
    "# A pintar!\n",
    "plt.figure(figsize=(6,4), dpi=400)\n",
    "plt.plot(bin_centers, C_d, '-', linewidth=1, color='C0')\n",
    "plt.xlim(min_d, 20)\n",
    "plt.xlabel(\"Distance $d$ (mm)\", fontsize=12)\n",
    "plt.ylabel(\"Spatial correlation $C(d)$\", fontsize=12)\n",
    "plt.grid(ls='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda X (adaptada): Correlación de caudales en junctions de grado 3 usando real_midpoints —\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dz = 1e-3  # espesor en z fijo\n",
    "\n",
    "# 1) Datos ya definidos en celdas anteriores:\n",
    "#    flow_rates, tubes, G_pruned, real_midpoints (lista de (x0,y0) para cada tubo)\n",
    "#    tangents          (lista de t_hat unitarios ya orientados TODO el bucle anterior)\n",
    "#    offsets, all_pts, Uall\n",
    "\n",
    "flows = np.array(flow_rates)\n",
    "\n",
    "# 2) Índice nodo→tubos (sin cambios)\n",
    "tube_index = {}\n",
    "for idx, tube in enumerate(tubes):\n",
    "    for node in tube:\n",
    "        tube_index.setdefault(node, []).append(idx)\n",
    "\n",
    "# 3) Detectar las junctions de grado 3 en el grafo podado\n",
    "junc3 = [n for n, d in G.degree() if d == 3]\n",
    "\n",
    "# 3.1) Reorientación de tangentes según proyección media de Uall (igual que antes)\n",
    "n_tubes   = len(tubes)\n",
    "proj_mean = np.empty(n_tubes)\n",
    "for i in range(n_tubes):\n",
    "    start, end = offsets[i], offsets[i+1]\n",
    "    v_sec      = Uall[start:end]         # velocidades XY en la sección\n",
    "    proj_mean[i] = v_sec.dot(tangents[i]).mean()\n",
    "oriented_tangents = tangents * np.sign(proj_mean)[:, None]\n",
    "\n",
    "# 4) Inicializar contadores\n",
    "sum_prods      = 0.0\n",
    "count_prods    = 0\n",
    "type1_count    = 0\n",
    "type2_count    = 0\n",
    "sum_feed_prods = 0.0\n",
    "n_feed_cases   = 0\n",
    "\n",
    "# 5) Clasificación “hacia/desde la junction” usando real_midpoints\n",
    "for j in junc3:\n",
    "    idxs = tube_index.get(j, [])\n",
    "    if len(idxs) != 3:\n",
    "        continue\n",
    "\n",
    "    qs    = flows[idxs]\n",
    "    i_max = idxs[np.argmax(qs)]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # --- Aquí usamos real_midpoints en lugar de pos[mid_node] ---\n",
    "    x0, y0   = real_midpoints[i_max]       # sección del tubo i_max\n",
    "    xj, yj   = pos[j]                      # posición de la junction\n",
    "    v2j      = np.array((xj - x0, yj - y0)) # vector sección→junction\n",
    "\n",
    "    dp = oriented_tangents[i_max].dot(v2j)\n",
    "\n",
    "    others = [i for i in idxs if i != i_max]\n",
    "    if len(others) < 2:\n",
    "        # caso raro: no hay dos tubos además del máximo, lo saltamos\n",
    "        continue\n",
    "    if dp > 0:\n",
    "        # caso 2: el tubo i_max es feeder → dos receptores\n",
    "        for o in others:\n",
    "            sum_prods   += flows[i_max] * flows[o]\n",
    "            count_prods += 1\n",
    "        type2_count += 1\n",
    "    else:\n",
    "        # caso 1: el tubo i_max es receptor ← dos feeders\n",
    "        q1, q2 = flows[others[0]], flows[others[1]]\n",
    "        sum_prods      += q1 * q2\n",
    "        count_prods    += 1\n",
    "        type1_count    += 1\n",
    "        sum_feed_prods += q1 * q2\n",
    "        n_feed_cases   += 1\n",
    "\n",
    "# (Opcional) mostrar figura de contexto, si quieres:\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6) Pearson global\n",
    "mean_q   = flows.mean()\n",
    "E_qiqj   = sum_prods / count_prods\n",
    "cov_qiqj = E_qiqj - mean_q**2\n",
    "var_q    = flows.var()\n",
    "pearson  = cov_qiqj / var_q if var_q != 0 else np.nan\n",
    "\n",
    "print(f\"Junctions tipo1 (2→1): {type1_count}\")\n",
    "print(f\"Junctions tipo2 (1→2): {type2_count}\")\n",
    "print(f\"E[q_i·q_j] global       = {E_qiqj:.3e}\")\n",
    "print(f\"Pearson global          = {pearson:.3e}\")\n",
    "\n",
    "# 7) Pearson solo feeders (caso1)\n",
    "if n_feed_cases > 0:\n",
    "    E_feed_prod  = sum_feed_prods / n_feed_cases\n",
    "    cov_feed     = E_feed_prod - mean_q**2\n",
    "    pearson_feed = cov_feed / var_q if var_q != 0 else np.nan\n",
    "    print(f\"Casos tipo1             = {n_feed_cases}\")\n",
    "    print(f\"E[q1*q2] feeders        = {E_feed_prod:.3e}\")\n",
    "    print(f\"Pearson feeders (caso1) = {pearson_feed:.3e}\")\n",
    "else:\n",
    "    print(\"No hay casos tipo1 para Pearson feeders.\")\n",
    "\n",
    "# 8) Diagnósticos adicionales\n",
    "print(\"0.75 Var + (9/16) mean² =\", 0.75*var_q + 9/16*mean_q**2)\n",
    "print(\"mean_q =\", mean_q)\n",
    "print(\"mean_q²/var_q =\", mean_q**2/var_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Celda X+1 (mejorada): secciones con vectores U reescalados y flechas amarillas en junction\n",
    "\n",
    "# %%\n",
    "# Asumimos que ya tienes definidas:\n",
    "# tubes, offsets, all_pts, Uall, real_midpoints, oriented_tangents, tube_index, junc3, pos, mask,\n",
    "# xmin, xmax, ymin, ymax\n",
    "\n",
    "# 1) Escalado de vectores U para visibilidad\n",
    "# hallamos la magnitud máxima en Uall\n",
    "vel_mags = np.linalg.norm(Uall, axis=1)\n",
    "max_vel = vel_mags.max() if vel_mags.max()>0 else 1.0\n",
    "# definimos factor de escala para que el vector más grande tenga longitud arrow_len\n",
    "arrow_len = (xmax - xmin) * 0.002\n",
    "vel_scale = 5*arrow_len / max_vel\n",
    "U_scaled = Uall * vel_scale  # ahora visibles\n",
    "\n",
    "# 2) Clasificación de junctions\n",
    "junc1, junc2 = [], []\n",
    "for j in junc3:\n",
    "    idxs = tube_index.get(j, [])\n",
    "    if len(idxs) != 3:\n",
    "        continue\n",
    "    qs = np.array([flow_rates[i] for i in idxs])\n",
    "    i_max = idxs[np.argmax(qs)]\n",
    "    x0, y0 = real_midpoints[i_max]\n",
    "    xj, yj = pos[j]\n",
    "    dp = oriented_tangents[i_max].dot((xj-x0, yj-y0))\n",
    "    if dp > 0:\n",
    "        junc2.append(j)\n",
    "    else:\n",
    "        junc1.append(j)\n",
    "\n",
    "# 3) Datos para flechas verdes (tangentes)\n",
    "Xg, Yg, Ug, Vg = [], [], [], []\n",
    "for k in range(len(tubes)):\n",
    "    x0, y0 = real_midpoints[k]\n",
    "    tx, ty = oriented_tangents[k]\n",
    "    Xg.append(x0); Yg.append(y0)\n",
    "    Ug.append(tx * arrow_len); Vg.append(ty * arrow_len)\n",
    "\n",
    "# 4) Datos para flechas amarillas (junction center)\n",
    "Xy, Yy, Uy, Vy = [], [], [], []\n",
    "for j in junc3:\n",
    "    idxs = tube_index[j]\n",
    "    qs = np.array([flow_rates[i] for i in idxs])\n",
    "    i_max = idxs[np.argmax(qs)]\n",
    "    xj, yj = pos[j]  # junction center\n",
    "    tx, ty = oriented_tangents[i_max]\n",
    "    Xy.append(xj); Yy.append(yj)\n",
    "    Uy.append(tx * arrow_len); Vy.append(ty * arrow_len)\n",
    "\n",
    "# 5) Gráfico\n",
    "fig, ax = plt.subplots(figsize=(12, 8), dpi=1200)\n",
    "ax.imshow(mask, origin='lower',\n",
    "          extent=(xmin, xmax, ymin, ymax),\n",
    "          cmap='gray', alpha=0.4)\n",
    "\n",
    "# 6) Secciones y vectores U reescalados\n",
    "for k in range(len(tubes)):\n",
    "    start, end = offsets[k], offsets[k+1]\n",
    "    pts_k = all_pts[start:end]\n",
    "    uscaled = U_scaled[start:end]\n",
    "    xs, ys = pts_k[:,0], pts_k[:,1]\n",
    "    # sección\n",
    "    ax.plot(xs, ys, color='black', linewidth=0.5, alpha=0.6, zorder=1)\n",
    "    # vectores de velocidad\n",
    "    ax.quiver(xs, ys,\n",
    "              uscaled[:,0], uscaled[:,1],\n",
    "              angles='xy', scale_units='xy', scale=1,\n",
    "              width=0.0002, color='cyan', alpha=0.8, zorder=2)\n",
    "\n",
    "# 7) Flechas verdes (tangentes)\n",
    "ax.quiver(\n",
    "    Xg, Yg, Ug, Vg,\n",
    "    angles='xy', scale_units='xy', scale=1,\n",
    "    width=0.0004, headwidth=1, headlength=1.2, headaxislength=1,\n",
    "    color='green', alpha=0.8, zorder=3\n",
    ")\n",
    "\n",
    "# 8) Flechas amarillas (tube máximo en junction)\n",
    "ax.quiver(\n",
    "    Xy, Yy, Uy, Vy,\n",
    "    angles='xy', scale_units='xy', scale=1,\n",
    "    width=0.0004, headwidth=1, headlength=1.2, headaxislength=1,\n",
    "    color='yellow', alpha=0.9, zorder=4\n",
    ")\n",
    "\n",
    "# 9) Etiquetas pequeñas para junciones\n",
    "for j in junc1:\n",
    "    xj, yj = pos[j]\n",
    "    ax.text(xj, yj, \"1\", color='red', fontsize=2,\n",
    "            fontweight='bold', ha='center', va='center', zorder=5)\n",
    "for j in junc2:\n",
    "    xj, yj = pos[j]\n",
    "    ax.text(xj, yj, \"2\", color='blue', fontsize=2,\n",
    "            fontweight='bold', ha='center', va='center', zorder=5)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_title('Secciones, vectores U reescalados y tangentes (verde/amarillo)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona el índice del tubo a inspeccionar\n",
    "k = 6000  # Cambia este valor para otros tubos\n",
    "\n",
    "# Extrae puntos y velocidades para el tubo k\n",
    "start, end = offsets[k], offsets[k+1]\n",
    "pts_k = all_pts[start:end]    # (N_k, 3) coordenadas (x, y, z_mid)\n",
    "U_k   = Uall[start:end]       # (N_k, 2) componentes (U_x, U_y)\n",
    "\n",
    "# Crea figura para depuración\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=300)\n",
    "# Dibuja la sección del tubo\n",
    "ax.plot(pts_k[:, 0], pts_k[:, 1], '-k', linewidth=1, label=f'Tubo {k} sección')\n",
    "\n",
    "# Dibuja vectores de velocidad en cada punto\n",
    "ax.quiver(\n",
    "    pts_k[:, 0], pts_k[:, 1],\n",
    "    U_k[:, 0], U_k[:, 1],\n",
    "    angles='xy', scale_units='xy', scale=1,\n",
    "    width=0.002, color='red', alpha=0.8, label='Vectores U'\n",
    ")\n",
    "\n",
    "ax.set_aspect('auto')\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_title(f'Sección y velocidad en tubo {k}')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "\n",
    "# 1) Extrae y triangulariza la superficie\n",
    "surf = vol_mesh.extract_surface()\n",
    "surf_tri = surf.triangulate()  # ahora solo triángulos\n",
    "\n",
    "# 2) Puntos XY\n",
    "pts = surf_tri.points[:, :2]\n",
    "\n",
    "# 3) Caras (cada tri es [3, i0, i1, i2])\n",
    "faces = surf_tri.faces.reshape(-1, 4)[:, 1:4]\n",
    "\n",
    "# 4) Dibujo 2D\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=300)\n",
    "for tri in faces:\n",
    "    poly = pts[tri]\n",
    "    # cerrar el polígono\n",
    "    xs = np.append(poly[:,0], poly[0,0])\n",
    "    ys = np.append(poly[:,1], poly[0,1])\n",
    "    ax.plot(xs, ys, color='black', linewidth=0.3)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('x (m)')\n",
    "ax.set_ylabel('y (m)')\n",
    "ax.set_title('Proyección XY de la superficie de la malla (triangularizada)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 1: Gradiente del campo U en celdas —\n",
    "import vtk\n",
    "from vtk.util.numpy_support import vtk_to_numpy\n",
    "\n",
    "# Aplica vtkGradientFilter sobre el UnstructuredGrid vol_mesh\n",
    "grad_filter = vtk.vtkGradientFilter()\n",
    "grad_filter.SetInputData(vol_mesh)\n",
    "# Asocia 'U' a cada celda\n",
    "grad_filter.SetInputScalars(vtk.vtkDataSet.FIELD_ASSOCIATION_CELLS, 'U')\n",
    "grad_filter.SetResultArrayName('gradU')\n",
    "grad_filter.Update()\n",
    "\n",
    "# Envuelve el resultado en PyVista\n",
    "grad_mesh = pv.wrap(grad_filter.GetOutput())\n",
    "\n",
    "# Extraemos el tensor gradiente: cada fila es [∂Ux/∂x, ∂Ux/∂y, …, ∂Uz/∂z]\n",
    "gradU = grad_mesh.cell_data['gradU']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 2 (corregida): Centros de celda, velocidades y volúmenes —\n",
    "# Centros de cada celda\n",
    "cell_centers = grad_mesh.cell_centers().points  # (n_cells, 3)\n",
    "\n",
    "# Velocidad en cada celda (asumiendo que tienes U en cell_data; \n",
    "# si no, muestrea point_data sobre cell_data_centers)\n",
    "if 'U' in grad_mesh.cell_data:\n",
    "    U_cell = grad_mesh.cell_data['U']\n",
    "else:\n",
    "    cloud = pv.PolyData(cell_centers)\n",
    "    samp  = vol_mesh.sample(cloud)\n",
    "    U_cell = samp.point_data['U']\n",
    "\n",
    "# Magnitud de la velocidad en el plano XY\n",
    "vel_mag = np.linalg.norm(U_cell[:, :2], axis=1)\n",
    "\n",
    "# Volumen de cada celda (en m³)\n",
    "# usamos compute_cell_sizes() en lugar de compute_cell_size()\n",
    "sizes_mesh = grad_mesh.compute_cell_sizes()  \n",
    "vols = sizes_mesh.cell_data['Volume']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 3: Componentes del gradiente en (w,z) —\n",
    "# Desempaquetamos los 9 componentes de gradU\n",
    "dxx, dxy, dxz, dyx, dyy, dyz, dzx, dzy, dzz = gradU.T\n",
    "\n",
    "# Arrays de salida\n",
    "n_cells = len(vel_mag)\n",
    "delww = np.zeros(n_cells)\n",
    "delwz = np.zeros(n_cells)\n",
    "delzw = np.zeros(n_cells)\n",
    "delzz = np.zeros(n_cells)\n",
    "\n",
    "for idx in range(n_cells):\n",
    "    ux, uy = U_cell[idx,0], U_cell[idx,1]\n",
    "    vm2 = ux*ux + uy*uy\n",
    "    if vm2 == 0.0:\n",
    "        continue\n",
    "\n",
    "    cos2   = ux*ux/vm2\n",
    "    sin2   = 1.0 - cos2\n",
    "    sincos = ux*uy/vm2\n",
    "    alpha  = dxy[idx] + dyx[idx]\n",
    "    beta   = dyy[idx] - dxx[idx]\n",
    "\n",
    "    # formúlulas del C++\n",
    "    delww[idx] = dxx[idx]*cos2 + dyy[idx]*sin2 + alpha*sincos\n",
    "    delwz[idx] = dxy[idx]*cos2 - dyx[idx]*sin2 + beta*sincos\n",
    "    delzw[idx] = dyx[idx]*cos2 - dxy[idx]*sin2 + beta*sincos\n",
    "    delzz[idx] = dyy[idx]*cos2 + dxx[idx]*sin2 - alpha*sincos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 4: Función de histograma ponderado logarítmico y guardado —\n",
    "def weighted_log_hist(values, weights, N, vmin, vmax):\n",
    "    bins = np.logspace(np.log10(vmin), np.log10(vmax), N+1)\n",
    "    hist, edges = np.histogram(values, bins=bins, weights=weights)\n",
    "    centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "    return hist, centers\n",
    "\n",
    "N = 40\n",
    "\n",
    "# 1) Histograma de |Ux,y| (velocidad)\n",
    "minU, maxU = 1e-7, vel_mag.max()\n",
    "hU, cU = weighted_log_hist(vel_mag, vols, N, minU, maxU)\n",
    "np.savetxt('histograma_U.dat', np.column_stack((cU, hU)),\n",
    "           header='velocity_mag[m/s]\\thistogram')\n",
    "\n",
    "# 2) Histograma de shearXY = |∂Ux/∂y|\n",
    "shearXY = np.abs(dxy)\n",
    "minS, maxS = 1e-4, shearXY.max()\n",
    "hS, cS = weighted_log_hist(shearXY, vols, N, minS, maxS)\n",
    "np.savetxt('histograma_shear_XY.dat', np.column_stack((cS, hS)),\n",
    "           header='|dUx/dy|[1/s]\\thistogram')\n",
    "\n",
    "# 3) Análogos para delww, delwz, delzw, delzz…\n",
    "for arr, name in [(delww,'WW'), (delwz,'WZ'), (delzw,'ZW'), (delzz,'ZZ')]:\n",
    "    mn, mx = 1e-4, np.abs(arr).max()\n",
    "    h, c = weighted_log_hist(np.abs(arr), vols, N, mn, mx)\n",
    "    np.savetxt(f'histograma_shear_{name}.dat', np.column_stack((c, h)),\n",
    "               header=f'|d{name}|[1/s]\\thistogram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 5: 2D log-histograma y shear dado velocidad —\n",
    "# Construimos bins log en ambas direcciones\n",
    "xbins = np.logspace(np.log10(minU), np.log10(maxU), N+1)\n",
    "ybins = np.logspace(np.log10(minS), np.log10(maxS), N+1)\n",
    "\n",
    "# 2D histograma ponderado\n",
    "hist2d, xedges, yedges = np.histogram2d(\n",
    "    vel_mag, np.abs(delwz), bins=[xbins, ybins], weights=np.repeat(vols, 1)\n",
    ")\n",
    "\n",
    "# Centroides de bin\n",
    "xcent = np.sqrt(xedges[:-1]*xedges[1:])\n",
    "ycent = np.sqrt(yedges[:-1]*yedges[1:])\n",
    "\n",
    "# shear promedio y error en cada bin de velocidad\n",
    "shear_given_v = np.zeros(N)\n",
    "sh_error_v   = np.zeros(N)\n",
    "for i in range(N):\n",
    "    mask = (vel_mag>=xedges[i]) & (vel_mag<xedges[i+1])\n",
    "    w = vols[mask]\n",
    "    s = np.abs(delwz[mask])\n",
    "    if w.sum()>0:\n",
    "        # suma de pesos\n",
    "        wsum = w.sum()\n",
    "        # media ponderada\n",
    "        mean_s = np.sum(s * w) / wsum\n",
    "        # varianza ponderada\n",
    "        var_w = np.sum(w * (s - mean_s)**2) / wsum\n",
    "        # cálculo del error estándar ponderado:\n",
    "        # N_eff = (sum w)^2 / sum(w^2)\n",
    "        # err = sqrt(var_w / N_eff) = sqrt(var_w * sum(w^2) / sum(w)^2)\n",
    "        err_s = np.sqrt(var_w * np.sum(w**2) / wsum**2)\n",
    "\n",
    "        shear_given_v[i] = mean_s\n",
    "        sh_error_v[i]   = err_s\n",
    "# Guardado\n",
    "np.savetxt('shear_given_v.dat', np.column_stack((xcent, shear_given_v, sh_error_v)),\n",
    "           header='velocity_bin_center[m/s]\\tshear_mean[1/s]\\tshear_std[1/s]')\n",
    "np.savetxt('conditioned_2D_histo.dat', np.column_stack(\n",
    "    [hist2d.flatten(), \n",
    "     np.repeat(xcent, N), \n",
    "     np.tile(ycent, N)]\n",
    "), header='hist_val\\tvel_center\\tshear_center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 6: Promedios ponderados por volumen —\n",
    "avgVel   = np.sum(vel_mag * vols) / np.sum(vols)\n",
    "avgShear = np.sum(np.abs(delwz) * vols) / np.sum(vols)\n",
    "\n",
    "with open('averages.dat', 'w') as f:\n",
    "    f.write('# Promedio ponderado por volumen\\n')\n",
    "    f.write(f'avgVelocity  {avgVel:.6e}\\n')\n",
    "    f.write(f'avgShearWZ   {avgShear:.6e}\\n')\n",
    "print(\"Promedios guardados en 'averages.dat'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 7 (actualizada): Histogramas con valores mínimos fijos —\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros\n",
    "nbins = 50\n",
    "vmin = 1e-6\n",
    "smin = 1e-3\n",
    "\n",
    "# Filtramos para evitar valores por debajo del umbral\n",
    "vel_filt   = vel_mag[vel_mag >= vmin]\n",
    "shear_wz_f = np.abs(delwz)\n",
    "shear_filt = shear_wz_f[shear_wz_f >= smin]\n",
    "\n",
    "# Máximos para los ejes\n",
    "vmax = vel_filt.max()\n",
    "smax = shear_filt.max()\n",
    "\n",
    "# 1) Histograma de vel_mag en escala lineal\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(vel_filt, bins=np.linspace(vmin, vmax, nbins), \n",
    "        density=True, edgecolor='black')\n",
    "ax.set_xlabel('Velocidad $|\\\\mathbf{U}|$ (m/s)')\n",
    "ax.set_ylabel('Número de celdas')\n",
    "ax.set_title('Histograma velocidad (lin–lin)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Histograma de vel_mag en escala log–log\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(vel_filt, bins=np.logspace(np.log10(vmin), np.log10(vmax), nbins),\n",
    "        density=True, edgecolor='black')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Velocidad $|\\\\mathbf{U}|$ (m/s)')\n",
    "ax.set_ylabel('Número de celdas')\n",
    "ax.set_title('Histograma velocidad (log–log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Histograma de shear WZ en escala lineal\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(shear_filt, bins=np.linspace(smin, smax, nbins),\n",
    "        density=True, edgecolor='black')\n",
    "ax.set_xlabel('|$∂_{WZ}$| (1/s)')\n",
    "ax.set_ylabel('Número de celdas')\n",
    "ax.set_title('Histograma shear WZ (lin–lin)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) Histograma de shear WZ en escala log–log\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.hist(shear_filt, bins=np.logspace(np.log10(smin), np.log10(smax), nbins),\n",
    "        density=True, edgecolor='black')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('|$∂_{WZ}$| (1/s)')\n",
    "ax.set_ylabel('Número de celdas')\n",
    "ax.set_title('Histograma shear WZ (log–log)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda 8: Promedio de shear WZ dado velocidad (log–log) —\n",
    "\n",
    "# (Asumimos que ya tienes xcent, shear_given_v y sh_error_v de la Celda 5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.errorbar(xcent, shear_given_v, yerr=sh_error_v, fmt='o', markersize=4,\n",
    "            elinewidth=1, capsize=2, label='⟨shear WZ⟩ por bin de velocidad')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Velocidad bin (m/s)')\n",
    "ax.set_ylabel('Promedio |$∂_wz$| (1/s)')\n",
    "ax.set_title('Shear WZ promedio vs velocidad (log–log)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajuste de caudales y comparación de P(v) y S(v) teórico/experimental —\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon\n",
    "from scipy.special import k0\n",
    "\n",
    "# 0) Parámetros geométricos\n",
    "h = 0.5e-3                   # espesor h = 1 mm\n",
    "r = h/np.sqrt(12)          # r = h/√12\n",
    "a = np.mean(half_ws)       # semianchura promedio (m)\n",
    "\n",
    "# 1) Ajuste exponencial de la distribución de caudales → Qc\n",
    "flow = np.array(flow_rates)\n",
    "_, Qc = expon.fit(flow, floc=0)\n",
    "print(f\"Qc (escala parámetro exponencial) = {Qc:.3e} m³/s\")\n",
    "\n",
    "# 2) Cálculo de w_c\n",
    "wc = 3*Qc*a / (h**3 * (1 - (r/a)*np.tanh(a/r)))\n",
    "print(f\"w_c = {wc:.3e} m/s\")\n",
    "\n",
    "# 3) Histograma de caudales + ajuste exponencial\n",
    "Qv = np.linspace(flow.min(), flow.max(), 200)\n",
    "pdf_exp = (1/Qc) * np.exp(-Qv/Qc)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(flow, bins=30, density=True, alpha=0.6,\n",
    "         edgecolor='black', label='Caudales (histograma)')\n",
    "plt.plot(Qv, pdf_exp, 'r-', lw=2, label='Ajuste exp')\n",
    "plt.xlabel('Caudal $Q$ (m³/s)')\n",
    "plt.ylabel('Densidad')\n",
    "plt.title('Distribución de caudales y ajuste exponencial')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4) Preparación para P(v) y S(v)\n",
    "v = np.array(vel_mag)\n",
    "vmin = 1e-7\n",
    "mask = v >= vmin\n",
    "v_filt = v[mask]\n",
    "v_th = np.linspace(vmin, v.max(), 300)\n",
    "\n",
    "# 5) Constantes intermedias\n",
    "ar      = a/r\n",
    "cosh_ar = np.cosh(ar)\n",
    "sinh_ar = np.sinh(ar)\n",
    "coth_ar = cosh_ar/sinh_ar\n",
    "factor  = cosh_ar / (sinh_ar**2)   # = cosh(ar)/sinh²(ar)\n",
    "alpha2  = (a/r)**2\n",
    "\n",
    "# 6) P_teórico(v) según tu foto\n",
    "P_pref = ( (a/r) * coth_ar ) / (2*wc)\n",
    "P_th   = P_pref * np.exp( -0.5 * alpha2 * coth_ar**2 * (v_th/wc) ) * k0( 0.5 * factor * alpha2 * (v_th/wc) )\n",
    "\n",
    "# 7) S_teórico(v) según tu foto\n",
    "#    S(v) = [2 w_c/a * (r/a) tanh(a/r)] \n",
    "#           * exp{ -½ [cosh(ar)/sinh²(ar)] (a/r)² v/wc }\n",
    "#           * K0[+½ [cosh(ar)/sinh²(ar)] (a/r)² v/wc]\n",
    "S_pref = (2*wc/a) * (r/a) * np.tanh(ar)\n",
    "S_th   = S_pref * np.exp( -0.5 * factor * alpha2 * (v_th/wc) )/k0( 0.5 * factor * alpha2 * (v_th/wc) )\n",
    "\n",
    "# 8) Gráfica de P(v)\n",
    "plt.figure(figsize=(6,4))\n",
    "bins_v = np.logspace(np.log10(vmin), np.log10(v.max()), 40)\n",
    "plt.hist(v_filt, bins=bins_v, density=True, alpha=0.6,\n",
    "         edgecolor='black', label='P_exp (histograma)')\n",
    "plt.plot(v_th, P_th, 'r-', lw=2, label='P_teórico')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Velocidad $v$ (m/s)')\n",
    "plt.ylabel('Densidad $P(v)$')\n",
    "plt.title('Distribución de velocidades (v ≥ 1e-7 m/s)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Gráfica de S(v)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.errorbar(xcent, shear_given_v, yerr=sh_error_v,\n",
    "             fmt='o', markersize=4, elinewidth=1, capsize=2,\n",
    "             label='⟨shear WZ⟩ experimental')\n",
    "plt.plot(v_th, S_th, 'r--', lw=2, label='S_teórico')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Velocidad $v$ (m/s)')\n",
    "plt.ylabel('Shear $S(v)$ (1/s)')\n",
    "plt.title('Shear WZ vs velocidad (log–log)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Celda X: Comparativa experimental vs teórico en escala lineal (lin–lin) —\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reutilizamos variables de la celda anterior: \n",
    "# vel, vmin, vel_filt, v_th, P_th, xcent, shear_given_v, sh_error_v, S_th\n",
    "\n",
    "# 1) Histograma de P(v) lin–lin\n",
    "plt.figure(figsize=(6,4))\n",
    "bins_lin = np.linspace(vmin, vel.max(), 40)\n",
    "plt.hist(vel_filt, bins=bins_lin, density=True, alpha=0.6,\n",
    "         edgecolor='black', label='P_exp (histograma)')\n",
    "plt.plot(v_th, P_th, 'r-', lw=2, label='P_teórico')\n",
    "plt.xlabel('Velocidad $v$ (m/s)')\n",
    "plt.ylabel('Densidad $P(v)$')\n",
    "plt.title('Distribución de velocidades (lin–lin)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Comparativa S(v) lin–lin\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.errorbar(xcent, shear_given_v, yerr=sh_error_v,\n",
    "             fmt='o', markersize=4, elinewidth=1, capsize=2,\n",
    "             label='S_exp = ⟨shear WZ⟩')\n",
    "plt.plot(v_th, S_th, 'r--', lw=2, label='S_teórico')\n",
    "plt.xlabel('Velocidad $v$ (m/s)')\n",
    "plt.ylabel('Shear $S(v)$ (1/s)')\n",
    "plt.title('Shear WZ vs velocidad (lin–lin)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
